{"id":"MvwLKznkcWQJt9LV3qspiNNstpReRGojdXM3bsYDh","title":"Kubernetes Blog","displayTitle":"Dev - Kubernetes Blog","url":"https://kubernetes.io/feed.xml","feedLink":"https://kubernetes.io/","items":[{"title":"How we built a dynamic Kubernetes API Server for the API Aggregation Layer in Cozystack","url":"https://kubernetes.io/blog/2024/11/21/dynamic-kubernetes-api-server-for-cozystack/","date":1732147200,"author":"","unread":true,"desc":"","content":"\n<p>Hi there! I'm Andrei Kvapil, but you might know me as <a href=\"https://github.com/kvaps\">@kvaps</a> in communities dedicated to Kubernetes\nand cloud-native tools. In this article, I want to share how we implemented our own extension api-server\nin the open-source PaaS platform, Cozystack.</p>\n<p>Kubernetes truly amazes me with its powerful extensibility features. You're probably already\nfamiliar with the <a href=\"https://kubernetes.io/docs/concepts/architecture/controller/\">controller</a> concept\nand frameworks like <a href=\"https://book.kubebuilder.io/\">kubebuilder</a> and\n<a href=\"https://sdk.operatorframework.io/\">operator-sdk</a> that help you implement it. In a nutshell, they\nallow you to extend your Kubernetes cluster by defining custom resources (CRDs) and writing additional\ncontrollers that handle your business logic for reconciling and managing these kinds of resources.\nThis approach is well-documented, with a wealth of information available online on how to develop your\nown operators.</p>\n<p>However, this is not the only way to\n<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/#api-extensions\">extend the Kubernetes API</a>.\nFor more complex scenarios such as implementing imperative logic,\nmanaging subresources, and dynamically generating responsesâ€”the Kubernetes API <em>aggregation layer</em>\nprovides an effective alternative. Through the aggregation layer, you can develop a custom\nextension API server and seamlessly integrate it within the broader Kubernetes API framework.</p>\n<p>In this article, I will explore the API aggregation layer, the types of challenges it is well-suited\nto address, cases where it may be less appropriate, and how we utilized this model to implement\nour own extension API server in Cozystack.</p>\n<h2 id=\"what-is-the-api-aggregation-layer\">What Is the API Aggregation Layer?</h2>\n<p>First, let's get definitions straight to avoid any confusion down the road.\nThe <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/\">API aggregation layer</a>\nis a feature in Kubernetes, while an extension api-server is a specific implementation of an\nAPI server for the aggregation layer. An extension API server is just like the standard Kubernetes API server, except it runs separately and handles requests for your specific resource types.</p>\n<p>So, the aggregation layer lets you write your own extension API server, integrate it easily into Kubernetes,\nand directly process requests for resources in a certain group. Unlike the CRD mechanism, the extension API\nis registered in Kubernetes as an APIService, telling Kubernetes to consider this new API server and acknowledge\nthat it serves certain APIs.</p>\n<p>You can execute this command to list all registered apiservices:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get apiservices.apiregistration.k8s.io\n</span></span></code></pre></div><p>Example APIService:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">NAME SERVICE AVAILABLE AGE\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">v1alpha1.apps.cozystack.io cozy-system/cozystack-api True 7h29m\n</span></span></span></code></pre></div><p>As soon as the Kubernetes api-server receives requests for resources in the group\n<code>v1alpha1.apps.cozystack.io</code>, it redirects all those requests to our extension api-server,\nwhich can handle them based on the business logic we've built into it.</p>\n<h2 id=\"when-to-use-the-api-aggregation-layer\">When to use the API Aggregation Layer</h2>\n<p>The API Aggregation Layer helps solve several issues where the usual CRD mechanism might\nnot enough. Let's break them down.</p>\n<h3 id=\"imperative-logic-and-subresources\">Imperative Logic and Subresources</h3>\n<p>Besides regular resources, Kubernetes also has something called subresources.</p>\n<p>In Kubernetes, subresources are additional actions or operations you can perform on primary resources\n(like Pods, Deployments, Services) via the Kubernetes API. They provide interfaces to manage\nspecific aspects of resources without affecting the entire object.</p>\n<p>A simple example is <code>status</code>, which is traditionally exposed as a separate subresource that you can\naccess independently from the parent object. The <code>status</code> field isn't meant to be changed</p>\n<p>But beyond <code>/status</code>, Pods in Kubernetes also have subresources like <code>/exec</code>, <code>/portforward</code>, and\n<code>/log</code>. Interestingly, instead of the usual declarative resources in Kubernetes, these represent\nendpoints for imperative operations like viewing logs, proxying connections, executing commands in\na running container, and so on.</p>\n<p>To support such imperative commands on your own API, you need implement an extension API and an\nextension API server. Here are some well-known examples:</p>\n<ul>\n<li><strong>KubeVirt</strong>: An add-on for Kubernetes that extends its API capabilities to run traditional virtual machines.\nThe extension api-server created as part of KubeVirt handles subresources\nlike <code>/restart</code>, <code>/console</code>, and <code>/vnc</code> for virtual machines.</li>\n<li><strong>Knative</strong>: A Kubernetes add-on that extends its capabilities for serverless computing,\nimplementing the <code>/scale</code> subresource to set up autoscaling for its resource types.</li>\n</ul>\n<p>By the way, even though subresource logic in Kubernetes can be <em>imperative</em>, you can manage access\nto them <em>declaratively</em> using Kubernetes standard RBAC model.</p>\n<p>For example this way you can control access to the <code>/log</code> and <code>/exec</code> subresources of the Pod kind:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Role<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>rbac.authorization.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>default<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>pod-and-pod-logs-reader<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">rules</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>- <span style=\"color:#008000;font-weight:bold\">apiGroups</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;pods&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;pods/log&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">verbs</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;get&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;list&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>- <span style=\"color:#008000;font-weight:bold\">apiGroups</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;pods/exec&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">verbs</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;create&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><h3 id=\"you-re-not-tied-to-use-etcd\">You're not tied to use etcd</h3>\n<p>Usually, the Kubernetes API server uses <a href=\"https://etcd.io/\">etcd</a> for its backend.\nHowever, implementing your own API server doesn't lock you into using only etcd.\nIf it doesn't make sense to store your server's state in etcd, you can store information in any\nother system and generate responses on the fly. Here are a few cases to illustrate:</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/kubernetes-sigs/metrics-server\">metrics-server</a> is a standard extension for Kubernetes\nwhich allows you to view real-time metrics of your nodes and pods. It defines alternative Pod and Node\nkinds in its own metrics.k8s.io API. Requests to these resources are translated into metrics\ndirectly from Kubelet. So when you run <code>kubectl top node</code> or <code>kubectl top pod</code>, metrics-server fetches\nmetrics from cAdvisor in real-time. It then returns these metrics to you. Since the information\nis generated in real-time and is only relevant at the moment of the request, there is no need\nto store it in etcd. This approach saves resources.</p>\n</li>\n<li>\n<p>If needed, you can use a backend other than etcd. You can even implement a Kubernetes-compatible API\nfor it. For example, if you use Postgres, you can create a transparent representation of its entities\nin the Kubernetes API. Eg. databases, users, and grants within Postgres would appear as regular\nKubernetes resources, thanks to your extension API server. You could manage them using <code>kubectl</code> or any\nother Kubernetes-compatible tool. Unlike controllers, which implement business logic using custom resources\nand reconciliation methods, an extension API server eliminates the need for separate controllers for every kind.\nThis means you don't have to sync state between the Kubernetes API and your backend.</p>\n</li>\n</ul>\n<h3 id=\"one-time-resources\">One-Time resources</h3>\n<ul>\n<li>\n<p>Kubernetes has a special API used to provide users with information about their permissions.\nThis is implemented using the SelfSubjectAccessReview API. One unusual detail of these\nresources is that you can't view them using <strong>get</strong> or <strong>list</strong> verbs. You can only create them (using\nthe <strong>create</strong> verb) and receive output with information about what you have access to at that\nmoment.</p>\n<p>If you try to run <code>kubectl get selfsubjectaccessreviews</code> directly, you'll just get an error\nlike this:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">Error from server (MethodNotAllowed): the server does not allow this method on the requested resource\n</span></span></span></code></pre></div><p>The reason is that the Kubernetes API server doesn't support any other interaction with this\ntype of resource (you can only CREATE them).</p>\n<p>The SelfSubjectAccessReview API supports commands such as:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl auth can-i create deployments --namespace dev\n</span></span></code></pre></div><p>When you run the command above, <code>kubectl</code> creates a SelfSubjectAccessReview using the\nKubernetes API. This allows Kubernetes to fetch a list of possible permissions for your user.\nKubernetes then generates a personalized response to your request in real-time. This logic is\ndifferent from a scenario where this resource is simply stored in etcd.</p>\n</li>\n<li>\n<p>Similarly, in KubeVirt's <a href=\"https://github.com/kubevirt/containerized-data-importer\">CDI (Containerized Data Importer)</a>\nextension, which allows file uploads into a PVC from a local machine using the <code>virtctl</code> tool,\na special token is required before the upload process begins.\nThis token is generated by creating an UploadTokenRequest resource via the Kubernetes API. Kubernetes\nroutes (proxies) all UploadTokenRequest resource creation requests to the CDI extension API server,\nwhich generates and returns the token in response.</p>\n</li>\n</ul>\n<h3 id=\"full-control-over-conversion-validation-and-output-formatting\">Full control over conversion, validation, and output formatting</h3>\n<ul>\n<li>\n<p>Your own API server can have all the capabilities of the vanilla Kubernetes API server. The resources you create\nin your API server can be validated immediately on the server side without additional webhooks.\nWhile CRDs also support server-side validation using <a href=\"https://kubernetes.io/docs/reference/using-api/cel/\">Common Expression Language (CEL)</a>\nfor declarative validation and <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/validating-admission-policy/\">ValidatingAdmissionPolicies</a>\nwithout the need for webhooks, a custom API server allows for more complex and tailored validation logic if needed.</p>\n<p>Kubernetes allows you to serve multiple API versions for each resource type, traditionally\n<code>v1alpha1</code>, <code>v1beta1</code> and <code>v1</code>. Only one version can be specified as the storage version.\nAll requests to other versions must be automatically converted to the version specified as storage version.\nWith CRDs, this mechanism is implemented using conversion webhooks. Whereas in an extension API server,\nyou can implement your own conversion mechanism, choose to mix up different storage versions (one\nobject might be serialized as <code>v1</code>, another as <code>v2</code>), or rely on an external backing API.</p>\n</li>\n<li>\n<p>Directly implementing the Kubernetes API lets you format table output however you like and doesn't force you to follow\nthe <code>additionalPrinterColumns</code> logic in CRDs. Instead, you can write your own formatter that\nformats the table output and custom fields in it. For example, when using <code>additionalPrinterColumns</code>,\nyou can display field values only following the JSONPath logic. In your own API server, you can generate\nand insert values on the fly, formatting the table output as you wish.</p>\n</li>\n</ul>\n<h3 id=\"dynamic-resource-registration\">Dynamic resource registration</h3>\n<ul>\n<li>The resources served by an extension api-server don't need to be pre-registered as CRDs.\nOnce your extension API server is registered using an APIService, Kubernetes starts polling it to discover\nAPIs and resources it can serve. After receiving a discovery response, the Kubernetes API server automatically\nregisters all available types for this API group.\nAlthough this isn't considered common practice, you can implement logic that dynamically registers\nthe resource types you need in your Kubernetes cluster.</li>\n</ul>\n<h2 id=\"when-not-to-use-the-api-aggregation-layer\">When not to use the API Aggregation Layer</h2>\n<p>There are some anti-patterns where using the API Aggregation Layer isn't recommended.\nLet's go through them.</p>\n<h3 id=\"unstable-backend\">Unstable backend</h3>\n<p>If your API server stops responding for some reason due to an unavailable backend or other issues it\nmay block some Kubernetes functionality. For example, when deleting namespaces, Kubernetes will wait\nfor a response from your API server to see if there are any remaining resources.\nIf the response doesn't come, the namespace deletion will be blocked.</p>\n<p>Also, you might have encountered a <a href=\"https://github.com/kedacore/keda/issues/4224\">situation</a> where,\nwhen the metrics-server is unavailable, an extra message appears in stderr after every API request\n(even unrelated to metrics) stating that <code>metrics.k8s.io</code> is unavailable. This is another example\nof how using the API Aggregation Layer can lead to problems when the api-server handling requests\nis unavailable.</p>\n<h3 id=\"slow-requests\">Slow requests</h3>\n<p>If you can't guarantee an instant response for user requests, it's better to consider using a\nCustomResourceDefinition and controller.\nOtherwise, you might make your cluster less stable. Many projects implement an extension\nAPI server only for a limited set of resources, particularly for imperative logic and subresources.\nThis recommendation is also\n<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/#response-latency\">mentioned</a>\nin the official Kubernetes\ndocumentation.</p>\n<h2 id=\"why-we-needed-it-in-cozystack\">Why we needed it in Cozystack</h2>\n<p>As a reminder, we're developing the open-source PaaS platform <a href=\"https://cozystack.io/\">Cozystack</a>,\nwhich can also be used as a framework for building your own private cloud. Therefore, the ability\nto easily extend the platform is crucial for us.</p>\n<p>Cozystack is built on top of <a href=\"https://fluxcd.io/\">FluxCD</a>. Any application is packaged into its\nown Helm chart, ready for deployment in a tenant namespace. Deploying any application on the platform\nis done by creating a HelmRelease resource, specifying the chart name and parameters for the application.\nAll the rest logic is handled by FluxCD. This pattern allows us to easily extend the platform with new\napplications and provide the ability to create new applications that just need to be packaged\ninto the appropriate Helm chart.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2024/11/21/dynamic-kubernetes-api-server-for-cozystack/cozystack.png\"\nalt=\"Interface of the Cozystack platform\"/> <figcaption>\n<p>Interface of the Cozystack platform</p>\n</figcaption>\n</figure>\n<p>So, in our platform, everything is configured as HelmRelease resources. However, we ran into\ntwo problems: limitations of the RBAC model and the need for a public API. Let's delve into these</p>\n<h3 id=\"limitations-of-the-rbac-model\">Limitations of the RBAC model</h3>\n<p>The widely-deployed RBAC system in Kubernetes doesn't allow you to restrict access to a list of resources\nof the same kind based on labels or specific fields in the spec. When creating a role, you can limit\naccess across the resources in the same kind only by specifying specific resource names in <code>resourceNames</code>.\nFor verbs like <strong>get</strong> or <strong>update</strong> it will work. However, filtering by <code>resourceNames</code> using <strong>list</strong>\nverb doesn't work like that. Thus you can limit listing certain resources by kind but not by name.</p>\n<ul>\n<li>Kubernetes has a special API used to provide users with information about their permissions.\nThis is implemented using the SelfSubjectAccessReview API. One unusual detail of these\nresources is that you can't view them using <strong>get</strong> or <strong>list</strong> verbs. You can only create them (using\nthe <strong>create</strong> verb) and receive output with information about what you have access to at that\nmoment.</li>\n</ul>\n<p>So, we decided to introduce new resource types based on the names of the Helm charts they use and\ngenerate the list of available kinds dynamically at runtime in our extension api-server.\nThis way, we can reuse Kubernetes standard RBAC model to manage access to specific resource types.</p>\n<h3 id=\"need-for-a-public-api\">Need for a public API</h3>\n<p>Since our platform provides capabilities for deploying various managed services, we want to organize\npublic access to the platform's API. However, we can't allow users to interact directly with resources\nlike HelmRelease because that would let them specify arbitrary names and parameters for Helm charts to\ndeploy, potentially compromising our system.</p>\n<p>We wanted to give users the ability to deploy a specific service simply by creating the resource with corresponding\nkind in Kubernetes. The type of this resource should be named the same as the chart from\nwhich it's deployed. Here are some examples:</p>\n<ul>\n<li><code>kind: Kubernetes</code> â†’ <code>chart: kubernetes</code></li>\n<li><code>kind: Postgres</code> â†’ <code>chart: postgres</code></li>\n<li><code>kind: Redis</code> â†’ <code>chart: redis</code></li>\n<li><code>kind: VirtualMachine</code> â†’ <code>chart: virtual-machine</code></li>\n</ul>\n<p>Moreover, we don't want to have to add a new type to codegen and recompile our extension API server\nevery time we add a new chart for it to start being served.\nThe schema update should be done dynamically or provided via a ConfigMap by the administrator.</p>\n<h3 id=\"two-way-conversion\">Two-Way conversion</h3>\n<p>Currently, we already have integrations and a dashboard that continue to use HelmRelease resources.\nAt this stage, we didn't want to lose the ability to support this API. Considering that we're simply\ntranslating one resource into another, support is maintained and it works both ways.\nIf you create a HelmRelease, you'll get a custom resource in Kubernetes, and if you create a\ncustom resource in Kubernetes, it will also be available as a HelmRelease.</p>\n<p>We don't have any additional controllers that synchronize state between these resources.\nAll requests to resources in our extension API server are transparently proxied to HelmRelease and vice versa.\nThis eliminates intermediate states and the need to write controllers and synchronization logic.</p>\n<h2 id=\"implementation\">Implementation</h2>\n<p>To implement the Aggregation API, you might consider starting with the following projects:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes-sigs/apiserver-builder-alpha\">apiserver-builder</a>:\nCurrently in alpha and hasn't been updated for two years. It works like kubebuilder,\nproviding a framework for creating an extension API server, allowing you to sequentially create\na project structure and generate code for your resources.</li>\n<li><a href=\"https://github.com/kubernetes/sample-apiserver\">sample-apiserver</a>:\nA ready-made example of an implemented API server, based on official Kubernetes libraries,\nwhich you can use as a foundation for your project.</li>\n</ul>\n<p>For practical reasons, we chose the second project. Here's what we needed to do:</p>\n<h3 id=\"disable-etcd-support\">Disable etcd support</h3>\n<p>In our case, we don't need it since all resources are stored directly in the Kubernetes API.</p>\n<p>You can disable etcd options by passing nil to <code>RecommendedOptions.Etcd</code>:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/cmd/server/start.go#L70\">Disabling etcd options</a></li>\n</ul>\n<h3 id=\"generate-a-common-resource-kind\">Generate a common resource kind</h3>\n<p>We called it Application, and it looks like this:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/apis/apps/v1alpha1/types.go\">Application type definition</a></li>\n</ul>\n<p>This is a generic type used for any application type, and its handling logic is the same for all charts.</p>\n<h3 id=\"configure-configuration-loading\">Configure configuration loading</h3>\n<p>Since we want to configure our extension api-server via a config file, we formed the config structure in Go:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/config/config.go\">Config type definition</a></li>\n</ul>\n<p>We also modified the resource registration logic so that the resources we create are registered in scheme with different <code>Kind</code> values:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/apis/apps/v1alpha1/register.go#L63-L77\">Dynamic resource registration</a></li>\n</ul>\n<p>As a result, we got a config where you can pass all possible types and specify what they should map to:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/packages/system/cozystack-api/templates/configmap.yaml\">ConfigMap example</a></li>\n</ul>\n<h3 id=\"implement-our-own-registry\">Implement our own registry</h3>\n<p>To store state not in etcd but translate it directly into Kubernetes HelmRelease resources (and vice versa),\nwe wrote conversion functions from Application to HelmRelease and from HelmRelease to Application:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/registry/apps/application/rest.go#L920-L991\">Conversion functions</a></li>\n</ul>\n<p>We implemented logic to filter resources by chart name, <code>sourceRef</code>, and prefix in the HelmRelease name:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/registry/apps/application/rest.go#L747-L784\">Filtering functions</a></li>\n</ul>\n<p>Then, using this logic, we implemented the methods <code>Get()</code>, <code>Delete()</code>, <code>List()</code>, <code>Create()</code>.</p>\n<p>You can see the full example here:</p>\n<ul>\n<li><a href=\"https://github.com/aenix-io/cozystack/blob/003edf8cf0a419bd67cd822d61ff806db49e7026/pkg/registry/apps/application/rest.go\">Registry Implementation</a></li>\n</ul>\n<p>At the end of each method, we set the correct <code>Kind</code> and return an <code>unstructured.Unstructured{}</code> object\nso that Kubernetes serializes the object correctly. Otherwise,\nit would always serialize them with <code>kind: Application</code>, which we don't want.</p>\n<h2 id=\"what-did-we-achieve\">What did we achieve?</h2>\n<p>In Cozystack, all our types from the ConfigMap are now available in Kubernetes as-is:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl api-resources | grep cozystack\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">buckets apps.cozystack.io/v1alpha1 true Bucket\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">clickhouses apps.cozystack.io/v1alpha1 true ClickHouse\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">etcds apps.cozystack.io/v1alpha1 true Etcd\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">ferretdb apps.cozystack.io/v1alpha1 true FerretDB\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">httpcaches apps.cozystack.io/v1alpha1 true HTTPCache\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">ingresses apps.cozystack.io/v1alpha1 true Ingress\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">kafkas apps.cozystack.io/v1alpha1 true Kafka\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">kuberneteses apps.cozystack.io/v1alpha1 true Kubernetes\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">monitorings apps.cozystack.io/v1alpha1 true Monitoring\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">mysqls apps.cozystack.io/v1alpha1 true MySQL\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">natses apps.cozystack.io/v1alpha1 true NATS\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">postgreses apps.cozystack.io/v1alpha1 true Postgres\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">rabbitmqs apps.cozystack.io/v1alpha1 true RabbitMQ\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">redises apps.cozystack.io/v1alpha1 true Redis\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">seaweedfses apps.cozystack.io/v1alpha1 true SeaweedFS\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">tcpbalancers apps.cozystack.io/v1alpha1 true TCPBalancer\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">tenants apps.cozystack.io/v1alpha1 true Tenant\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">virtualmachines apps.cozystack.io/v1alpha1 true VirtualMachine\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vmdisks apps.cozystack.io/v1alpha1 true VMDisk\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vminstances apps.cozystack.io/v1alpha1 true VMInstance\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vpns apps.cozystack.io/v1alpha1 true VPN\n</span></span></span></code></pre></div><p>We can work with them just like regular Kubernetes resources.</p>\n<p>Listing S3 Buckets:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get buckets.apps.cozystack.io -n tenant-kvaps\n</span></span></code></pre></div><p>Example output:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">NAME READY AGE VERSION\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">foo True 22h 0.1.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">testaasd True 27h 0.1.0\n</span></span></span></code></pre></div><p>Listing Kubernetes Clusters:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get kuberneteses.apps.cozystack.io -n tenant-kvaps\n</span></span></code></pre></div><p>Example output:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">NAME READY AGE VERSION\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">abc False 19h 0.14.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">asdte True 22h 0.13.0\n</span></span></span></code></pre></div><p>Listing Virtual Machine Disks:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get vmdisks.apps.cozystack.io -n tenant-kvaps\n</span></span></code></pre></div><p>Example output:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">NAME READY AGE VERSION\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">docker True 21d 0.1.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">test True 18d 0.1.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">win2k25-iso True 21d 0.1.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">win2k25-system True 21d 0.1.0\n</span></span></span></code></pre></div><p>Listing Virtual Machine Instances:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get vminstances.apps.cozystack.io -n tenant-kvaps\n</span></span></code></pre></div><p>Example output:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">NAME READY AGE VERSION\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">docker True 21d 0.1.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">test True 18d 0.1.0\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">win2k25 True 20d 0.1.0\n</span></span></span></code></pre></div><p>We can create, modify, and delete each of them, and any interaction with them will be translated\ninto HelmRelease resources, while also applying the resource structure and prefix in the name.</p>\n<p>To see all related Helm releases:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get helmreleases -n tenant-kvaps -l cozystack.io/ui\n</span></span></code></pre></div><p>Example output:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#888\">NAME AGE READY\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">bucket-foo 22h True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">bucket-testaasd 27h True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">kubernetes-abc 19h False\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">kubernetes-asdte 22h True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">redis-test 18d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">redis-yttt 12d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-disk-docker 21d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-disk-test 18d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-disk-win2k25-iso 21d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-disk-win2k25-system 21d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-instance-docker 21d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-instance-test 18d True\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">vm-instance-win2k25 20d True\n</span></span></span></code></pre></div><h2 id=\"next-steps\">Next Steps</h2>\n<p>We donâ€™t intend to stop here with our API. In the future, we plan to add new features:</p>\n<ul>\n<li>Add validation based on an OpenAPI spec generated directly from Helm charts.</li>\n<li>Develop a controller that collects release notes from deployed releases and shows users\naccess information for specific services.</li>\n<li>Revamp our dashboard to work directly with the new API.</li>\n</ul>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>The API Aggregation Layer allowed us to quickly and efficiently solve our problem by providing\na flexible mechanism for extending the Kubernetes API with dynamically registered resources and\nconverting them on the fly. Ultimately, this made our platform even more flexible and extensible\nwithout the need to write code for each new resource.</p>\n<p>You can test the API yourself in the open-source PaaS platform Cozystack,\nstarting from <a href=\"https://github.com/aenix-io/cozystack/releases/tag/v0.18.0\">version v0.18</a>.</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Gateway API v1.2: WebSockets, Timeouts, Retries, and More","url":"https://kubernetes.io/blog/2024/11/21/gateway-api-v1-2/","date":1732208400,"author":"","unread":true,"desc":"","content":"\n<p><img alt=\"Gateway API logo\" src=\"https://kubernetes.io/blog/2024/11/21/gateway-api-v1-2/gateway-api-logo.svg\"></p>\n<p>Kubernetes SIG Network is delighted to announce the general availability of\n<a href=\"https://gateway-api.sigs.k8s.io/\">Gateway API</a> v1.2! This version of the API\nwas released on October 3, and we're delighted to report that we now have a\nnumber of conformant implementations of it for you to try out.</p>\n<p>Gateway API v1.2 brings a number of new features to the <em>Standard channel</em>\n(Gateway API's GA release channel), introduces some new experimental features,\nand inaugurates our new release process â€” but it also brings two breaking\nchanges that you'll want to be careful of.</p>\n<h2 id=\"breaking-changes\">Breaking changes</h2>\n<h3 id=\"grpcroute-and-referencegrant-v1alpha2-removal\">GRPCRoute and ReferenceGrant <code>v1alpha2</code> removal</h3>\n<p>Now that the <code>v1</code> versions of GRPCRoute and ReferenceGrant have graduated to\nStandard, the old <code>v1alpha2</code> versions have been removed from both the Standard\nand Experimental channels, in order to ease the maintenance burden that\nperpetually supporting the old versions would place on the Gateway API\ncommunity.</p>\n<p>Before upgrading to Gateway API v1.2, you'll want to confirm that any\nimplementations of Gateway API have been upgraded to support the v1 API\nversion of these resources instead of the v1alpha2 API version. Note that even\nif you've been using v1 in your YAML manifests, a controller may still be\nusing v1alpha2 which would cause it to fail during this upgrade. Additionally,\nKubernetes itself goes to some effort to stop you from removing a CRD version\nthat it thinks you're using: check out the <a href=\"https://github.com/kubernetes-sigs/gateway-api/releases/tag/v1.2.0\">release notes</a> for more\ninformation about what you need to do to safely upgrade.</p>\n<h3 id=\"status-supported-features\">Change to <code>.status.supportedFeatures</code> (experimental)</h3>\n<p>A much smaller breaking change: <code>.status.supportedFeatures</code> in a Gateway is\nnow a list of objects instead of a list of strings. The objects have a single\n<code>name</code> field, so the translation from the strings is straightforward, but\nmoving to objects permits a lot more flexibility for the future. This stanza\nis not yet present in the Standard channel.</p>\n<h2 id=\"graduations-to-the-standard-channel\">Graduations to the standard channel</h2>\n<p>Gateway API 1.2.0 graduates four features to the Standard channel, meaning\nthat they can now be considered generally available. Inclusion in the Standard\nrelease channel denotes a high level of confidence in the API surface and\nprovides guarantees of backward compatibility. Of course, as with any other\nKubernetes API, Standard channel features can continue to evolve with\nbackward-compatible additions over time, and we certainly expect further\nrefinements and improvements to these new features in the future. For more\ninformation on how all of this works, refer to the <a href=\"https://gateway-api.sigs.k8s.io/concepts/versioning/\">Gateway API Versioning\nPolicy</a>.</p>\n<h3 id=\"httproute-timeouts\">HTTPRoute timeouts</h3>\n<p><a href=\"https://gateway-api.sigs.k8s.io/geps/gep-1742/\">GEP-1742</a> introduced the\n<code>timeouts</code> stanza into HTTPRoute, permitting configuring basic timeouts for\nHTTP traffic. This is a simple but important feature for proper resilience\nwhen handling HTTP traffic, and it is now Standard.</p>\n<p>For example, this HTTPRoute configuration sets a timeout of 300ms for traffic\nto the <code>/face</code> path:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>gateway.networking.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>HTTPRoute<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>face-with-timeouts<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>faces<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">parentRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>my-gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">rules</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">matches</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">path</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>PathPrefix<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">value</span>:<span style=\"color:#bbb\"> </span>/face<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backendRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>face<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">timeouts</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">request</span>:<span style=\"color:#bbb\"> </span>300ms<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>For more information, check out the <a href=\"https://gateway-api.sigs.k8s.io/guides/http-routing/\">HTTP routing</a> documentation. (Note that\nthis applies only to HTTPRoute timeouts. GRPCRoute timeouts are not yet part\nof Gateway API.)</p>\n<h3 id=\"gateway-infrastructure-labels-and-annotations\">Gateway infrastructure labels and annotations</h3>\n<p>Gateway API implementations are responsible for creating the backing\ninfrastructure needed to make each Gateway work. For example, implementations\nrunning in a Kubernetes cluster often create Services and Deployments, while\ncloud-based implementations may be creating cloud load balancer resources. In\nmany cases, it can be helpful to be able to propagate labels or annotations to\nthese generated resources.</p>\n<p>In v1.2.0, the Gateway <code>infrastructure</code> stanza moves to the Standard channel,\nallowing you to specify labels and annotations for the infrastructure created\nby the Gateway API controller. For example, if your Gateway infrastructure is\nrunning in-cluster, you can specify both Linkerd and Istio injection using the\nfollowing Gateway configuration, making it simpler for the infrastructure to\nbe incorporated into whichever service mesh you've installed:</p>\n<pre tabindex=\"0\"><code>apiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\nname: meshed-gateway\nnamespace: incoming\nspec:\ngatewayClassName: meshed-gateway-class\nlisteners:\n- name: http-listener\nprotocol: HTTP\nport: 80\ninfrastructure:\nlabels:\nistio-injection: enabled\nannotations:\nlinkerd.io/inject: enabled\n</code></pre><p>For more information, check out the\n<a href=\"https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.GatewayInfrastructure\"><code>infrastructure</code> API reference</a>.</p>\n<h3 id=\"backend-protocol-support\">Backend protocol support</h3>\n<p>Since Kubernetes v1.20, the Service and EndpointSlice resources have supported\na stable <code>appProtocol</code> field to allow users to specify the L7 protocol that\nService supports. With the adoption of\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-network/3726-standard-application-protocols\">KEP 3726</a>,\nKubernetes now supports three new <code>appProtocol</code> values:</p>\n<dl>\n<dt><code>kubernetes.io/h2c</code></dt>\n<dd>HTTP/2 over cleartext as described in <a href=\"https://www.rfc-editor.org/rfc/rfc7540\">RFC7540</a></dd>\n<dt><code>kubernetes.io/ws</code></dt>\n<dd>WebSocket over cleartext as described in <a href=\"https://www.rfc-editor.org/rfc/rfc6445\">RFC6445</a></dd>\n<dt><code>kubernetes.io/wss</code></dt>\n<dd>WebSocket over TLS as described in <a href=\"https://www.rfc-editor.org/rfc/rfc6445\">RFC6445</a></dd>\n</dl>\n<p>With Gateway API 1.2.0, support for honoring <code>appProtocol</code> is now Standard.\nFor example, given the following Service:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Service<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>websocket-service<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>my-namespace<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">selector</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">app.kubernetes.io/name</span>:<span style=\"color:#bbb\"> </span>websocket-app<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ports</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>http<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">targetPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">9376</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">protocol</span>:<span style=\"color:#bbb\"> </span>TCP<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">appProtocol</span>:<span style=\"color:#bbb\"> </span>kubernetes.io/ws<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>then an HTTPRoute that includes this Service as a <code>backendRef</code> will\nautomatically upgrade the connection to use WebSockets rather than assuming\nthat the connection is pure HTTP.</p>\n<p>For more information, check out\n<a href=\"https://gateway-api.sigs.k8s.io/geps/gep-1911/\">GEP-1911</a>.</p>\n<h2 id=\"new-additions-to-experimental-channel\">New additions to experimental channel</h2>\n<h3 id=\"named-rules-for-route-resources\">Named rules for *Route resources</h3>\n<p>The <code>rules</code> field in HTTPRoute and GRPCRoute resources can now be named, in\norder to make it easier to reference the specific rule, for example:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>gateway.networking.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>HTTPRoute<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>multi-color-route<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>faces<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">parentRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>my-gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">rules</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>center-rule<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">matches</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">path</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>PathPrefix<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">value</span>:<span style=\"color:#bbb\"> </span>/color/center<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backendRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>color-center<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>edge-rule<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">matches</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">path</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>PathPrefix<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">value</span>:<span style=\"color:#bbb\"> </span>/color/edge<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backendRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>color-edge<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Logging or status messages can now refer to these two rules as <code>center-rule</code>\nor <code>edge-rule</code> instead of being forced to refer to them by index. For more\ninformation, see <a href=\"https://gateway-api.sigs.k8s.io/geps/gep-995/\">GEP-995</a>.</p>\n<h3 id=\"httproute-retry-support\">HTTPRoute retry support</h3>\n<p>Gateway API 1.2.0 introduces experimental support for counted HTTPRoute\nretries. For example, the following HTTPRoute configuration retries requests\nto the <code>/face</code> path up to 3 times with a 500ms delay between retries:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>gateway.networking.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>HTTPRoute<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>face-with-retries<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>faces<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">parentRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>my-gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">rules</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">matches</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">path</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>PathPrefix<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">value</span>:<span style=\"color:#bbb\"> </span>/face<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backendRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>face<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">retry</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">codes</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#bbb\"> </span><span style=\"color:#666\">500</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#666\">502</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#666\">503</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#666\">504</span><span style=\"color:#bbb\"> </span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">attempts</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">3</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backoff</span>:<span style=\"color:#bbb\"> </span>500ms<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>For more information, check out <a href=\"https://gateway-api.sigs.k8s.io/geps/gep-1731\">GEP\n1731</a>.</p>\n<h3 id=\"httproute-percentage-based-mirroring\">HTTPRoute percentage-based mirroring</h3>\n<p>Gateway API has long supported the\n<a href=\"https://gateway-api.sigs.k8s.io/guides/http-request-mirroring/\">Request Mirroring</a>\nfeature, which allows sending the same request to multiple backends. In\nGateway API 1.2.0, we're introducing percentage-based mirroring, which allows\nyou to specify a percentage of requests to mirror to a different backend. For\nexample, the following HTTPRoute configuration mirrors 42% of requests to the\n<code>color-mirror</code> backend:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>gateway.networking.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>HTTPRoute<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>color-mirror-route<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>faces<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">parentRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>mirror-gateway<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">hostnames</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- mirror.example<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">rules</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">backendRefs</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>color<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">filters</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>RequestMirror<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requestMirror</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backendRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>color-mirror<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">percent</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">42</span><span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># This value must be an integer.</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>There's also a <code>fraction</code> stanza which can be used in place of <code>percent</code>, to\nallow for more precise control over exactly what amount of traffic is\nmirrored, for example:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>...<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">filters</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>RequestMirror<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requestMirror</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">backendRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>color-mirror<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fraction</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">numerator</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">denominator</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">10000</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>This configuration mirrors 1 in 10,000 requests to the <code>color-mirror</code> backend,\nwhich may be relevant with very high request rates. For more details, see\n<a href=\"https://gateway-api.sigs.k8s.io/geps/gep-3171\">GEP-1731</a>.</p>\n<h3 id=\"additional-backend-tls-configuration\">Additional backend TLS configuration</h3>\n<p>This release includes three additions related to TLS configuration for\ncommunications between a Gateway and a workload (a <em>backend</em>):</p>\n<ol>\n<li>\n<p><strong>A new <code>backendTLS</code> field on Gateway</strong></p>\n<p>This new field allows you to specify the client certificate that a Gateway\nshould use when connecting to backends.</p>\n</li>\n<li>\n<p><strong>A new <code>subjectAltNames</code> field on BackendTLSPolicy</strong></p>\n<p>Previously, the <code>hostname</code> field was used to configure both the SNI that a\nGateway should send to a backend <em>and</em> the identity that should be provided\nby a certificate. When the new <code>subjectAltNames</code> field is specified, any\ncertificate matching at least one of the specified SANs will be considered\nvalid. This is particularly critical for SPIFFE where URI-based SANs may\nnot be valid SNIs.</p>\n</li>\n<li>\n<p><strong>A new <code>options</code> field on BackendTLSPolicy</strong></p>\n<p>Similar to the TLS options field on Gateway Listeners, we believe the same\nconcept will be broadly useful for TLS-specific configuration for Backend\nTLS.</p>\n</li>\n</ol>\n<p>For more information, check out\n<a href=\"https://gateway-api.sigs.k8s.io/geps/gep-3155\">GEP-3135</a>.</p>\n<h2 id=\"more-changes\">More changes</h2>\n<p>For a full list of the changes included in this release, please refer to the\n<a href=\"https://github.com/kubernetes-sigs/gateway-api/releases/tag/v1.2.0\">v1.2.0 release notes</a>.</p>\n<h2 id=\"project-updates\">Project updates</h2>\n<p>Beyond the technical, the v1.2 release also marks a few milestones in the life\nof the Gateway API project itself.</p>\n<h3 id=\"release-process-improvements\">Release process improvements</h3>\n<p>Gateway API has never been intended to be a static API, and as more projects\nuse it as a component to build on, it's become clear that we need to bring\nsome more predictability to Gateway API releases. To that end, we're pleased -\nand a little nervous! - to announce that we've formalized a new release\nprocess:</p>\n<ul>\n<li>\n<p><strong>Scoping</strong> (4-6 weeks): maintainers and community determine the set of\nfeatures we want to include in the release. A particular emphasis here is\ngetting features <em>out</em> of the Experimental channel â€” ideally this involves\nmoving them to Standard, but it can also mean removing them.</p>\n</li>\n<li>\n<p><strong>GEP Iteration and Review</strong> (5-7 weeks): contributors write or update\nGateway Enhancement Proposals (GEPs) for features accepted into the release,\nwith emphasis on getting consensus around the design and graduation criteria\nof the feature.</p>\n</li>\n<li>\n<p><strong>API Refinement and Documentation</strong> (3-5 weeks): contributors implement the\nfeatures in the Gateway API controllers and write the necessary\ndocumentation.</p>\n</li>\n<li>\n<p><strong>SIG Network Review and Release Candidates</strong> (2-4 weeks): maintainers get\nthe required upstream review, build release candidates, and release the new\nversion.</p>\n</li>\n</ul>\n<p>Gateway API 1.2.0 was the first release to use the new process, and although\nthere are the usual rough edges of anything new, we believe that it went well.\nWe've already completed the Scoping phase for Gateway API 1.3, with the\nrelease expected around the end of January 2025.</p>\n<h3 id=\"gwctl-moves-out\"><code>gwctl</code> moves out</h3>\n<p>The <code>gwctl</code> CLI tool has moved into its very own repository,\n<a href=\"https://github.com/kubernetes-sigs/gwctl\">https://github.com/kubernetes-sigs/gwctl</a>. <code>gwctl</code> has proven a valuable tool\nfor the Gateway API community; moving it into its own repository will, we\nbelieve, make it easier to maintain and develop. As always, we welcome\ncontributions; while still experimental, <code>gwctl</code> already helps make working\nwith Gateway API a bit easier â€” especially for newcomers to the project!</p>\n<h3 id=\"maintainer-changes\">Maintainer changes</h3>\n<p>Rounding out our changes to the project itself, we're pleased to announce that\n<a href=\"https://github.com/mlavacca\">Mattia Lavacca</a> has joined the ranks of Gateway API Maintainers! We're also\nsad to announce that <a href=\"https://github.com/@keithmattix\">Keith Mattix</a> has stepped down as a GAMMA lead â€”\nhappily, <a href=\"https://github.com/@mikemorris\">Mike Morris</a> has returned to the role. We're grateful for everything\nKeith has done, and excited to have Mattia and Mike on board.</p>\n<h2 id=\"try-it-out\">Try it out</h2>\n<p>Unlike other Kubernetes APIs, you don't need to upgrade to the latest version of\nKubernetes to get the latest version of Gateway API. As long as you're running\nKubernetes 1.26 or later, you'll be able to get up and running with this\nversion of Gateway API.</p>\n<p>To try out the API, follow our <a href=\"https://gateway-api.sigs.k8s.io/guides/\">Getting Started\nGuide</a>. As of this writing, five\nimplementations are already conformant with Gateway API v1.2. In alphabetical\norder:</p>\n<ul>\n<li><a href=\"https://github.com/cilium/cilium\">Cilium v1.17.0-pre.1</a>, Experimental channel</li>\n<li><a href=\"https://github.com/envoyproxy/gateway\">Envoy Gateway v1.2.0-rc.1</a>, Experimental channel</li>\n<li><a href=\"https://istio.io\">Istio v1.24.0-alpha.0</a>, Experimental channel</li>\n<li><a href=\"https://github.com/kong/kubernetes-ingress-controller\">Kong v3.2.0-244-gea4944bb0</a>, Experimental channel</li>\n<li><a href=\"https://traefik.io\">Traefik v3.2</a>, Experimental channel</li>\n</ul>\n<h2 id=\"get-involved\">Get involved</h2>\n<p>There are lots of opportunities to get involved and help define the future of\nKubernetes routing APIs for both ingress and service mesh.</p>\n<ul>\n<li>Check out the <a href=\"https://gateway-api.sigs.k8s.io/guides\">user guides</a> to see what use-cases can be addressed.</li>\n<li>Try out one of the <a href=\"https://gateway-api.sigs.k8s.io/implementations/\">existing Gateway controllers</a>.</li>\n<li>Or <a href=\"https://gateway-api.sigs.k8s.io/contributing/\">join us in the community</a>\nand help us build the future of Gateway API together!</li>\n</ul>\n<p>The maintainers would like to thank <em>everyone</em> who's contributed to Gateway\nAPI, whether in the form of commits to the repo, discussion, ideas, or general\nsupport. We could never have gotten this far without the support of this\ndedicated and active community.</p>\n<h2 id=\"related-kubernetes-blog-articles\">Related Kubernetes blog articles</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/blog/2024/05/09/gateway-api-v1-1/\">Gateway API v1.1: Service mesh, GRPCRoute, and a whole lot more</a></li>\n<li><a href=\"https://kubernetes.io/blog/2023/11/28/gateway-api-ga/\">New Experimental Features in Gateway API v1.0</a>\n11/2023</li>\n<li><a href=\"https://kubernetes.io/blog/2023/10/31/gateway-api-ga/\">Gateway API v1.0: GA Release</a>\n10/2023</li>\n<li><a href=\"https://kubernetes.io/blog/2023/10/25/introducing-ingress2gateway/\">Introducing ingress2gateway; Simplifying Upgrades to Gateway API</a>\n10/2023</li>\n<li><a href=\"https://kubernetes.io/blog/2023/08/29/gateway-api-v0-8/\">Gateway API v0.8.0: Introducing Service Mesh Support</a>\n08/2023</li>\n</ul>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Kubernetes v1.32: Penelope","url":"https://kubernetes.io/blog/2024/12/11/kubernetes-v1-32-release/","date":1733875200,"author":"","unread":true,"desc":"","content":"\n<p><strong>Editors:</strong> Matteo Bianchi, Edith Puclla, William Rizzo, Ryota Sawada, Rashan Smith</p>\n<p>Announcing the release of Kubernetes v1.32: Penelope!</p>\n<p>In line with previous releases, the release of Kubernetes v1.32 introduces new stable, beta, and alpha features.\nThe consistent delivery of high-quality releases underscores the strength of our development cycle and the vibrant\nsupport from our community.\nThis release consists of 44 enhancements in total.\nOf those enhancements, 13 have graduated to Stable, 12 are entering Beta, and 19 have entered in Alpha.</p>\n<h2 id=\"release-theme-and-logo\">Release theme and logo</h2>\n<figure class=\"release-logo \">\n<img src=\"https://kubernetes.io/blog/2024/12/11/kubernetes-v1-32-release/k8s-1.32.png\"\nalt=\"Kubernetes v1.32 logo: Penelope from the Odyssey, a helm and a purple geometric background\"/>\n</figure>\n<p>The Kubernetes v1.32 Release Theme is &quot;Penelope&quot;.</p>\n<p>If Kubernetes is Ancient Greek for &quot;pilot&quot;, in this release we start from that origin\nand reflect on the last 10 years of Kubernetes and our accomplishments:\neach release cycle is a journey, and just like Penelope, in &quot;The Odyssey&quot;,<br>\nweaved for 10 years -- each night removing parts of what she had done during the day --\nso does each release add new features and removes others, albeit here with a much\nclearer purpose of constantly improving Kubernetes.\nWith v1.32 being the last release in the year Kubernetes marks its first decade anniversary,\nwe wanted to honour all of those that have been part of the global Kubernetes crew\nthat roams the cloud-native seas through perils and challanges:\nmay we continue to weave the future of Kubernetes together.</p>\n<h2 id=\"updates-to-recent-key-features\">Updates to recent key features</h2>\n<h3 id=\"a-note-on-dra-enhancements\">A note on DRA enhancements</h3>\n<p>In this release, like the previous one, the Kubernetes project continues proposing a number of enhancements to the\nDynamic Resource Allocation (DRA), a key component of the Kubernetes resource management system. These enhancements aim\nto improve the flexibility and efficiency of resource allocation for workloads that require specialized hardware, such\nas GPUs, FPGAs and network adapters.\nThese features are particularly useful for use-cases such as machine learning or high-performance computing\napplications. The core part enabling DRA Structured parameter support <a href=\"#structured-parameter-support\">got promoted to beta</a>.</p>\n<h3 id=\"quality-of-life-improvements-on-nodes-and-sidecar-containers-update\">Quality of life improvements on nodes and sidecar containers update</h3>\n<p><a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node</a> has the following highlights that go beyond\nKEPs:</p>\n<ol>\n<li>\n<p>The systemd watchdog capability is now used to restart the kubelet when its health check fails, while also limiting\nthe maximum number of restarts within a given time period. This enhances the reliability of the kubelet. For more\ndetails, see pull request <a href=\"https://github.com/kubernetes/kubernetes/pull/127566\">#127566</a>.</p>\n</li>\n<li>\n<p>In cases when an image pull back-off error is encountered, the message displayed in the Pod status has been improved\nto be more human-friendly and to indicate details about why the Pod is in this condition.\nWhen an image pull back-off occurs, the error is appended to the <code>status.containerStatuses[*].state.waiting.message</code>\nfield in the Pod specification with an <code>ImagePullBackOff</code> value in the <code>reason</code> field. This change provides you with\nmore context and helps you to identify the root cause of the issue. For more details, see pull request\n<a href=\"https://github.com/kubernetes/kubernetes/pull/127918\">#127918</a>.</p>\n</li>\n<li>\n<p>The sidecar containers feature is targeting graduation to Stable in v1.33. To view the remaining work items and\nfeedback from users, see comments in the issue\n<a href=\"https://github.com/kubernetes/enhancements/issues/753#issuecomment-2350136594\">#753</a>.</p>\n</li>\n</ol>\n<h2 id=\"highlights-of-features-graduating-to-stable\">Highlights of features graduating to Stable</h2>\n<p><em>This is a selection of some of the improvements that are now stable following the v1.32 release.</em></p>\n<h3 id=\"custom-resource-field-selectors\">Custom Resource field selectors</h3>\n<p>Custom resource field selector allows developers to add field selectors to custom resources, mirroring the functionality\navailable for built-in Kubernetes objects. This allows for more efficient and precise filtering of custom resources,\npromoting better API design practices.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4358\">KEP #4358</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-api-machinery\">SIG API\nMachinery</a>.</p>\n<h3 id=\"support-to-size-memory-backed-volumes\">Support to size memory backed volumes</h3>\n<p>This feature makes it possible to dynamically size memory-backed volumes based on Pod resource limits, improving the\nworkload's portability and overall node resource utilization.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/1967\">KEP #1967</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG\nNode</a>.</p>\n<h3 id=\"bound-service-account-token-improvement\">Bound service account token improvement</h3>\n<p>The inclusion of the node name in the service account token claims allows users to use such information during\nauthorization and admission (ValidatingAdmissionPolicy).\nFurthermore this improvement keeps service account credentials from being a privilege escalation path for nodes.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4193\">KEP #4193</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG\nAuth</a>.</p>\n<h3 id=\"structured-authorization-configuration\">Structured authorization configuration</h3>\n<p>Multiple authorizers can be configured in the API server to allow for structured authorization decisions,\nwith support for CEL match conditions in webhooks.\nThis work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/3221\">KEP #3221</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG\nAuth</a>.</p>\n<h3 id=\"auto-remove-pvcs-created-by-statefulset\">Auto remove PVCs created by StatefulSet</h3>\n<p>PersistentVolumeClaims (PVCs) created by StatefulSets get automatically deleted when no longer needed,\nwhile ensuring data persistence during StatefulSet updates and node maintenance.\nThis feature simplifies storage management for StatefulSets and reduces the risk of orphaned PVCs.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/1847\">KEP #1847</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-apps\">SIG\nApps</a>.</p>\n<h2 id=\"highlights-of-features-graduating-to-beta\">Highlights of features graduating to Beta</h2>\n<p><em>This is a selection of some of the improvements that are now beta following the v1.32 release.</em></p>\n<h3 id=\"job-api-managed-by-mechanism\">Job API managed-by mechanism</h3>\n<p>The <code>managedBy</code> field for Jobs was promoted to beta in the v1.32 release. This feature enables external controllers\n(like <a href=\"https://kueue.sigs.k8s.io/\">Kueue</a>) to manage Job synchronization, offering greater flexibility and integration\nwith advanced workload management systems.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4368\">KEP #4368</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-apps\">SIG\nApps</a>.</p>\n<h3 id=\"only-allow-anonymous-auth-for-configured-endpoints\">Only allow anonymous auth for configured endpoints</h3>\n<p>This feature lets admins specify which endpoints are allowed for anonymous requests. For example, the admin\ncan choose to only allow anonymous access to health endpoints like <code>/healthz</code>, <code>/livez</code>, and <code>/readyz</code> while\nmaking sure preventing anonymous access to other cluster endpoints or resources even if a user\nmisconfigures RBAC.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4633\">KEP #4633</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG\nAuth</a>.</p>\n<h3 id=\"per-plugin-callback-functions-for-accurate-requeueing-in-kube-scheduler-enhancements\">Per-plugin callback functions for accurate requeueing in kube-schedulerÂ enhancements</h3>\n<p>This feature enhances scheduling throughput with more efficient scheduling retry decisions by\nper-plugin callback functions (QueueingHint). All plugins now have QueueingHints.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4247\">KEP #4247</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG\nScheduling</a>.</p>\n<h3 id=\"recover-from-volume-expansion-failure\">Recover from volume expansion failure</h3>\n<p>This feature lets users recover from volume expansion failure by retrying with a smaller size. This enhancement ensures\nthat volume expansion is more resilient and reliable, reducing the risk of data loss or corruption during the process.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/1790\">KEP #1790</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">SIG\nStorage</a>.</p>\n<h3 id=\"volume-group-snapshot\">Volume group snapshot</h3>\n<p>This feature introduces a VolumeGroupSnapshot API, which lets users take a snapshot of multiple volumes together, ensuring data consistency across the volumes.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/3476\">KEP #3476</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">SIG\nStorage</a>.</p>\n<h3 id=\"structured-parameter-support\">Structured parameter support</h3>\n<p>The core part of Dynamic Resource Allocation (DRA), the structured parameter support, got promoted to beta.\nThis allows the kube-scheduler and Cluster Autoscaler to simulate claim allocation directly, without needing a\nthird-party driver.\nThese components can now predict whether resource requests can be fulfilled based on the cluster's current state without actually\ncommitting to the allocation. By eliminating the need for a third-party driver to validate or test allocations, this\nfeature improves planning and decision-making for resource distribution, making the scheduling and scaling processes\nmore efficient.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4381\">KEP #4381</a>, by WG Device\nManagement (a cross functional team containing <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a> and <a href=\"https://github.com/kubernetes/community/tree/master/sig-autoscaling\">SIG\nAutoscaling</a>).</p>\n<h3 id=\"label-and-field-selector-authorization\">Label and field selector authorization</h3>\n<p>Label and field selectors can be used in authorization decisions. The node authorizer\nautomatically takes advantage of this to limit nodes to list or watch their pods only.\nWebhook authorizers can be updated to limit requests based on the label or field selector used.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4601\">KEP #4601</a>\nby <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG Auth</a>.</p>\n<h2 id=\"highlights-of-new-features-in-alpha\">Highlights of new features in Alpha</h2>\n<p><em>This is a selection of key improvements introduced as alpha features in the v1.32 release.</em></p>\n<h3 id=\"asynchronous-preemption-in-the-kubernetes-scheduler\">Asynchronous preemption in theÂ Kubernetes Scheduler</h3>\n<p>The Kubernetes scheduler has been enhanced with Asynchronous Preemption, a feature that improves scheduling throughput\nby handling preemption operations asynchronously. Preemption ensures higher-priority pods get the resources they need by\nevicting lower-priority ones, but this process previously involved heavy operations like API calls to delete pods,\nslowing down the scheduler. With this enhancement, such tasks are now processed in parallel, allowing the scheduler to\ncontinue scheduling other pods without delays.\nThis improvement is particularly beneficial in clusters with high Pod churn or frequent scheduling failures, ensuring a\nmore efficient and resilient scheduling process.</p>\n<p>This work was done as a part of KEP <a href=\"https://github.com/kubernetes/enhancements/issues/4832\">#4832</a>\nby <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a>.</p>\n<h3 id=\"mutating-admission-policies-using-cel-expressions\">Mutating admission policies using CEL expressions</h3>\n<p>This feature leverages CEL's object instantiation and JSON Patch strategies, combined with Server Side Applyâ€™s merge\nalgorithms. It simplifies policy definition, reduces mutation conflicts, and enhances admission control performance\nwhile laying a foundation for more robust, extensible policy frameworks in Kubernetes.</p>\n<p>The Kubernetes API server now supports Common Expression Language (CEL)-based Mutating Admission Policies, providing a\nlightweight, efficient alternative to mutating admission webhooks. With this enhancement, administrators can use CEL to\ndeclare mutations like setting labels, defaulting fields, or injecting sidecars with simple, declarative expressions.\nThis approach reduces operational complexity, eliminates the need for webhooks, and integrates directly with the\nkube-apiserver, offering faster and more reliable in-process mutation handling.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/3962\">KEP #3962</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-api-machinery\">SIG API\nMachinery</a>.</p>\n<h3 id=\"pod-level-resource-specifications\">Pod-level resource specifications</h3>\n<p>This enhancement simplifies resource management in Kubernetes by introducing the ability to set resource requests and\nlimits at the Pod level, creating a shared pool that all containers in the Pod can dynamically use. This is particularly\nvaluable for workloads with containers that have fluctuating or bursty resource needs, as it minimizes over-provisioning\nand improves overall resource efficiency.</p>\n<p>By leveraging Linux cgroup settings at the Pod level, Kubernetes ensures that these resource limits are enforced while\nenabling tightly coupled containers to collaborate more effectively without hitting artificial constraints. Importantly,\nthis feature maintains backward compatibility with existing container-level resource settings, allowing users to adopt\nit incrementally without disrupting current workflows or existing configurations.</p>\n<p>This marks a significant improvement for multi-container pods, as it reduces the operational complexity of managing\nresource allocations across containers. It also provides a performance boost for tightly integrated applications, such\nas sidecar architectures, where containers share workloads or depend on each otherâ€™s availability to perform optimally.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/2837\">KEP #2837</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG\nNode</a>.</p>\n<h3 id=\"allow-zero-value-for-sleep-action-of-prestop-hook\">Allow zero value for sleep action of PreStop hook</h3>\n<p>This enhancement introduces the ability to set a zero-second sleep duration for the PreStop lifecycle hook in\nKubernetes, offering a more flexible and no-op option for resource validation and customization. Previously, attempting\nto define a zero value for the sleep action resulted in validation errors, restricting its use. With this update, users\ncan configure a zero-second duration as a valid sleep setting, enabling immediate execution and termination behaviors\nwhere needed.</p>\n<p>The enhancement is backward-compatible, introduced as an opt-in feature controlled by the\n<code>PodLifecycleSleepActionAllowZero</code> feature gate. This change is particularly beneficial for scenarios requiring PreStop\nhooks for validation or admission webhook processing without requiring an actual sleep duration. By aligning with the\ncapabilities of the <code>time.After</code> Go function, this update simplifies configuration and expands usability for Kubernetes\nworkloads.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4818\">KEP #4818</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG\nNode</a>.</p>\n<h3 id=\"dra-standardized-network-interface-data-for-resource-claim-status\">DRA: Standardized network interface data for resource claim status</h3>\n<p>This enhancement adds a new field that allows drivers to report specific device status data for each allocated object\nin a ResourceClaim. It also establishes a standardized way to represent networking devices information.</p>\n<p>This work was done as a part of\n<a href=\"https://github.com/kubernetes/enhancements/issues/4817\">KEP #4817</a>, by\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-network\">SIG Network</a>.</p>\n<h3 id=\"new-statusz-and-flagz-endpoints-for-core-components\">New statusz and flagz endpoints for core components</h3>\n<p>You can enable two new HTTP endpoints, <code>/statusz</code> and <code>/flagz</code>, for core components.\nThese enhance cluster debuggability by gaining insight into what versions (e.g. Golang version) that component is\nrunning as, along with details about its uptime, and which command line flags that component was executed with;\nmaking it easier to diagnose both runtime and configuration issues.</p>\n<p>This work was done as part of\n<a href=\"https://github.com/kubernetes/enhancements/issues/4827\">KEP #4827</a>\nand <a href=\"https://github.com/kubernetes/enhancements/issues/4828\">KEP #4828</a> by\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-instrumentation\">SIG Instrumentation</a>.</p>\n<h3 id=\"windows-strikes-back\">Windows strikes back!</h3>\n<p>Support for graceful shutdowns of Windows nodes in Kubernetes clusters has been added.\nBefore this release, Kubernetes provided graceful node shutdown functionality for Linux nodes\nbut lacked equivalent support for Windows. This enhancement enables the kubelet on Windows nodes to handle system\nshutdown events properly. Doing so, it ensures that Pods running on Windows nodes are gracefully terminated,\nallowing workloads to be rescheduled without disruption. This improvement enhances the reliability and stability\nof clusters that include Windows nodes, especially during a planned maintenance or any system updates.</p>\n<p>Moreover CPU and memory affinity support has been added for Windows nodes with nodes, with improvements\nto the CPU manager, memory manager and topology manager.</p>\n<p>This work was done respectively as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4802\">KEP #4802</a>\nand <a href=\"https://github.com/kubernetes/enhancements/issues/4885\">KEP #4885</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-windows\">SIG\nWindows</a>.</p>\n<h2 id=\"graduations-deprecations-and-removals-in-1-32\">Graduations, deprecations, and removals in 1.32</h2>\n<h3 id=\"graduations-to-stable\">Graduations to Stable</h3>\n<p>This lists all the features that graduated to stable (also known as <em>general availability</em>). For a full list of updates\nincluding new features and graduations from alpha to beta, see the release notes.</p>\n<p>This release includes a total of 13 enhancements promoted to Stable:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3221\">Structured Authorization Configuration</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4193\">Bound service account token improvements</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4358\">Custom Resource Field Selectors</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4420\">Retry Generate Name</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1860\">Make Kubernetes aware of the LoadBalancer behaviour</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2681\">Field <code>status.hostIPs</code> added for Pod</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4292\">Custom profile in kubectl debug</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1769\">Memory Manager</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1967\">Support to size memory backed volumes</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3545\">Improved multi-numa alignment in Topology Manager</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4026\">Add job creation timestamp to job annotations</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4017\">Add Pod Index Label for StatefulSets and Indexed Jobs</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1847\">Auto remove PVCs created by StatefulSet</a></li>\n</ul>\n<h3 id=\"deprecations-and-removals\">Deprecations and removals</h3>\n<p>As Kubernetes develops and matures, features may be deprecated, removed, or replaced with better ones for the project's\noverall health.\nSee the Kubernetes <a href=\"https://kubernetes.io/docs/reference/using-api/deprecation-policy/\">deprecation and removal policy</a> for more details on\nthis process.</p>\n<h4 id=\"withdrawal-of-the-old-dra-implementation\">Withdrawal of the old DRA implementation</h4>\n<p>The enhancement <a href=\"https://github.com/kubernetes/enhancements/issues/3063\">#3063</a> introduced Dynamic Resource Allocation\n(DRA) in Kubernetes 1.26.</p>\n<p>However, in Kubernetes v1.32, this approach to DRA will be significantly changed. Code related to the original\nimplementation will be removed, leaving KEP <a href=\"https://github.com/kubernetes/enhancements/issues/4381\">#4381</a> as the &quot;new&quot;\nbase functionality.</p>\n<p>The decision to change the existing approach originated from its incompatibility with cluster autoscaling as resource\navailability was non-transparent, complicating decision-making for both Cluster Autoscaler and controllers.\nThe newly added Structured Parameter model substitutes the functionality.</p>\n<p>This removal will allow Kubernetes to handle new hardware requirements and resource claims more predictably, bypassing\nthe complexities of back and forth API calls to the kube-apiserver.</p>\n<p>See the enhancement issue <a href=\"https://github.com/kubernetes/enhancements/issues/3063\">#3063</a> to find out more.</p>\n<h4 id=\"api-removals\">API removals</h4>\n<p>There is one API removal in <a href=\"https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-32\">Kubernetes v1.32</a>:</p>\n<ul>\n<li>The <code>flowcontrol.apiserver.k8s.io/v1beta3</code> API version of FlowSchema and PriorityLevelConfiguration has been removed.\nTo prepare for this, you can edit your existing manifests and rewrite client software to use the\n<code>flowcontrol.apiserver.k8s.io/v1 API</code> version, available since v1.29.\nAll existing persisted objects are accessible via the new API. Notable changes in flowcontrol.apiserver.k8s.io/v1beta3\ninclude that the PriorityLevelConfiguration <code>spec.limited.nominalConcurrencyShares</code> field only defaults to 30 when\nunspecified, and an explicit value of 0 is not changed to 30.</li>\n</ul>\n<p>For more information, refer to the <a href=\"https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-32\">API deprecation guide</a>.</p>\n<h3 id=\"release-notes-and-upgrade-actions-required\">Release notes and upgrade actions required</h3>\n<p>Check out the full details of the Kubernetes v1.32 release in our <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.32.md\">release\nnotes</a>.</p>\n<h2 id=\"availability\">Availability</h2>\n<p>Kubernetes v1.32 is available for download on <a href=\"https://github.com/kubernetes/kubernetes/releases/tag/v1.32.0\">GitHub</a> or\non the <a href=\"https://kubernetes.io/releases/download/\">Kubernetes download page</a>.</p>\n<p>To get started with Kubernetes, check out these <a href=\"https://kubernetes.io/docs/tutorials/\">interactive tutorials</a> or run local Kubernetes\nclusters using <a href=\"https://minikube.sigs.k8s.io/\">minikube</a>. You can also easily install v1.32 using\n<a href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\">kubeadm</a>.</p>\n<h2 id=\"release-team\">Release team</h2>\n<p>Kubernetes is only possible with the support, commitment, and hard work of its community.\nEach release team is made up of dedicated community volunteers who work together to build the many pieces that make up\nthe Kubernetes releases you rely on.\nThis requires the specialized skills of people from all corners of our community, from the code itself to its\ndocumentation and project management.</p>\n<p>We would like to thank the entire <a href=\"https://github.com/kubernetes/sig-release/blob/master/releases/release-1.32/release-team.md\">release\nteam</a> for the hours spent\nhard at work to deliver the Kubernetes v1.32 release to our community.\nThe Release Team's membership ranges from first-time shadows to returning team leads with experience forged over several\nrelease cycles.\nA very special thanks goes out our release lead, Frederico MuÃ±oz, for leading the release team so gracefully and handle\nany matter with the uttermost care, making sure this release was executed smoothly and efficiently.\nLast but not least a big thanks goes to all the release members - leads and shadows alike - and to the following SIGs\nfor the terrific work and outcome achieved during these 14 weeks of release work:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-docs\">SIG Docs</a> - for the fundamental support in docs and\nblog reviews and continous collaboration with release Comms and Docs;</li>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-k8s-infra\">SIG k8s Infra</a> and <a href=\"https://github.com/kubernetes/community/tree/master/sig-testing\">SIG\nTesting</a> - for the outstanding work in keeping the\ntesting framework in check, along with all the infra components necessary;</li>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-release\">SIG Release</a> and\nall the release managers - for the incredible support provided throughout the orchestration of the entire release,\naddressing even the most challenging issues in a graceful and timely manner.</li>\n</ul>\n<h2 id=\"project-velocity\">Project velocity</h2>\n<p>The CNCF K8s <a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&var-period=m&var-repogroup_name=All\">DevStats\nproject</a>\naggregates a number of interesting data points related to the velocity of Kubernetes and various sub-projects. This\nincludes everything from individual contributions to the number of companies that are contributing and is an\nillustration of the depth and breadth of effort that goes into evolving this ecosystem.</p>\n<p>In the v1.32 release cycle, which ran for 14 weeks (September 9th to December 11th), we saw contributions to Kubernetes\nfrom as many as 125 different companies and 559 individuals as of writing.</p>\n<p>In the whole Cloud Native ecosystem, the figure goes up to 433 companies counting 2441 total contributors. This sees an\nincrease of 7% more overall contributions compared to the <a href=\"https://kubernetes.io/blog/2024/08/13/kubernetes-v1-31-release/#project-velocity\">previous\nrelease</a> cycle, along with 14%\nincrease in the number of companies involved, showcasing strong interest and community behind the Cloud Native projects.</p>\n<p>Source for this data:</p>\n<ul>\n<li><a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&from=1725832800000&to=1733961599000&var-period=d28&var-repogroup_name=Kubernetes&var-repo_name=kubernetes%2Fkubernetes\">Companies contributing to\nKubernetes</a></li>\n<li><a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&from=1725832800000&to=1733961599000&var-period=d28&var-repogroup_name=All&var-repo_name=kubernetes%2Fkubernetes\">Overall ecosystem\ncontributions</a></li>\n</ul>\n<p>By contribution we mean when someone makes a commit, code review, comment, creates an issue or PR, reviews a PR\n(including blogs and documentation) or comments on issues and PRs.</p>\n<p>If you are interested in contributing visit <a href=\"https://www.kubernetes.dev/docs/guide/#getting-started\">Getting Started</a> on\nour contributor website.</p>\n<p><a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&var-period=m&var-repogroup_name=All\">Check out\nDevStats</a>\nto learn more about the overall velocity of the Kubernetes project and community.</p>\n<h2 id=\"event-updates\">Event updates</h2>\n<p>Explore the upcoming Kubernetes and cloud-native events from March to June 2025, featuring KubeCon and KCD Stay informed\nand engage with the Kubernetes community.</p>\n<p><strong>March 2025</strong></p>\n<ul>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Beijing, China</strong></a>: In March | Beijing, China</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Guadalajara, Mexico</strong></a>: March 16, 2025 | Guadalajara,\nMexico</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Rio de Janeiro, Brazil</strong></a>: March 22, 2025 | Rio de\nJaneiro, Brazil</li>\n</ul>\n<p><strong>April 2025</strong></p>\n<ul>\n<li><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-europe\"><strong>KubeCon + CloudNativeCon Europe 2025</strong></a>: April\n1-4, 2025 | London, United Kingdom</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Budapest, Hungary</strong></a>: April 23, 2025 | Budapest,\nHungary</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Chennai, India</strong></a>: April 26, 2025 | Chennai, India</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Auckland, New Zealand</strong></a>: April 28, 2025 | Auckland,\nNew Zealand</li>\n</ul>\n<p><strong>May 2025</strong></p>\n<ul>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Helsinki, Finland</strong></a>: May 6, 2025 | Helsinki, Finland</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: San Francisco, USA</strong></a>: May 8, 2025 | San Francisco, USA</li>\n<li><a href=\"https://community.cncf.io/events/details/cncf-kcd-texas-presents-kcd-texas-austin-2025/\"><strong>KCD - Kubernetes Community Days: Austin,\nUSA</strong></a>: May 15, 2025 | Austin,\nUSA</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Seoul, South Korea</strong></a>: May 22, 2025 | Seoul, South\nKorea</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Istanbul, Turkey</strong></a>: May 23, 2025 | Istanbul, Turkey</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Heredia, Costa Rica</strong></a>: May 31, 2025 | Heredia, Costa\nRica</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: New York, USA</strong></a>: In May | New York, USA</li>\n</ul>\n<p><strong>June 2025</strong></p>\n<ul>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Bratislava, Slovakia</strong></a>: June 5, 2025 | Bratislava,\nSlovakia</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Bangalore, India</strong></a>: June 6, 2025 | Bangalore, India</li>\n<li><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-china/\"><strong>KubeCon + CloudNativeCon China 2025</strong></a>: June\n10-11, 2025 | Hong Kong</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Antigua Guatemala, Guatemala</strong></a>: June 14, 2025 |\nAntigua Guatemala, Guatemala</li>\n<li><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-japan\"><strong>KubeCon + CloudNativeCon Japan 2025</strong></a>: June\n16-17, 2025 | Tokyo, Japan</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Nigeria, Africa</strong></a>: June 19, 2025 | Nigeria, Africa</li>\n</ul>\n<h2 id=\"upcoming-release-webinar\">Upcoming release webinar</h2>\n<p>Join members of the Kubernetes v1.32 release team on <strong>Thursday, January 9th 2025 at 5:00 PM (UTC)</strong>, to learn about the\nrelease highlights of this release, as well as deprecations and removals to help plan for upgrades.\nFor more information and registration, visit the <a href=\"https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-live-webinar-kubernetes-132-release/\">event\npage</a>\non the CNCF Online Programs site.</p>\n<h2 id=\"get-involved\">Get involved</h2>\n<p>The simplest way to get involved with Kubernetes is by joining one of the many <a href=\"https://www.kubernetes.dev/community/community-groups/#special-interest-groups\">Special Interest\nGroups</a> (SIGs) that align with your\ninterests.\nHave something youâ€™d like to broadcast to the Kubernetes community?\nShare your voice at our weekly <a href=\"https://github.com/kubernetes/community/tree/master/communication\">community meeting</a>,\nand through the channels below.\nThank you for your continued feedback and support.</p>\n<ul>\n<li>Follow us on Bluesky <a href=\"https://bsky.app/profile/did:plc:kyg4uikmq7lzpb76ugvxa6ul\">@Kubernetes.io</a> for latest updates</li>\n<li>Join the community discussion on <a href=\"https://discuss.kubernetes.io/\">Discuss</a></li>\n<li>Join the community on <a href=\"http://slack.k8s.io/\">Slack</a></li>\n<li>Post questions (or answer questions) on <a href=\"http://stackoverflow.com/questions/tagged/kubernetes\">Stack Overflow</a></li>\n<li>Share your Kubernetes\n<a href=\"https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform\">story</a></li>\n<li>Read more about whatâ€™s happening with Kubernetes on the <a href=\"https://kubernetes.io/blog/\">blog</a></li>\n<li>Learn more about the <a href=\"https://github.com/kubernetes/sig-release/tree/master/release-team\">Kubernetes Release Team</a></li>\n</ul>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Kubernetes v1.32: QueueingHint Brings a New Possibility to Optimize Pod Scheduling","url":"https://kubernetes.io/blog/2024/12/12/scheduler-queueinghint/","date":1733961600,"author":"","unread":true,"desc":"","content":"\n<p>The Kubernetes <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/\">scheduler</a> is the core\ncomponent that selects the nodes on which new Pods run. The scheduler processes\nthese new Pods <strong>one by one</strong>. Therefore, the larger your clusters, the more important\nthe throughput of the scheduler becomes.</p>\n<p>Over the years, Kubernetes SIG Scheduling has improved the throughput\nof the scheduler in multiple enhancements. This blog post describes a major improvement to the\nscheduler in Kubernetes v1.32: a\n<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/#extension-points\">scheduling context element</a>\nnamed <em>QueueingHint</em>. This page provides background knowledge of the scheduler and explains how\nQueueingHint improves scheduling throughput.</p>\n<h2 id=\"scheduling-queue\">Scheduling queue</h2>\n<p>The scheduler stores all unscheduled Pods in an internal component called the <em>scheduling queue</em>.</p>\n<p>The scheduling queue consists of the following data structures:</p>\n<ul>\n<li><strong>ActiveQ</strong>: holds newly created Pods or Pods that are ready to be retried for scheduling.</li>\n<li><strong>BackoffQ</strong>: holds Pods that are ready to be retried but are waiting for a backoff period to end. The\nbackoff period depends on the number of unsuccessful scheduling attempts performed by the scheduler on that Pod.</li>\n<li><strong>Unschedulable Pod Pool</strong>: holds Pods that the scheduler won't attempt to schedule for one of the\nfollowing reasons:\n<ul>\n<li>The scheduler previously attempted and was unable to schedule the Pods. Since that attempt, the cluster\nhasn't changed in a way that could make those Pods schedulable.</li>\n<li>The Pods are blocked from entering the scheduling cycles by PreEnqueue Plugins,\nfor example, they have a <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-scheduling-readiness/#configuring-pod-schedulinggates\">scheduling gate</a>,\nand get blocked by the scheduling gate plugin.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"scheduling-framework-and-plugins\">Scheduling framework and plugins</h2>\n<p>The Kubernetes scheduler is implemented following the Kubernetes\n<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/\">scheduling framework</a>.</p>\n<p>And, all scheduling features are implemented as plugins\n(e.g., <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\">Pod affinity</a>\nis implemented in the <code>InterPodAffinity</code> plugin.)</p>\n<p>The scheduler processes pending Pods in phases called <em>cycles</em> as follows:</p>\n<ol>\n<li>\n<p><strong>Scheduling cycle</strong>: the scheduler takes pending Pods from the activeQ component of the scheduling\nqueue <em>one by one</em>. For each Pod, the scheduler runs the filtering/scoring logic from every scheduling plugin. The\nscheduler then decides on the best node for the Pod, or decides that the Pod can't be scheduled at that time.</p>\n<p>If the scheduler decides that a Pod can't be scheduled, that Pod enters the Unschedulable Pod Pool\ncomponent of the scheduling queue. However, if the scheduler decides to place the Pod on a node,\nthe Pod goes to the binding cycle.</p>\n</li>\n<li>\n<p><strong>Binding cycle</strong>: the scheduler communicates the node placement decision to the Kubernetes API\nserver. This operation bounds the Pod to the selected node.</p>\n</li>\n</ol>\n<p>Aside from some exceptions, most unscheduled Pods enter the unschedulable pod pool after each scheduling\ncycle. The Unschedulable Pod Pool component is crucial because of how the scheduling cycle processes Pods one by one. If the scheduler had to constantly retry placing unschedulable Pods, instead of offloading those\nPods to the Unschedulable Pod Pool, multiple scheduling cycles would be wasted on those Pods.</p>\n<h2 id=\"improvements-to-retrying-pod-scheduling-with-queuinghint\">Improvements to retrying Pod scheduling with QueuingHint</h2>\n<p>Unschedulable Pods only move back into the ActiveQ or BackoffQ components of the scheduling\nqueue if changes in the cluster might allow the scheduler to place those Pods on nodes.</p>\n<p>Prior to v1.32, each plugin registered which cluster changes could solve their failures, an object creation, update, or deletion in the cluster (called <em>cluster events</em>),\nwith <code>EnqueueExtensions</code> (<code>EventsToRegister</code>),\nand the scheduling queue retries a pod with an event that is registered by a plugin that rejected the pod in a previous scheduling cycle.</p>\n<p>Additionally, we had an internal feature called <code>preCheck</code>, which helped further filtering of events for efficiency, based on Kubernetes core scheduling constraints;\nFor example, <code>preCheck</code> could filter out node-related events when the node status is <code>NotReady</code>.</p>\n<p>However, we had two issues for those approaches:</p>\n<ul>\n<li>Requeueing with events was too broad, could lead to scheduling retries for no reason.\n<ul>\n<li>A new scheduled Pod <em>might</em> solve the <code>InterPodAffinity</code>'s failure, but not all of them do.\nFor example, if a new Pod is created, but without a label matching <code>InterPodAffinity</code> of the unschedulable pod, the pod wouldn't be schedulable.</li>\n</ul>\n</li>\n<li><code>preCheck</code> relied on the logic of in-tree plugins and was not extensible to custom plugins,\nlike in issue <a href=\"https://github.com/kubernetes/kubernetes/issues/110175\">#110175</a>.</li>\n</ul>\n<p>Here QueueingHints come into play;\na QueueingHint subscribes to a particular kind of cluster event, and make a decision about whether each incoming event could make the Pod schedulable.</p>\n<p>For example, consider a Pod named <code>pod-a</code> that has a required Pod affinity. <code>pod-a</code> was rejected in\nthe scheduling cycle by the <code>InterPodAffinity</code> plugin because no node had an existing Pod that matched\nthe Pod affinity specification for <code>pod-a</code>.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2024/12/12/scheduler-queueinghint/queueinghint1.svg\"\nalt=\"A diagram showing the scheduling queue and pod-a rejected by InterPodAffinity plugin\"/> <figcaption>\n<p>A diagram showing the scheduling queue and pod-a rejected by InterPodAffinity plugin</p>\n</figcaption>\n</figure>\n<p><code>pod-a</code> moves into the Unschedulable Pod Pool. The scheduling queue records which plugin caused\nthe scheduling failure for the Pod. For <code>pod-a</code>, the scheduling queue records that the <code>InterPodAffinity</code>\nplugin rejected the Pod.</p>\n<p><code>pod-a</code> will never be schedulable until the InterPodAffinity failure is resolved.\nThere're some scenarios that the failure could be resolved, one example is an existing running pod gets a label update and becomes matching a Pod affinity.\nFor this scenario, the <code>InterPodAffinity</code> plugin's <code>QueuingHint</code> callback function checks every Pod label update that occurs in the cluster.\nThen, if a Pod gets a label update that matches the Pod affinity requirement of <code>pod-a</code>, the <code>InterPodAffinity</code>,\nplugin's <code>QueuingHint</code> prompts the scheduling queue to move <code>pod-a</code> back into the ActiveQ or\nthe BackoffQ component.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2024/12/12/scheduler-queueinghint/queueinghint2.svg\"\nalt=\"A diagram showing the scheduling queue and pod-a being moved by InterPodAffinity QueueingHint\"/> <figcaption>\n<p>A diagram showing the scheduling queue and pod-a being moved by InterPodAffinity QueueingHint</p>\n</figcaption>\n</figure>\n<h2 id=\"queueinghint-s-history-and-what-s-new-in-v1-32\">QueueingHint's history and what's new in v1.32</h2>\n<p>At SIG Scheduling, we have been working on the development of QueueingHint since\nKubernetes v1.28.</p>\n<p>While QueuingHint isn't user-facing, we implemented the <code>SchedulerQueueingHints</code> feature gate as a\nsafety measure when we originally added this feature. In v1.28, we implemented QueueingHints with a\nfew in-tree plugins experimentally, and made the feature gate enabled by default.</p>\n<p>However, users reported a memory leak, and consequently we disabled the feature gate in a\npatch release of v1.28. From v1.28 until v1.31, we kept working on the QueueingHint implementation\nwithin the rest of the in-tree plugins and fixing bugs.</p>\n<p>In v1.32, we made this feature enabled by default again. We finished implementing QueueingHints\nin all plugins and also identified the cause of the memory leak!</p>\n<p>We thank all the contributors who participated in the development of this feature and those who reported and investigated the earlier issues.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>These features are managed by Kubernetes <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a>.</p>\n<p>Please join us and share your feedback.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/4247-queueinghint/README.md\">KEP-4247: Per-plugin callback functions for efficient requeueing in the scheduling queue</a></li>\n</ul>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Kubernetes v1.32: Memory Manager Goes GA","url":"https://kubernetes.io/blog/2024/12/13/memory-manager-goes-ga/","date":1734048000,"author":"","unread":true,"desc":"","content":"\n<p>With Kubernetes 1.32, the memory manager has officially graduated to General Availability (GA),\nmarking a significant milestone in the journey toward efficient and predictable memory allocation for containerized applications.\nSince Kubernetes v1.22, where it graduated to beta, the memory manager has proved itself reliable, stable and a good complementary feature for the\n<a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/\">CPU Manager</a>.</p>\n<p>As part of kubelet's workload admission process,\nthe memory manager provides topology hints\nto optimize memory allocation and alignment.\nThis enables users to allocate exclusive\nmemory for Pods in the <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/#guaranteed\">Guaranteed</a> QoS class.\nMore details about the process can be found in the memory manager goes to beta <a href=\"https://kubernetes.io/blog/2021/08/11/kubernetes-1-22-feature-memory-manager-moves-to-beta/\">blog</a>.</p>\n<p>Most of the changes introduced since the Beta are bug fixes, internal refactoring and\nobservability improvements, such as metrics and better logging.</p>\n<h2 id=\"observability-improvements\">Observability improvements</h2>\n<p>As part of the effort\nto increase the observability of memory manager, new metrics have been added\nto provide some statistics on memory allocation patterns.</p>\n<ul>\n<li>\n<p><strong>memory_manager_pinning_requests_total</strong> -\ntracks the number of times the pod spec required the memory manager to pin memory pages.</p>\n</li>\n<li>\n<p><strong>memory_manager_pinning_errors_total</strong> -\ntracks the number of times the pod spec required the memory manager\nto pin memory pages, but the allocation failed.</p>\n</li>\n</ul>\n<h2 id=\"improving-memory-manager-reliability-and-consistency\">Improving memory manager reliability and consistency</h2>\n<p>The kubelet does not guarantee pod ordering\nwhen admitting pods after a restart or reboot.</p>\n<p>In certain edge cases, this behavior could cause\nthe memory manager to reject some pods,\nand in more extreme cases, it may cause kubelet to fail upon restart.</p>\n<p>Previously, the beta implementation lacked certain checks and logic to prevent\nthese issues.</p>\n<p>To stabilize the memory manager for general availability (GA) readiness,\nsmall but critical refinements have been\nmade to the algorithm, improving its robustness and handling of edge cases.</p>\n<h2 id=\"future-development\">Future development</h2>\n<p>There is more to come for the future of Topology Manager in general,\nand memory manager in particular.\nNotably, ongoing efforts are underway\nto extend <a href=\"https://github.com/kubernetes/kubernetes/pull/128560\">memory manager support to Windows</a>,\nenabling CPU and memory affinity on a Windows operating system.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>This feature is driven by the <a href=\"https://github.com/Kubernetes/community/blob/master/sig-node/README.md\">SIG Node</a> community.\nPlease join us to connect with the community\nand share your ideas and feedback around the above feature and\nbeyond.\nWe look forward to hearing from you!</p>","flags":null,"enclosureUrl":"","enclosureMime":""}]}