{"id":"6C2W1azD1rBrcTRY3HU8boSx83NbkHKLjCRzRoNgHM1f9rDLzUhN2yx","title":"MLOps.community","displayTitle":"Podcast - MLOps","url":"https://anchor.fm/s/174cb1b8/podcast/rss","feedLink":"https://mlops.community/","items":[{"title":"Unleashing Unconstrained News Knowledge Graphs to Combat Misinformation // Robert Caulk // #279","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Unleashing-Unconstrained-News-Knowledge-Graphs-to-Combat-Misinformation--Robert-Caulk--279-e2sis0d","date":1734712634,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p><em></em><a href=\"https://www.linkedin.com/in/rcaulk/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Robert Caulk</em></a> is responsible for directing software development, enabling research, coordinating company projects, quality control, proposing external collaborations, and securing funding. He believes firmly in open-source, having spent 12 years accruing over 1000 academic citations building open-source software in domains such as machine learning, image analysis, and coupled physical processes. He received his Ph.D. from Université Grenoble Alpes, France, in computational mechanics.\n\nUnleashing Unconstrained News Knowledge Graphs to Combat Misinformation // MLOps Podcast #279 with Robert Caulk, Founder of Emergent Methods.\n\n// Abstract\nIndexing hundreds of thousands of news articles per day into a knowledge graph (KG) was previously impossible due to the strict requirement that high-level reasoning, general world knowledge, and full-text context *must* be present for proper KG construction.\n\nThe latest tools now enable such general world knowledge and reasoning to be applied cost effectively to high-volumes of news articles. Beyond the low cost of processing these news articles, these tools are also opening up a new, controversial, approach to KG building - unconstrained KGs. \n\nWe discuss the construction and exploration of the largest news-knowledge-graph on the planet - hosted on an endpoint at AskNews.app. During talk we aim to highlight some of the sacrifices and benefits that go hand-in-hand with using the infamous unconstrained KG approach.\n\nWe conclude the talk by explaining how knowledge graphs like these help to mitigate misinformation. We provide some examples of how our clients are using this graph, such as generating sports forecasts, generating better social media posts, generating regional security alerts, and combating human trafficking.\n\n// Bio\nRobert is the founder of Emergent Methods, where he directs research and software development for large-scale applications. He is currently overseeing the structuring of hundreds of thousands of news articles per day in order to build the best news retrieval API in the world: https://asknews.app. \n\n// MLOps Swag/Merch</p>\n<p><a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\nWebsite: <a href=\"https://emergentmethods.ai\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://emergentmethods.ai</a></p>\n<p>News Retrieval API: <a href=\"https://asknews.app\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://asknews.app</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Rob on LinkedIn: <a href=\"https://www.linkedin.com/in/rcaulk/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/rcaulk/</a>\n\n</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/96087501/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-20%2F391880580-44100-2-d57545176debf.mp3","enclosureMime":""},{"title":"Domino: Communication-Free LLM Training Engine // Guanhua Wang // #278","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Domino-Communication-Free-LLM-Training-Engine--Guanhua-Wang--278-e2sebhr","date":1734455373,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p><a href=\"https://www.linkedin.com/in/guanhua-wang/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Guanhua Wang</em></a> is <em>a Senior Researcher</em> in DeepSpeed Team at <em>Microsoft</em>. Before <em>Microsoft</em>, Guanhua earned his Computer Science PhD from UC Berkeley.\n\nDomino: Communication-Free LLM Training Engine // MLOps Podcast #278 with Guanhua \"Alex\" Wang, Senior Researcher at Microsoft.\n\n// Abstract\nGiven the popularity of generative AI, Large Language Models (LLMs) often consume hundreds or thousands of GPUs to parallelize and accelerate the training process. Communication overhead becomes more pronounced when training LLMs at scale. To eliminate communication overhead in distributed LLM training, we propose Domino, which provides a generic scheme to hide communication behind computation. By breaking the data dependency of a single batch training into smaller independent pieces, Domino pipelines these independent pieces of training and provides a generic strategy of fine-grained communication and computation overlapping. Extensive results show that compared with Megatron-LM, Domino achieves up to 1.3x speedup for LLM training on Nvidia DGX-H100 GPUs.\n\n// Bio\nGuanhua Wang is a Senior Researcher in the DeepSpeed team at Microsoft. His research focuses on large-scale LLM training and serving. Previously, he led the ZeRO++ project at Microsoft which helped reduce over half of model training time inside Microsoft and Linkedin. He also led and was a major contributor to Microsoft Phi-3 model training. He holds a CS PhD from UC Berkeley advised by Prof Ion Stoica. \n\n// MLOps Swag/Merch\n<a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\nWebsite: <a href=\"https://guanhuawang.github.io/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://guanhuawang.github.io/</a>\nDeepSpeed hiring: <a href=\"https://www.microsoft.com/en-us/research/project/deepspeed/opportunities/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.microsoft.com/en-us/research/project/deepspeed/opportunities/</a></p>\n<p>Large Model Training and Inference with DeepSpeed // Samyam Rajbhandari // LLMs in Prod Conference: <a href=\"https://youtu.be/cntxC3g22oU\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://youtu.be/cntxC3g22oU</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Guanhua on LinkedIn: <a href=\"https://www.linkedin.com/in/guanhua-wang/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/guanhua-wang/</a>\n\nTimestamps:\n[00:00] Guanhua's preferred coffee\n[00:17] Takeaways\n[01:36] Please like, share, leave a review, and subscribe to our MLOps channels!\n[01:47] Phi model explanation\n[06:29] Small Language Models optimization challenges\n[07:29] DeepSpeed overview and benefits\n[10:58] Crazy unimplemented crazy AI ideas\n[17:15] Post training vs QAT\n[19:44] Quantization over distillation\n[24:15] Using Lauras \n[27:04] LLM scaling sweet spot\n[28:28] Quantization techniques\n[32:38] Domino overview\n[38:02] Training performance benchmark\n[42:44] Data dependency-breaking strategies\n[49:14] Wrap up</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/95939579/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-17%2F391693039-44100-2-29c2d2f312cdf.mp3","enclosureMime":""},{"title":"AI's Next Frontier // Aditya Naganath // #277","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/AIs-Next-Frontier--Aditya-Naganath--277-e2s5j88","date":1733912098,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p>Thanks to the High Signal Podcast by Delphina: \n<a href=\"https://go.mlops.community/HighSignalPodcast\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/HighSignalPodcast</a></p>\n<p><a href=\"https://www.linkedin.com/in/aditya-naganath/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Aditya Naganath</em></a> is an experienced investor currently working with <a href=\"https://www.kleinerperkins.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Kleiner Perkins</em></a>. He has a passion for connecting with people over coffee and discussing various topics related to tech, products, ideas, and markets.\n</p>\n<p>AI's Next Frontier // MLOps Podcast #277 with Aditya Naganath, Principal at Kleiner Perkins.\n\n// Abstract\nLLMs have ushered in an unmistakable supercycle in the world of technology. The low-hanging use cases have largely been picked off. The next frontier will be AI coworkers who sit alongside knowledge workers, doing work side by side. At the infrastructure level, one of the most important primitives invented by man - the data center, is being fundamentally rethought in this new wave.\n\n// Bio\nAditya Naganath joined Kleiner Perkins’ investment team in 2022 with a focus on artificial intelligence, enterprise software applications, infrastructure and security. Prior to joining Kleiner Perkins, Aditya was a product manager at Google focusing on growth initiatives for the next billion users team. He previously was a technical lead at Palantir Technologies and formerly held software engineering roles at Twitter and Nextdoor, where he was a Kleiner Perkins fellow. Aditya earned a patent during his time at Twitter for a technical analytics product he co-created.\n\nOriginally from Mumbai India, Aditya graduated magna cum laude from Columbia University with a bachelor’s degree in Computer Science, and an MBA from Stanford University. Outside of work, you can find him playing guitar with a hard rock band, competing in chess or on the squash courts, and fostering puppies. He is also an avid poker player.\n\n// MLOps Swag/Merch\n<a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\nFaith's Hymn by Beautiful Chorus: ⁠<a href=\"https://open.spotify.com/track/1bDv6grQB5ohVFI8UDGvKK?si=4b00752eaa96413b\" target=\"_blank\" rel=\"ugc noopener noreferrer\">⁠https://open.spotify.com/track/1bDv6grQB5ohVFI8UDGvKK?si=4b00752eaa96413b⁠</a>⁠ Substack: ⁠<a href=\"https://adityanaganath.substack.com/?utm_source=substack&amp;utm_medium=web&amp;utm_campaign=substack_profile\" target=\"_blank\" rel=\"ugc noopener noreferrer\">⁠https://adityanaganath.substack.com/?utm_source=substack&amp;utm_medium=web&amp;utm_campaign=substack_profile⁠</a>⁠<br />With thanks to the High Signal Podcast by Delphina: <a href=\"https://go.mlops.community/HighSignalPodcast\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/HighSignalPodcast</a><br />Building the Future of AI in Software Development // Varun Mohan // MLOps Podcast #195 - ⁠<a href=\"https://youtu.be/1DJKq8StuTo\" target=\"_blank\" rel=\"ugc noopener noreferrer\">⁠https://youtu.be/1DJKq8StuTo⁠</a>⁠<br />Do Re MI for Training Metrics: Start at the Beginning // Todd Underwood // AIQCON - ⁠<a href=\"https://youtu.be/DxyOlRdCofo\" target=\"_blank\" rel=\"ugc noopener noreferrer\">⁠https://youtu.be/DxyOlRdCofo</a>\n\n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Aditya on LinkedIn: <a href=\"https://www.linkedin.com/in/aditya-naganath/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/aditya-naganath/</a></p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/95652552/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-11%2F391388417-44100-2-7174d356c87e7.mp3","enclosureMime":""},{"title":"PyTorch for Control Systems and Decision Making // Vincent Moens // #276","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/PyTorch-for-Control-Systems-and-Decision-Making--Vincent-Moens--276-e2rr6qq","date":1733278694,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p>Dr <a href=\"https://www.linkedin.com/in/mvi/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Vincent Moens</em></a> is an Applied Machine Learning <em>Research</em> Scientist at <em>Meta</em> and an author of <a href=\"https://github.com/pytorch/rl\" target=\"_blank\" rel=\"ugc noopener noreferrer\">TorchRL</a> and <a href=\"https://github.com/pytorch/tensordict\" target=\"_blank\" rel=\"ugc noopener noreferrer\">TensorDict</a> in Pytorch.\n\nPyTorch for Control Systems and Decision Making // MLOps Podcast #276 with Vincent Moens, Research Engineer at Meta.\n\n// Abstract\nPyTorch is widely adopted across the machine learning community for its flexibility and ease of use in applications such as computer vision and natural language processing. However, supporting reinforcement learning, decision-making, and control communities is equally crucial, as these fields drive innovation in areas like robotics, autonomous systems, and game-playing. This podcast explores the intersection of PyTorch and these fields, covering practical tips and tricks for working with PyTorch, an in-depth look at TorchRL, and discussions on debugging techniques, optimization strategies, and testing frameworks. By examining these topics, listeners will understand how to effectively use PyTorch for control systems and decision-making applications.\n\n// Bio\nVincent Moens is a research engineer on the PyTorch core team at Meta, based in London. As the maintainer of TorchRL (<a href=\"https://github.com/pytorch/rl\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/pytorch/rl</a>) and TensorDict (<a href=\"https://github.com/pytorch/tensordict\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/pytorch/tensordict</a>), Vincent plays a key role in supporting the decision-making community within the PyTorch ecosystem. \n\nAlongside his technical role in the PyTorch community, Vincent also actively contributes to AI-related research projects.\n\nBefore joining Meta, Vincent worked as an ML researcher at Huawei and AIG. \n\nVincent holds a Medical Degree and a PhD in Computational Neuroscience.\n\n// MLOps Swag/Merch\n<a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links</p>\n<p>Musical recommendation: <a href=\"https://open.spotify.com/artist/1Uff91EOsvd99rtAupatMP?si=jVkoFiq8Tmq0fqK_OIEglg\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://open.spotify.com/artist/1Uff91EOsvd99rtAupatMP?si=jVkoFiq8Tmq0fqK_OIEglg</a>\nWebsite: <a href=\"github.com/vmoens\" target=\"_blank\" rel=\"ugc noopener noreferrer\">github.com/vmoens</a>\nTorchRL: <a href=\"https://github.com/pytorch/rl\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/pytorch/rl</a>\nTensorDict: <a href=\"https://github.com/pytorch/tensordict\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/pytorch/tensordict</a>\nLinkedIn post: <a href=\"https://www.linkedin.com/posts/vincent-moens-9bb91972_join-the-tensordict-discord-server-activity-7189297643322253312-Wo9J?utm_source=share&amp;utm_medium=member_desktop\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/posts/vincent-moens-9bb91972_join-the-tensordict-discord-server-activity-7189297643322253312-Wo9J?utm_source=share&amp;utm_medium=member_desktop</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter:<a href=\" @mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\"> @mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Vincent on LinkedIn: <a href=\"https://www.linkedin.com/in/mvi/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/mvi/</a></p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/95312154/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-3%2F390930188-44100-2-7d7396ed93203.mp3","enclosureMime":""},{"title":"AI-Driven Code: Navigating Due Diligence & Transparency in MLOps // Matt van Itallie // #275","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/AI-Driven-Code-Navigating-Due-Diligence--Transparency-in-MLOps--Matt-van-Itallie--275-e2rm1dr","date":1732922367,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p><a href=\"https://www.linkedin.com/in/mvi/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Matt Van Itallie</em></a><em> </em>is the founder and CEO of<em> </em><a href=\"https://www.semasoftware.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Sema</em></a>. Prior to this, they were the Vice President of Customer Support and Customer Operations at Social Solutions.\n\nAI-Driven Code: Navigating Due Diligence &amp; Transparency in MLOps // MLOps Podcast #275 with Matt van Itallie, Founder and CEO of Sema.\n\n// Abstract\nMatt Van Itallie, founder and CEO of Sema, discusses how comprehensive codebase evaluations play a crucial role in MLOps and technical due diligence. He highlights the impact of Generative AI on code transparency and explains the Generative AI Bill of Materials (GBOM), which helps identify and manage risks in AI-generated code. This talk offers practical insights for technical and non-technical audiences, showing how proper diligence can enhance value and mitigate risks in machine learning operations.\n\n// Bio\nMatt Van Itallie is the Founder and CEO of Sema. He and his team have developed Comprehensive Codebase Scans, the most thorough and easily understandable assessment of a codebase and engineering organization. These scans are crucial for private equity and venture capital firms looking to make informed investment decisions. Sema has evaluated code within organizations that have a collective value of over $1 trillion. In 2023, Sema served 7 of the 9 largest global investors, along with market-leading strategic investors, private equity, and venture capital firms, providing them with critical insights.\n\nIn addition, Sema is at the forefront of Generative AI Code Transparency, which measures how much code created by GenAI is in a codebase. They are the inventors behind the Generative AI Bill of Materials (GBOM), an essential resource for investors to understand and mitigate risks associated with AI-generated code.\n\nBefore founding Sema, Matt was a Private Equity operating executive and a management consultant at McKinsey. He graduated from Harvard Law School and has had some interesting adventures, like hiking a third of the Appalachian Trail and biking from Boston to Seattle.\n\nFull bio: https://alistar.fm/bio/matt-van-itallie\n\n// MLOps Swag/Merch\nhttps://shop.mlops.community/\n\n// Related Links\nWebsite: https://en.m.wikipedia.org/wiki/Michael_Gschwind\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: https://go.mlops.community/slack\nFollow us on Twitter: @mlopscommunity\nSign up for the next meetup: https://go.mlops.community/register\nCatch all episodes, blogs, newsletters, and more: https://mlops.community/\n\nConnect with Demetrios on LinkedIn: https://www.linkedin.com/in/dpbrinkm/\nConnect with Matt on LinkedIn: https://www.linkedin.com/in/mvi/\n\n</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/95142779/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-10-29%2F390714674-44100-2-d09999f78d91e.mp3","enclosureMime":""},{"title":"PyTorch's Combined Effort in Large Model Optimization // Michael Gschwind // #274","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/PyTorchs-Combined-Effort-in-Large-Model-Optimization--Michael-Gschwind--274-e2rgvt4","date":1732624950,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p><a href=\"https://www.linkedin.com/in/michael-gschwind-3704222/?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=ios_app\" target=\"_blank\" rel=\"ugc noopener noreferrer\">Dr. <em>Michael Gschwind</em></a> is a Director / Principal <em>Engineer</em> for PyTorch at <em>Meta Platforms</em>. At <em>Meta</em>, he led the rollout of GPU Inference for production services.\n\n// MLOps Podcast #274 with Michael Gschwind, Software Engineer, Software Executive at Meta Platforms.\n\n// Abstract\nExplore the role in boosting model performance, on-device AI processing, and collaborations with tech giants like ARM and Apple. Michael shares his journey from gaming console accelerators to AI, emphasizing the power of community and innovation in driving advancements.\n\n// Bio\nDr. Michael Gschwind is a Director / Principal Engineer for PyTorch at Meta Platforms. At Meta, he led the rollout of GPU Inference for production services. He led the development of MultiRay and Textray, the first deployment of LLMs at a scale exceeding a trillion queries per day shortly after its rollout. He created the strategy and led the implementation of PyTorch donation optimization with Better Transformers and Accelerated Transformers, bringing Flash Attention, PT2 compilation, and ExecuTorch into the mainstream for LLMs and GenAI models. Most recently, he led the enablement of large language models on-device AI with mobile and edge devices.\n\n// MLOps Swag/Merch\n<a href=\"https://mlops-community.myshopify.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops-community.myshopify.com/</a>\n\n// Related Links\n<a target=\"_blank\" rel=\"ugc noopener noreferrer\">Website: https://en.m.wikipedia.org/wiki/Michael_Gschwind</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Michael on LinkedIn: <a href=\"https://www.linkedin.com/in/michael-gschwind-3704222/?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=ios_app\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/michael-gschwind-3704222/?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=ios_app</a></p>\n<p><br /></p>\n<p>Timestamps:\n[00:00] Michael's preferred coffee\n[00:21] Takeaways\n[01:59] Please like, share, leave a review, and subscribe to our MLOps channels!\n[02:10] Gaming to AI Accelerators\n[11:34] Torch Chat goals\n[18:53] Pytorch benchmarking and competitiveness\n[21:28] Optimizing MLOps models\n[24:52] GPU optimization tips\n[29:36] Cloud vs On-device AI\n[38:22] Abstraction across devices \n[42:29] PyTorch developer experience\n[45:33] AI and MLOps-related antipatterns\n[48:33] When to optimize\n[53:26] Efficient edge AI models\n[56:57] Wrap up</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/94977380/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-10-26%2F390499573-44100-2-f59f15a90ef5b.mp3","enclosureMime":""},{"title":"LLMs to agents: The Beauty & Perils of Investing in GenAI // VC Panel // Agents in Production","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/LLMs-to-agents-The-Beauty--Perils-of-Investing-in-GenAI--VC-Panel--Agents-in-Production-e2r88qe","date":1732295523,"author":"Demetrios Brinkmann","unread":true,"desc":"","content":"<ituneshack><p>//Abstract\nIn this segment, the Panel will dive into the evolving landscape of AI, where large language models (LLMs) power the next wave of intelligent agents. In this engaging panel, leading investors Meera (Redpoint), George (Sequoia), and Sandeep (Prosus Ventures) discuss the promise and pitfalls of AI in production. From transformative industry applications to the challenges of scalability, costs, and shifting business models, this session unpacks the metrics and insights shaping GenAI's future. Whether you're excited about AI's potential or wary of its complexities, this is a must-watch for anyone exploring the cutting edge of tech investment.\n\n//Bio\nHost: Paul van der Boor\nSenior Director Data Science @ Prosus Group\n\nSandeep Bakshi\nHead of Investments, Europe @ Prosus\n\nMeera Clark\nPrincipal @ Redpoint Ventures\n\nGeorge Robson\nPartner @ Sequoia Capital\n\nA Prosus | MLOps Community Production\n\n</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/94691598/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-10-22%2F390299987-44100-2-a84174efc247a.mp3","enclosureMime":""}]}