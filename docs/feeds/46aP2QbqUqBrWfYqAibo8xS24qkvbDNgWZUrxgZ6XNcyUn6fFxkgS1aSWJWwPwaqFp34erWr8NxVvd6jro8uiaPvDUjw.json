{"id":"46aP2QbqUqBrWfYqAibo8xS24qkvbDNgWZUrxgZ6XNcyUn6fFxkgS1aSWJWwPwaqFp34erWr8NxVvd6jro8uiaPvDUjw","title":"top scoring links : kubernetes","displayTitle":"Reddit - Kubernetes","url":"https://www.reddit.com/r/kubernetes/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/kubernetes/top/?sort=top&t=day&limit=6","items":[{"title":"Who introduced Kubernetes to you? What's your story?","url":"https://www.reddit.com/r/kubernetes/comments/1h8o1tm/who_introduced_kubernetes_to_you_whats_your_story/","date":1733559576,"author":"/u/moneyppt","unread":true,"desc":"","content":"<!-- SC_OFF --><div class=\"md\"><p>For me, it&#39;s my boss. He had some working experiance.</p> <p>2.5 years ago, we got a project to execute. He proposed k8s and convinced us to run the project on k8s. The intent was clear. To manage the scale efficiently. So thats my story. What&#39;s yours?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/moneyppt\"> /u/moneyppt </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8o1tm/who_introduced_kubernetes_to_you_whats_your_story/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8o1tm/who_introduced_kubernetes_to_you_whats_your_story/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Performance issues with Airflow DagProcessor in a multi-core container","url":"https://www.reddit.com/r/kubernetes/comments/1h8q9fd/performance_issues_with_airflow_dagprocessor_in_a/","date":1733569623,"author":"/u/ScoreApprehensive992","unread":true,"desc":"","content":"<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I&#39;m running an Airflow DAG processor in a Kubernetes pod with 8 CPU cores:</p> <pre><code>lscpu | grep &#39;^CPU(s):&#39; CPU(s): 8 </code></pre> <p>Pod command:</p> <pre><code>containers: - args: - bash - -c - exec airflow dag-processor </code></pre> <p>However, I&#39;m experiencing performance issues. Despite having multiple cores, the total CPU usage isn&#39;t reaching its limit.</p> <p>Upon debugging, I noticed that at some points, one of the cores reaches 100% usage while others remain underutilized.</p> <p>I understand that the Global Interpreter Lock (GIL) in CPython ensures that only one thread executes Python bytecode at a time.</p> <p>And the <code>multiprocessing</code> module creates separate processes for each task rather than threads. Each process has its own memory space, so thereâ€™s no need for a GIL. </p> <p>Given that the Airflow DAG processor uses Python&#39;s <code>multiprocessing</code> module (as seen in <a href=\"https://github.com/apache/airflow/blob/main/airflow/dag_processing/processor.py\">this file</a>), I&#39;m unsure if it&#39;s effectively utilizing all cores.</p> <p>Additionally, there are many subdirectories under <code>$AIRFLOW_HOME/dags</code>, and I suspect one process is parsing all of them, but I&#39;m not entirely sure.</p> <p>Is it normal for one core to hit 100% while others are underutilized in this setup? Should I tune the configuration to ensure better CPU utilization across all cores?</p> <p>Any insights or suggestions would be greatly appreciated!</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ScoreApprehensive992\"> /u/ScoreApprehensive992 </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8q9fd/performance_issues_with_airflow_dagprocessor_in_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8q9fd/performance_issues_with_airflow_dagprocessor_in_a/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"ArgoCD alternative for many deployments","url":"https://www.reddit.com/r/kubernetes/comments/1h8sqya/argocd_alternative_for_many_deployments/","date":1733578954,"author":"/u/Ultimate_Mugwump","unread":true,"desc":"","content":"<!-- SC_OFF --><div class=\"md\"><p>Tech Stack: GKE clusters with around 3k deployments all packaged as helm charts, managed by a single argocd instance </p> <p>I work with several large clusters, night now all managed by a single ArgoCD instance - we are working on splitting it up to deploy an argocd instance on each cluster, but the lions share of our deployments are all in the same cluster, which slows argo a lot, and often causes weird behavior e.g. it will completely an application it was supposed to add, usually gets fixed by just kicking the argocd applicationset controller. </p> <p>weâ€™ve taken some other measures to improve performance, e.g. querying our helm charts repo in GCP to pull in changes instead of pulling them from github, since the artifacts registry generally responds much more quickly and more efficiently than github, but the problem ultimately comes down to the fact that we have almost 3k deployments that it is managing, and the documented limit for argo is 500.</p> <p>Does anyone know of another tool that could handle 1000s of deployments better than Argo? iâ€™ve heard Kustomize is a better solution than helm for very large environments like this but iâ€™m not sure how, why, or even if itâ€™s true at all honestly </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ultimate_Mugwump\"> /u/Ultimate_Mugwump </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8sqya/argocd_alternative_for_many_deployments/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8sqya/argocd_alternative_for_many_deployments/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Kubernetes The Hard Way Made Easy: A Vagrantfile for macOS ARM Users.","url":"https://www.reddit.com/r/kubernetes/comments/1h8vkhe/kubernetes_the_hard_way_made_easy_a_vagrantfile/","date":1733587395,"author":"/u/azalio","unread":true,"desc":"","content":"<table> <tr><td> <a href=\"https://www.reddit.com/r/kubernetes/comments/1h8vkhe/kubernetes_the_hard_way_made_easy_a_vagrantfile/\"> <img src=\"https://external-preview.redd.it/9US5nHmwd7SW76d7MsOZSj_QrDPpzC3jPMXx-vUzq0o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=40e867eca9eaedf0464d1180c63b0df3a4d690b2\" alt=\"Kubernetes The Hard Way Made Easy: A Vagrantfile for macOS ARM Users.\" title=\"Kubernetes The Hard Way Made Easy: A Vagrantfile for macOS ARM Users.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Greetings, Kubernetes community!</p> <p><a href=\"https://preview.redd.it/bs0sesr69g5e1.jpg?width=1400&amp;format=pjpg&amp;auto=webp&amp;s=361a510885102f92cd58356baabbba4f392c2af0\">https://preview.redd.it/bs0sesr69g5e1.jpg?width=1400&amp;format=pjpg&amp;auto=webp&amp;s=361a510885102f92cd58356baabbba4f392c2af0</a></p> <p>Recently, I published an article on Medium where I share a Vagrantfile that simplifies the setup process of Kubernetes The Hard Way for macOS users with ARM architecture.</p> <p><a href=\"https://medium.com/@azalio_16174/kubernetes-the-hard-way-vagrant-edition-for-mac-arm-9137aa9c3fcb\">Read the article here.</a></p> <p>This Vagrantfile provides:</p> <p>- Optimized environment setup: Easily launch virtual machines for Kubernetes The Hard Way on macOS ARM.</p> <p>- Simplified configuration: Pre-configured settings reduce manual setup complexity.</p> <p>- Compatibility: Ensures smooth operation on Apple Silicon, solving common setup issues.</p> <p>- Quick start: Get your environment up and running quickly, allowing you to focus on Kubernetes learning.</p> <p>My motivation for creating this:</p> <p>Setting up a Kubernetes environment can be a complex process, especially on ARM-based Mac systems. My aim was to create a Vagrantfile that would automate and simplify the setup process, making it easier for developers and enthusiasts to learn Kubernetes.</p> <p>I&#39;d love to hear your thoughts and feedback on this setup, as well as any questions you may have. Let&#39;s work together to make learning Kubernetes more efficient!</p> <p>Have a great day! ðŸš€</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/azalio\"> /u/azalio </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8vkhe/kubernetes_the_hard_way_made_easy_a_vagrantfile/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h8vkhe/kubernetes_the_hard_way_made_easy_a_vagrantfile/\">[comments]</a></span> </td></tr></table>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Linux container from scratch","url":"https://www.reddit.com/r/kubernetes/comments/1h90ct0/linux_container_from_scratch/","date":1733600343,"author":"/u/disenchanted_bytes","unread":true,"desc":"","content":"<!-- SC_OFF --><div class=\"md\"><p>Wrote a detailed post where I create a linux container step-by-step using just terminal commands. The post illustrates kernel features for container isolation and how to practically use them.</p> <p><a href=\"https://open.substack.com/pub/michalpitr/p/linux-container-from-scratch?r=gt6tv&amp;utm_campaign=post&amp;utm_medium=web\">https://open.substack.com/pub/michalpitr/p/linux-container-from-scratch?r=gt6tv&amp;utm_campaign=post&amp;utm_medium=web</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/disenchanted_bytes\"> /u/disenchanted_bytes </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h90ct0/linux_container_from_scratch/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h90ct0/linux_container_from_scratch/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"HA Storage Options for a Small Baremetal Cluster?","url":"https://www.reddit.com/r/kubernetes/comments/1h995zz/ha_storage_options_for_a_small_baremetal_cluster/","date":1733626376,"author":"/u/Lyraeixis","unread":true,"desc":"","content":"<!-- SC_OFF --><div class=\"md\"><p>Hey there! I&#39;ve recently stood up a small Kubernetes cluster at home made out of three repurposed workstations that my workplace threw out. I do have a small NAS, and that&#39;s fine for most of my apps, but I run a local instance of Vaultwarden to manage passwords and I&#39;d like that to be as HA as possible for obvious reasons. The issue I have with just linking its volumes to the NAS like everything else is that if the NAS goes down, the volumes go down, which means Vaultwarden goes down -- single point of failure. I&#39;d like to be able to lose the NAS, or any individual node, while still keeping Vaultwarden up. The good news is that it reads way more than it writes, traffic overall is pretty light, and it doesn&#39;t store a lot of information -- less than 1GB.</p> <p>The two big options I&#39;ve seen are Longhorn and Rook. Longhorn looks great on paper, but I hear a lot of people talk about unreliability and issues with replicas going out of sync. Rook also looks pretty good, but the Ceph docs talk about specs my reimaged workstations don&#39;t have like 32GB of RAM for a small cluster. So what do you guys think is best for this kind of a use case with these limitations? Is distributed storage too much for such a small setup in the first place?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lyraeixis\"> /u/Lyraeixis </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h995zz/ha_storage_options_for_a_small_baremetal_cluster/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1h995zz/ha_storage_options_for_a_small_baremetal_cluster/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""}]}