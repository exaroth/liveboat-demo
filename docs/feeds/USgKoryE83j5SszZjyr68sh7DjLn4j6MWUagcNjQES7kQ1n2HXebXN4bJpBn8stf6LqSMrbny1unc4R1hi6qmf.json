{
  "id": "USgKoryE83j5SszZjyr68sh7DjLn4j6MWUagcNjQES7kQ1n2HXebXN4bJpBn8stf6LqSMrbny1unc4R1hi6qmf",
  "title": "top scoring links : golang",
  "displayTitle": "Reddit - Go",
  "url": "https://www.reddit.com/r/golang/top/.rss?sort=top&t=day&limit=6",
  "feedLink": "https://www.reddit.com/r/golang/top/?sort=top&t=day&limit=6",
  "items": [
    {
      "title": "Handing errors with namespace codes",
      "url": "https://www.reddit.com/r/golang/comments/1h7x5ks/handing_errors_with_namespace_codes/",
      "date": 1733475144,
      "author": "/u/olvrng",
      "unread": true,
      "desc": "",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone. I&#39;m developing an internal framework for my company about handling errors, around the concept of using namespace error codes.</p> <p>For example, use DEPS.PG.NOT_FOUND for database error, when this error is handled by the profile/user layer, it&#39;s wrapped as PRFL.USR.NOT_FOUND.</p> <p>It may be a bit over-engineering, but now the error codes become more structured. The logs become more manageable and clearer, with the ability to tag and monitor each code, separating between expected and unexpected code. I&#39;m sharing the idea in this article. Would love to hear your thoughts, or know more about how you handle errors in your projects.</p> <p><a href=\"https://olivernguyen.io/w/namespace.error\">https://olivernguyen.io/w/namespace.error</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/olvrng\"> /u/olvrng </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1h7x5ks/handing_errors_with_namespace_codes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1h7x5ks/handing_errors_with_namespace_codes/\">[comments]</a></span>",
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": ""
    },
    {
      "title": "Introducing a new Enum library for Go - No Code Generation, Simple and Back-compatible with standard definition",
      "url": "https://www.reddit.com/r/golang/comments/1h84em8/introducing_a_new_enum_library_for_go_no_code/",
      "date": 1733500292,
      "author": "/u/Lumpy_Peach5111",
      "unread": true,
      "desc": "",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Recently, I came across discussions on why Go enums are challenging to work with. I started searching for existing Go enum libraries and found that many have at least one of the following issues:</p> <ul> <li>Need code generation</li> <li>Non-constant enums</li> <li>Incompatibility with <code>iota</code> enum implementation</li> <li>No serialization</li> </ul> <p>To address this, I wrote a simple enum library to make working with enums in Go easier and more straightforward. <a href=\"https://github.com/xybor-x/enum\">https://github.com/xybor-x/enum</a></p> <p>Feel free to share your feedback, suggestions, or concerns. If this library is helpful, please consider giving it a star on GitHub!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lumpy_Peach5111\"> /u/Lumpy_Peach5111 </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1h84em8/introducing_a_new_enum_library_for_go_no_code/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1h84em8/introducing_a_new_enum_library_for_go_no_code/\">[comments]</a></span>",
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": ""
    },
    {
      "title": "Context with Graceful Shutdown",
      "url": "https://www.reddit.com/r/golang/comments/1h85rzd/context_with_graceful_shutdown/",
      "date": 1733503804,
      "author": "/u/obenns",
      "unread": true,
      "desc": "",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I have a context that finishes when a cancellation signal is sent to the program. A package waits on this signal and then finishes:</p> <pre><code>func WithSignalCancel(baseCtx context.Context) (context.Context, context.CancelFunc) { ctx, cancel := context.WithCancel(baseCtx) sigChan := make(chan os.Signal, 1) signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM) go func() { sig := &lt;-sigChan cancel() }() return ctx, cancel } </code></pre> <p>Now, upon this context being cancelled, I want to process anything that is still on the channel (the service that pushes to this channel also listens to this ctx, but it could still be pushing before it is able to handle it).</p> <p>So there are 2 scenarios here that I want to solve and not sure how I go about it:<br/> - If an entity is already being saved, these now fail due to it calling a db func with a cancelled ctx. However I still actually want these to complete when the shutdown occurs, <em>before then shutting down</em>. Do I just create a new context here for the database that is not wrapped in the signal cancel?<br/> - If ctx.Done() is hit, then I suppose I want to do a `range` on any remaining entries before the other service closes the channel?</p> <p>I sense I am doing something wrong here as I have not been able to find a solution! Any advice would be appreciated.</p> <pre><code>func (s *Service) Run(ctx context.Context, entities &lt;-chan *Entity) error { for { select { case data, ok := &lt;-entities: if !ok { return nil } // saves to db s.saveEntity(ctx, data) case &lt;-ctx.Done(): } } } </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/obenns\"> /u/obenns </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1h85rzd/context_with_graceful_shutdown/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1h85rzd/context_with_graceful_shutdown/\">[comments]</a></span>",
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": ""
    },
    {
      "title": "GitHub - essentialkaos/aligo: Utility for checking and viewing Golang struct alignment info",
      "url": "https://www.reddit.com/r/golang/comments/1h86n5z/github_essentialkaosaligo_utility_for_checking/",
      "date": 1733505991,
      "author": "/u/web3samy",
      "unread": true,
      "desc": "",
      "content": "<table> <tr><td> <a href=\"https://www.reddit.com/r/golang/comments/1h86n5z/github_essentialkaosaligo_utility_for_checking/\"> <img src=\"https://external-preview.redd.it/815uGj9GuKSnf_-O7dgkgCBHGewNQaSxET9NaEh_pL8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b32d536c1b2c6026c4dfc359765360ade75980d1\" alt=\"GitHub - essentialkaos/aligo: Utility for checking and viewing Golang struct alignment info\" title=\"GitHub - essentialkaos/aligo: Utility for checking and viewing Golang struct alignment info\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/web3samy\"> /u/web3samy </a> <br/> <span><a href=\"https://github.com/essentialkaos/aligo\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1h86n5z/github_essentialkaosaligo_utility_for_checking/\">[comments]</a></span> </td></tr></table>",
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": ""
    },
    {
      "title": "What happens if net.Conn.Read reads more bytes than the buffer size",
      "url": "https://www.reddit.com/r/golang/comments/1h87t2i/what_happens_if_netconnread_reads_more_bytes_than/",
      "date": 1733508914,
      "author": "/u/Interesting_Shine_38",
      "unread": true,
      "desc": "",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I failed to find meaningful answer(for me at least) to this question.<br/> If i have the following code: </p> <pre><code>buf := make([]byte, 1 &lt;&lt; 3) sizeInput, err := conn.Read(buf) // this is handling tcp connection </code></pre> <p>What happens when the data fed into <code>buf</code> via the network is larger than the <code>buf</code> array size? </p> <p>Also is there a way to limit the number of bytes read? I expected <code>Read</code> to take second argument, which indicates the buffer size but according to the documentation this is not the case. </p> <p>The source code of the Read method is a little bit cryptic for me and I failed to understand how this is handled. </p> <p>The code from the net package is basically this:</p> <pre><code>// Read implements the Conn Read method. func (c *conn) Read(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Read(b) if err != nil &amp;&amp; err != io.EOF { err = &amp;OpError{Op: &quot;read&quot;, Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Interesting_Shine_38\"> /u/Interesting_Shine_38 </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1h87t2i/what_happens_if_netconnread_reads_more_bytes_than/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1h87t2i/what_happens_if_netconnread_reads_more_bytes_than/\">[comments]</a></span>",
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": ""
    },
    {
      "title": "High-Performance Image Compression Project (Part 5 - Async Batch Processing)",
      "url": "https://www.reddit.com/r/golang/comments/1h8e6p7/highperformance_image_compression_project_part_5/",
      "date": 1733525755,
      "author": "/u/Investorator3000",
      "unread": true,
      "desc": "",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone!!</p> <p>This is my 5th post in this Subreddit on my journey to build a high-performance scalable image compression service (or the whole project now). </p> <p>After launching <a href=\"https://gofilecompress.com/\">gofilecompress.com</a>, where you can compress single PNG files (up to 5MB), I am starting to work on a much bigger project related to it: a <strong>batch image compression service</strong> that handles <strong>massive ZIP files (1â€“10GB+)</strong> asynchronously. The idea is that users or organizations upload their files, and the service processes them in the background. After a few minutes or hours (depending on size), theyâ€™ll get an email notification with a link to download the compressed results.</p> <p>This time, Iâ€™m aiming to build something <strong>high-performant and scalable</strong>, designed for multiple users and large-scale tasks. Hereâ€™s what Iâ€™ve got so far:</p> <h1>Architecture Overview</h1> <p>(you can view the architecture flow chart for better understanding of it visually <a href=\"https://drive.google.com/file/d/1U51iAi9XUPZFd7yxvq3CFnXHrWIG8zOx/view?usp=share_link\">Architecture Flow Chart</a>)</p> <p>The system is built on a <strong>microservices-based, event-driven architecture</strong>, where everything is containerized and deployed using <strong>AWS ECS</strong> for easy scaling. Hereâ€™s the key flow:</p> <ol> <li><strong>Microservices:</strong> Each major task (uploading, compression, notifications) is handled by a separate service to keep things modular and manageable.</li> <li><strong>Event-Driven Workflow:</strong> Jobs are queued and processed asynchronously using <strong>AWS SQS</strong>, which helps handle multiple user requests efficiently.</li> <li><strong>Components:</strong> File storage is managed with <strong>S3</strong>, job metadata is tracked in <strong>RDS</strong>, and the API is exposed via <strong>API Gateway</strong>.</li> </ol> <p>Also, if someone remembers my previous posts, you can notice that <strong>I have switched to AWS from GCP</strong>. The reason for that is aside from building an actual scalable product, but I also want to learn tools and skills that will allow me to consider many job opportunities as a young student who wants to become a great backend engineer. </p> <h1>How It Works</h1> <ol> <li><strong>Create a Compression Request/Job by User:</strong> <ul> <li>Users start by calling the <strong>API Gateway (the single point to reach my VPC)</strong> to create a compression job.</li> <li>The <strong>Upload Service</strong> stores the job in <strong>RDS</strong> (Amazon&#39;s SQL Service) with a status of &quot;INITIATED&quot; and returns <strong>pre-signed S3 URLs</strong> for uploading the ZIP file.</li> </ul></li> <li><strong>Upload the File:</strong> <ul> <li>Users upload their ZIP files in chunks (up to 5MB each) from Frontend directly to <strong>S3</strong> using the pre-signed URLs.</li> <li>Once the upload is done, <strong>S3</strong> triggers a notification, and the <strong>Upload Service</strong> updates the job status to &quot;UPLOADED&quot; in <strong>RDS</strong>. The job is then pushed to <strong>SQS</strong> for processing.</li> </ul></li> <li><strong>Compression Time:</strong> <ul> <li>The <strong>Compression Service</strong> picks up jobs from <strong>SQS</strong>, streams the ZIP file from <strong>S3</strong>, and processes each image in memory.</li> <li>Compressed images are added to a new ZIP file, which is then uploaded back to <strong>S3</strong>.</li> <li>The service updates the progress and marks the job as &quot;COMPLETED&quot; in <strong>RDS</strong>.</li> </ul></li> <li><strong>Notification and Download:</strong> <ul> <li>Once the job is done, the <strong>Notification Service</strong> sends an email to the user with a download link (a pre-signed URL for the compressed ZIP file stored in <strong>S3</strong>).</li> </ul></li> </ol> <h1>Why I Designed It This Way</h1> <p>I wanted to keep things modular, scalable, and easy to deploy, which is why I went with <strong>microservices and containers</strong> on <strong>AWS ECS</strong>. Using <strong>SQS</strong> for task queuing keeps everything asynchronous and smooth, even when there are multiple user requests. Storing files directly in <strong>S3</strong> ensures I donâ€™t run into storage issues, and tracking progress in <strong>RDS</strong> makes it easier to debug and monitor.</p> <p>So, that&#39;s it! :) I would love to hear your thoughts on this project and any recommendations or best practices you think I should consider or add.</p> <p>To be honest, I also have a question: as I start managing this big project, do you have any suggestions for staying organized and ensuring everything is well-structured? I&#39;m using <strong>Notion</strong> right now to track tasks, but I&#39;m also considering tools like <strong>JIRA</strong> for a more detailed project management workflow. </p> <p>Thanks for checking this out! Iâ€™m super open to feedback as I fine-tune this!!!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Investorator3000\"> /u/Investorator3000 </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1h8e6p7/highperformance_image_compression_project_part_5/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1h8e6p7/highperformance_image_compression_project_part_5/\">[comments]</a></span>",
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": ""
    }
  ]
}