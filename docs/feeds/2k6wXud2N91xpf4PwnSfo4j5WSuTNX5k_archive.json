{"id":"2k6wXud2N91xpf4PwnSfo4j5WSuTNX5k","title":"Tech News - Last 2 days","displayTitle":"Tech News - Last 2 days","url":"","feedLink":"","items":[{"title":"Qualcomm Processors Properly Licensed From Arm, US Jury Finds","url":"https://yro.slashdot.org/story/24/12/20/2216253/qualcomm-processors-properly-licensed-from-arm-us-jury-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734735000,"author":"BeauHD","unread":true,"desc":"","content":"Jurors delivered a mixed verdict on Friday, ruling that Qualcomm had properly licensed its central processor chips from Arm. This decision effectively concludes Arm's lawsuit against Qualcomm, which had the potential to disrupt the global smartphone and PC chip markets.\n \nThe dispute stemmed from Qualcomm's $1.4 billion acquisition of chip startup Nuvia in 2021. Arm claimed Qualcomm breached contract terms by using Nuvia's designs without permission, while Qualcomm maintained its existing agreement covers the acquired technology. Arm demanded Qualcomm destroy the Nuvia designs created before the acquisition. Reuters reports: An eight-person jury in U.S. federal court deadlocked on the question of whether Nuvia, a startup that Qualcomm purchased for $1.4 billion in 2021, breached the terms of its license with Arm. But the jury found that Qualcomm did not breach Nuvia's license with Arm.\n \nThe jury also found that Qualcomm's chips created using Nuvia technology, which have been central to Qualcomm's push into the personal computer market, are properly licensed under its own agreement with Arm, clearing the way for Qualcomm to continue selling them.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Qualcomm+Processors+Properly+Licensed+From+Arm%2C+US+Jury+Finds%3A+https%3A%2F%2Fyro.slashdot.org%2Fstory%2F24%2F12%2F20%2F2216253%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fyro.slashdot.org%2Fstory%2F24%2F12%2F20%2F2216253%2Fqualcomm-processors-properly-licensed-from-arm-us-jury-finds%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://yro.slashdot.org/story/24/12/20/2216253/qualcomm-processors-properly-licensed-from-arm-us-jury-finds?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557465&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Arizona's Getting an Online Charter School Taught Entirely By AI","url":"https://news.slashdot.org/story/24/12/20/2211207/arizonas-getting-an-online-charter-school-taught-entirely-by-ai?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734732660,"author":"BeauHD","unread":true,"desc":"","content":"An anonymous reader quotes a report from TechCrunch: The newest online-only school greenlighted (PDF) by the Arizona State Board for Charter Schools comes with a twist: The academic curriculum will be taught entirely by AI. Charter schools -- independently operated but publicly funded -- typically get greater autonomy compared to traditional public schools when it comes to how subjects are taught. But Unbound Academy's application, which proposes an \"AI-driven adaptive learning technology\" that \"condenses academic instruction into a two-hour window,\" is a first for the model. (Unbound's founders have been running a similar program at a \"high-end private school\" in Texas, which appears to be in-person.)\n \nUnbound's approach leans on edtech platforms like IXL and Khan Academy, and students engage with \"interactive, AI-powered platforms that continuously adjust to their individual learning pace and style.\" There will be humans, just fewer of them, and maybe not actual accredited teachers: It will adopt a \"human-in-the-loop\" approach with \"skilled guides\" monitoring progress who can provide \"targeted interventions\" and coaching for each student. Academic instruction is whittled down to just two hours. The remainder of the students' day will include \"life-skills workshops\" covering areas such as critical thinking, creative problem-solving, financial literacy, public speaking, goal setting, and entrepreneurship. The online-only school targets students from fourth to eighth grades.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Arizona's+Getting+an+Online+Charter+School+Taught+Entirely+By+AI%3A+https%3A%2F%2Fnews.slashdot.org%2Fstory%2F24%2F12%2F20%2F2211207%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fnews.slashdot.org%2Fstory%2F24%2F12%2F20%2F2211207%2Farizonas-getting-an-online-charter-school-taught-entirely-by-ai%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://news.slashdot.org/story/24/12/20/2211207/arizonas-getting-an-online-charter-school-taught-entirely-by-ai?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557463&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"After causing outrage on the first day of Y Combinator, AI code editor PearAI lands $1M seed","url":"https://techcrunch.com/2024/12/20/after-causing-outrage-on-the-first-day-of-y-combinator-ai-code-editor-pearai-lands-1m-seed/","date":1734730490,"author":"Julie Bort","unread":true,"desc":"","content":"<p>On the first day of Y Combinator the founders of PearAI got “cancelled.\" They used the hate to launch a new product, raise $1 million.</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"CFPB Sues America's Largest Banks For 'Allowing Fraud To Fester' on Zelle","url":"https://slashdot.org/story/24/12/20/1851237/cfpb-sues-americas-largest-banks-for-allowing-fraud-to-fester-on-zelle?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734729720,"author":"msmash","unread":true,"desc":"","content":"The Consumer Financial Protection Bureau is suing America's three largest banks, accusing the institutions of failing to protect customers from fraud on Zelle, the payment platform they co-own. From a report: According to the suit, which also targets Early Warning Services LLC, Zelle's official operator, Zelle users have lost more than $870 million over the network's seven-year existence due to these alleged failures. \"The nation's largest banks felt threatened by competing payment apps, so they rushed to put out Zelle,\" said CFPB Director Rohit Chopra in a statement. \"By their failing to put in place proper safeguards, Zelle became a gold mine for fraudsters, while often leaving victims to fend for themselves.\" \n\nAmong the charges:\n1. Poor identity verification methods, which have allowed bad actors to quickly create accounts and target Zelle users.\n2. Allowing repeat offenders to continue to gain access to the platform\n3. Ignoring and failing to report instances of fraud\n4. Failing to properly investigate consumer complaints \n\nThe CFPB's suit seeks to change the platform's operations, as well as obtain a civil money penalty, that would be paid into the CFPB's victims relief fund.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=CFPB+Sues+America's+Largest+Banks+For+'Allowing+Fraud+To+Fester'+on+Zelle%3A+https%3A%2F%2Fslashdot.org%2Fstory%2F24%2F12%2F20%2F1851237%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fslashdot.org%2Fstory%2F24%2F12%2F20%2F1851237%2Fcfpb-sues-americas-largest-banks-for-allowing-fraud-to-fester-on-zelle%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://slashdot.org/story/24/12/20/1851237/cfpb-sues-americas-largest-banks-for-allowing-fraud-to-fester-on-zelle?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557299&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Apple Pulls Lightning-Equipped iPhones From Swiss Stores Ahead of EU USB-C Mandate","url":"https://apple.slashdot.org/story/24/12/20/1839234/apple-pulls-lightning-equipped-iphones-from-swiss-stores-ahead-of-eu-usb-c-mandate?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734727320,"author":"msmash","unread":true,"desc":"","content":"Apple has started pulling its iPhone SE and iPhone 14 models from sale in Switzerland, signaling broader discontinuation across the European Union ahead of new USB-C charging requirements taking effect December 28. \n\nThe devices, which use Apple's proprietary Lightning port, disappeared from Swiss online stores today. Switzerland, while not an EU member, follows EU market rules. Apple-authorized resellers can continue selling existing stock until depleted. A new USB-C compatible iPhone SE is expected in March.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Apple+Pulls+Lightning-Equipped+iPhones+From+Swiss+Stores+Ahead+of+EU+USB-C+Mandate%3A+https%3A%2F%2Fapple.slashdot.org%2Fstory%2F24%2F12%2F20%2F1839234%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fapple.slashdot.org%2Fstory%2F24%2F12%2F20%2F1839234%2Fapple-pulls-lightning-equipped-iphones-from-swiss-stores-ahead-of-eu-usb-c-mandate%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://apple.slashdot.org/story/24/12/20/1839234/apple-pulls-lightning-equipped-iphones-from-swiss-stores-ahead-of-eu-usb-c-mandate?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557297&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Michael Dell Says Adoption of AI PCs is 'Definitely Delayed'","url":"https://tech.slashdot.org/story/24/12/20/181253/michael-dell-says-adoption-of-ai-pcs-is-definitely-delayed?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734727260,"author":"msmash","unread":true,"desc":"","content":"Dell CEO Michael Dell has acknowledged delays in corporate adoption of AI-enabled PCs but remains confident in their eventual widespread uptake, citing his four decades of industry experience with technology transitions. \n\nThe PC maker's chief executive told Fortune that while the current refresh cycle is \"definitely delayed,\" adoption is inevitable once sufficient features drive customer demand. Meanwhile, Dell's infrastructure division saw 80% revenue growth last quarter from AI-server sales. The company is supplying servers for xAI's Colossus supercomputer project in Memphis and sees opportunities in \"sovereign AI\" systems for nations seeking technological independence. \"Pick a country ranked by GDP, the [top] 49 other than the U.S., they all need one,\" Dell said.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Michael+Dell+Says+Adoption+of+AI+PCs+is+'Definitely+Delayed'%3A+https%3A%2F%2Ftech.slashdot.org%2Fstory%2F24%2F12%2F20%2F181253%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Ftech.slashdot.org%2Fstory%2F24%2F12%2F20%2F181253%2Fmichael-dell-says-adoption-of-ai-pcs-is-definitely-delayed%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://tech.slashdot.org/story/24/12/20/181253/michael-dell-says-adoption-of-ai-pcs-is-definitely-delayed?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557245&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Third member of LockBit ransomware gang has been arrested","url":"https://techcrunch.com/2024/12/20/third-member-of-lockbit-ransomware-gang-has-been-arrested/","date":1734726017,"author":"Zack Whittaker","unread":true,"desc":"","content":"<p>LockBit is believed tobe responsible for at least $500 million in ransom payments alone. </p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Feds clear the way for robotaxis without steering wheels and pedals","url":"https://techcrunch.com/2024/12/20/feds-clear-the-way-for-robotaxis-without-steering-wheel-and-pedals/","date":1734725885,"author":"Rebecca Bellan","unread":true,"desc":"","content":"<p>The National Highway Traffic Safety Administration (NHTSA) on Friday proposed a new national framework that could make it easier for companies to deploy at scale autonomous vehicles without traditional manual driving controls &#8212; like steering wheels, pedals, and sideview mirrors.  The guidelines also require AV companies to share a whole lot more safety data with [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"ChatGPT: Everything you need to know about the AI-powered chatbot","url":"https://techcrunch.com/2024/12/20/chatgpt-everything-to-know-about-the-ai-chatbot/","date":1734725700,"author":"Kyle Wiggers, Cody Corrall, Alyssa Stringer","unread":true,"desc":"","content":"<p>ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users. 2024 has been a big year for OpenAI, from its [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"VCs pledge not to take money from Russia or China, and Databricks raises a humongous round","url":"https://techcrunch.com/2024/12/20/vcs-pledge-not-to-take-money-from-russia-china-databricks-raises-humongous-round/","date":1734725100,"author":"Anna Heim","unread":true,"desc":"","content":"<p>Welcome to Startups Weekly — your weekly recap of everything you can’t miss from the world of startups. Want it in your inbox every Friday? Sign up here. This week was full of news, likely because it is also the last &#8220;real&#8221; week of 2024. Which is another way for us to say goodbye for [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"We're About To Fly a Spacecraft Into the Sun For the First Time","url":"https://science.slashdot.org/story/24/12/20/1821229/were-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734724860,"author":"msmash","unread":true,"desc":"","content":"NASA's Parker Solar Probe will make its closest approach yet to the Sun on Christmas Eve, flying within 3.8 million miles of the solar surface and entering its atmosphere for the first time. \n\nThe spacecraft, which travels at speeds up to 430,000 miles per hour, aims to study the origins of solar wind -- the stream of charged particles emanating from the Sun's corona. The probe's heat shield will endure temperatures exceeding 2,500-degree Fahrenheit during the flyby, requiring specialized materials like sapphire crystal tubes and niobium wiring to protect its instruments.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=We're+About+To+Fly+a+Spacecraft+Into+the+Sun+For+the+First+Time%3A+https%3A%2F%2Fscience.slashdot.org%2Fstory%2F24%2F12%2F20%2F1821229%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fscience.slashdot.org%2Fstory%2F24%2F12%2F20%2F1821229%2Fwere-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://science.slashdot.org/story/24/12/20/1821229/were-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557271&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Linux 6.13-rc4 To Fix A Nasty USB Problem Plaguing The Kernel For A Few Weeks","url":"https://www.phoronix.com/news/Linux-6.13-rc4-USB-Fix","date":1734724500,"author":"Michael Larabel","unread":true,"desc":"","content":"Merged to Linux Git minutes ago and ahead of the Linux 6.13-rc4 tagging on Sunday were this week's set of USB fixes that are particularly noteworthy. Most significant is fixing a USB regression that had been present in the stack since the Linux 6.13 merge window last month...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"OpenAI announces o3 and o3-mini, its next simulated reasoning models","url":"https://arstechnica.com/information-technology/2024/12/openai-announces-o3-and-o3-mini-its-next-simulated-reasoning-models/","date":1734723103,"author":"Benj Edwards","unread":true,"desc":"","content":"\n              <p>On Friday, during Day 12 of its \"<a href=\"https://arstechnica.com/ai/2024/12/openai-teases-12-days-of-mystery-product-launches-starting-tomorrow/\">12 days of OpenAI</a>,\" OpenAI CEO Sam Altman announced its latest AI \"reasoning\" models, o3 and o3-mini, which build upon the <a href=\"https://arstechnica.com/information-technology/2024/09/openais-new-reasoning-ai-models-are-here-o1-preview-and-o1-mini/\">o1 models</a> launched earlier this year. The company is not releasing them yet but will make these models available for public safety testing and research access today.</p>\n<p>The models use what OpenAI calls \"private chain of thought,\" where the model pauses to examine its internal dialog and plan ahead before responding, which you might call \"simulated reasoning\" (SR)—a form of AI that goes beyond basic large language models (LLMs).</p>\n<p>The company named the model family \"o3\" instead of \"o2\" to avoid potential trademark conflicts with British telecom provider O2, according to <a href=\"https://www.theinformation.com/briefings/openai-preps-o3-reasoning-model\">The Information</a>. During Friday's livestream, Altman acknowledged his company's naming foibles, saying, \"In the grand tradition of OpenAI being really, truly bad at names, it'll be called o3.\"</p><p><a href=\"https://arstechnica.com/information-technology/2024/12/openai-announces-o3-and-o3-mini-its-next-simulated-reasoning-models/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/information-technology/2024/12/openai-announces-o3-and-o3-mini-its-next-simulated-reasoning-models/#comments\">Comments</a></p>\n\n            ","flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/openai_o3_model-1152x648.jpg","enclosureMime":""},{"title":"Why Online Returns Are a Hassle Now","url":"https://slashdot.org/story/24/12/20/1816259/why-online-returns-are-a-hassle-now?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734722520,"author":"msmash","unread":true,"desc":"","content":"U.S. retailers are cracking down on free returns as costs spiral out of control, The Atlantic reports. Return rates have more than doubled since 2019, with shoppers expected to send back nearly $900 billion in merchandise this year. \n\nMajor chains like REI and JCPenney are now charging fees or requiring in-store drop-offs, abandoning years of customer-friendly policies. With each $100 return costing stores up to $30 to process, some retailers have given up entirely -- telling customers to keep cheap items rather than send them back.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Why+Online+Returns+Are+a+Hassle+Now%3A+https%3A%2F%2Fslashdot.org%2Fstory%2F24%2F12%2F20%2F1816259%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fslashdot.org%2Fstory%2F24%2F12%2F20%2F1816259%2Fwhy-online-returns-are-a-hassle-now%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://slashdot.org/story/24/12/20/1816259/why-online-returns-are-a-hassle-now?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557269&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"AMD Launches A YouTube Channel For Developers","url":"https://www.phoronix.com/news/AMD-Developer-Central-YouTube","date":1734721396,"author":"Michael Larabel","unread":true,"desc":"","content":"If you are looking for some interesting technical content to watch over the holidays or end-of-year downtime, AMD shared today that they have launched their own YouTube channel for developer-related content...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Nvidia clears regulatory hurdle to acquire Run:ai","url":"https://techcrunch.com/2024/12/20/nvidia-clears-regulatory-hurdle-to-acquire-runai/","date":1734720893,"author":"Rebecca Szkutak","unread":true,"desc":"","content":"<p>Chip company Nvidia gets the green light from the European Union to complete its acquisition of Run:ai. The EU came to a unanimous decision today that Nvidia could go ahead with its acquisition of Israeli GPU orchestration platform Run:ai, according to reporting from Bloomberg. The European Commission determined that if the merger went through, other [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"OpenAI Unveils o3, a Smarter AI Model With Improved Reasoning Skills","url":"https://slashdot.org/story/24/12/20/1836246/openai-unveils-o3-a-smarter-ai-model-with-improved-reasoning-skills?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734719760,"author":"msmash","unread":true,"desc":"","content":"OpenAI has unveiled a new AI model that it says takes longer to solve problems but gets better results, following Google's similar announcement a day earlier. The model, called o3, replaces o1 from September and spends extra time working through questions that need step-by-step reasoning. \n\nIt scores three times higher than o1 on ARC-AGI, a test measuring how well AI handles complex math and logic problems it hasn't seen before. \"This is the beginning of the next phase of AI,\" CEO Sam Altman said during a livestream Friday. \n\nThe Microsoft-backed startup is keeping o3 under wraps for now but plans to let outside researchers test it.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=OpenAI+Unveils+o3%2C+a+Smarter+AI+Model+With+Improved+Reasoning+Skills%3A+https%3A%2F%2Fslashdot.org%2Fstory%2F24%2F12%2F20%2F1836246%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fslashdot.org%2Fstory%2F24%2F12%2F20%2F1836246%2Fopenai-unveils-o3-a-smarter-ai-model-with-improved-reasoning-skills%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://slashdot.org/story/24/12/20/1836246/openai-unveils-o3-a-smarter-ai-model-with-improved-reasoning-skills?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557293&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Google is expanding Gemini’s in-depth research mode to 40 languages","url":"https://techcrunch.com/2024/12/20/google-is-expanding-geminis-in-depth-research-mode-to-40-languages/","date":1734718885,"author":"Ivan Mehta","unread":true,"desc":"","content":"<p>Google said Friday that the company is expanding Gemini&#8217;s latest in-depth research mode to 40 more languages. The company launched the in-depth research mode earlier this month, allowing Google One AI premium plan users to unlock an AI-powered research assistant of sorts. The in-depth function works in a multi-step method, from creating a research plan [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Here’s the full list of 49 US AI startups that have raised $100M or more in 2024","url":"https://techcrunch.com/2024/12/20/heres-the-full-list-of-49-us-ai-startups-that-have-raised-100m-or-more-in-2024/","date":1734718365,"author":"Rebecca Szkutak","unread":true,"desc":"","content":"<p>In the first half of 2024 alone, more than $35.5 billion was invested into AI startups globally.</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"US Data-Center Power Use Could Nearly Triple By 2028, DOE-Backed Report Says","url":"https://hardware.slashdot.org/story/24/12/20/1755236/us-data-center-power-use-could-nearly-triple-by-2028-doe-backed-report-says?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734717720,"author":"msmash","unread":true,"desc":"","content":"U.S. data center power demand could nearly triple in the next three years, and consume as much as 12% of the country's electricity, as the industry undergoes an AI transformation, according to an unpublished Department of Energy-backed report seen by Reuters. The publication adds: The Lawrence Berkeley National Laboratory report, which is expected to be released on Friday, comes as the U.S. power industry and government agencies attempt to understand how the sudden rise of Big Tech's data-center demand will affect electrical grids, power bills and the climate. \n\nBy 2028, data-center annual energy use could reach between 74 and 132 gigawatts, or between 6.7% and 12% of total U.S. electricity consumption, according to the Berkeley Lab report. The industry standard-setting report included ranges that depended partly on the availability and demand for a type of AI chip known as GPUs. Currently, data centers make up a little more than 4% of the country's power load. \"This really signals to us where the frontier is in terms of growing energy demand in the U.S.,\" said Avi Shultz, director of the DOE's Industrial Efficiency and Decarbonization Office.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=US+Data-Center+Power+Use+Could+Nearly+Triple+By+2028%2C+DOE-Backed+Report+Says%3A+https%3A%2F%2Fhardware.slashdot.org%2Fstory%2F24%2F12%2F20%2F1755236%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fhardware.slashdot.org%2Fstory%2F24%2F12%2F20%2F1755236%2Fus-data-center-power-use-could-nearly-triple-by-2028-doe-backed-report-says%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://hardware.slashdot.org/story/24/12/20/1755236/us-data-center-power-use-could-nearly-triple-by-2028-doe-backed-report-says?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557243&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Video Friday: Happy Holidays!","url":"https://spectrum.ieee.org/video-friday-holidays-2024","date":1734717605,"author":"Evan Ackerman","unread":true,"desc":"","content":"<p>Your weekly selection of awesome robot videos</p>","flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NTM4ODM2My9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc1MzgyMDg3Mn0.04JpzJOBZGw50OWQZcVXINm-ZXzlDB56Pc0JLK58iHs/image.png?width=600","enclosureMime":""},{"title":"OpenAI announces new o3 models","url":"https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/","date":1734717417,"author":"Maxwell Zeff, Kyle Wiggers","unread":true,"desc":"","content":"<p>OpenAI saved its biggest announcement for the last day of its 12-day &#8220;shipmas&#8221; event. On Friday, the company unveiled o3, the successor to the o1 &#8220;reasoning&#8221; model it released earlier in the year. o3 is a model family, to be more precise — as was the case with o1. There&#8217;s o3 and o3-mini, a smaller, [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"FDA Sets Stricter Rules for 'Healthy' Food Labels","url":"https://news.slashdot.org/story/24/12/20/1721248/fda-sets-stricter-rules-for-healthy-food-labels?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734715320,"author":"msmash","unread":true,"desc":"","content":"The U.S. Food and Drug Administration has unveiled stricter criteria for food manufacturers to label their products as \"healthy,\" marking the first major update to the definition in 30 years. \n\nThe new rule requires products to meet specific thresholds for nutrients while limiting sodium, saturated fat and added sugars. Under the guidelines, foods must contain minimum amounts of nutrient-dense ingredients like fruits, vegetables, or whole grains. Saturated fats cannot exceed 5% of daily recommended value, while sodium is capped at 10%. Manufacturers have until February 2028 to comply with the regulations.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=FDA+Sets+Stricter+Rules+for+'Healthy'+Food+Labels%3A+https%3A%2F%2Fnews.slashdot.org%2Fstory%2F24%2F12%2F20%2F1721248%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fnews.slashdot.org%2Fstory%2F24%2F12%2F20%2F1721248%2Ffda-sets-stricter-rules-for-healthy-food-labels%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://news.slashdot.org/story/24/12/20/1721248/fda-sets-stricter-rules-for-healthy-food-labels?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557203&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"OpenSUSE Announces New \"YQPkg\" Package Management Tool","url":"https://www.phoronix.com/news/openSUSE-YQPkg","date":1734714754,"author":"Michael Larabel","unread":true,"desc":"","content":"The openSUSE project announced today YQPkg as a new package management tool for openSUSE Linux distributions...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"OpenAI 2024 event: How to watch new ChatGPT product reveals and demos","url":"https://techcrunch.com/2024/12/20/openai-2024-event-how-to-watch-new-chatgpt-product-reveals-and-demos/","date":1734714000,"author":"Cody Corrall","unread":true,"desc":"","content":"<p>OpenAI is in the holiday spirit, it seems. The ChatGPT series of reveals, called “12 Days of OpenAI,” will be streamed live at 10 a.m. PT each weekday through December 20. So far, we&#8217;ve seen the launch of ChatGPT Pro, OpenAI’s $200 per month subscription plan; the full version of its “reasoning” o1 model; the [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Academic Writing is Getting Harder To Read","url":"https://news.slashdot.org/story/24/12/20/1524250/academic-writing-is-getting-harder-to-read?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734712920,"author":"msmash","unread":true,"desc":"","content":"Academic writing has become significantly less readable over the past 80 years, particularly in humanities and social sciences, according to an analysis of 347,000 PhD abstracts by The Economist. Using the Flesch reading-ease test, researchers found that readability scores in humanities and social sciences plunged from 37 in the 1940s to 18 in the 2020s. The decline was observed across all disciplines, with humanities and social sciences becoming as complex as natural sciences by the 1990s. The study, examining abstracts from 1812 to 2023, covered English-language doctoral theses from British universities.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Academic+Writing+is+Getting+Harder+To+Read%3A+https%3A%2F%2Fnews.slashdot.org%2Fstory%2F24%2F12%2F20%2F1524250%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fnews.slashdot.org%2Fstory%2F24%2F12%2F20%2F1524250%2Facademic-writing-is-getting-harder-to-read%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://news.slashdot.org/story/24/12/20/1524250/academic-writing-is-getting-harder-to-read?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557103&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"\"The Future is Where Any Business Gets Insights From Their Data Easily\" says Aniruth from Databricks","url":"https://hackernoon.com/the-future-is-where-any-business-gets-insights-from-their-data-easily-says-aniruth-from-databricks?source=rss","date":1734712310,"author":"Aniruth Narayanan","unread":true,"desc":"","content":"<p>\\</p>\n<blockquote>\n  <p>At HackerNoon, we value stories about building groundbreaking tech. These questions aren’t just about AI mechanics—they’re about the innovation, challenges, and creativity of bringing cutting-edge tools to life, a perfect fit for our community of tech leaders, builders, and future-minded readers.</p>\n</blockquote>\n<p>\\</p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>My name is <a href=\"https://www.aniruthn.com/\">Aniruth</a>. I work on the storage team at <a href=\"https://www.databricks.com/\">Databricks</a>, where we work on enabling customers to save large amounts of data in an open, scalable format with our Data Intelligence Platform. Specifically, I work on our interoperability efforts with Delta Lake and Apache Iceberg.</p>\n<p>\\</p>\n<h3 id=\"hackernoonwhatsthemainproblemyouraiproductisdesignedtosolveandwhatiseffectiveaboutyourapproachtosolvingit\">==HackerNoon:== What’s the main problem your AI product is designed to solve, and what is effective about your approach to solving it?</h3>\n<p><strong>==Aniruth==</strong>: Databricks unifies data and AI to give customers actionable intelligence—what we call data intelligence. This includes ingesting large amounts of data, ETL, large-scale storage, business intelligence queries, and AI workloads. The techniques used in machine learning in the past decade have been around since the 1980s; the rise of big data made it feasible to run algorithms at scale.</p>\n<p>\\\nTechniques like few shot prompting or RAG rely on high-quality data. Models that have better data win against those with better architectures. Databricks has put significant investment into leading efforts in the data space, pioneering the lakehouse architecture with open data formats and open governance, where customers are able to get the best insights with the best performance from data lakes.</p>\n<p>\\</p>\n<h3 id=\"whatcriteriadidyouusetoselectthespecificaimodelsforthisproductandhowdoesyourcompanymakedecisionslikethis\">What criteria did you use to select the specific AI models for this product, and how does your company make decisions like this?</h3>\n<p>We use AI models in a number of ways in the product - such as Llama 3 for the AI Assistant. We believe in an open data and AI ecosystem and encourage our customers to use any model of their choice. We help make sure customers have end-to-end governance across the AI lifecycle regardless of the models they use, so they can focus on making their models purpose-built for their use cases.</p>\n<p>\\</p>\n<h3 id=\"howdoyouensureyourproductdeliversaccurateandunbiasedresultstousers\">How do you ensure your product delivers accurate and unbiased results to users?</h3>\n<p>We have spent significant effort and investment in prioritizing accuracy and unbiased answers for AI usage within our products, and continue to conduct frequent testing.</p>\n<p>\\</p>\n<h3 id=\"whatisyourdayinthelifelikeasaproductmanager\">What is your day in the life like as a product manager?</h3>\n<p>The data and AI space is rapidly evolving, so it’s very important to keep up to date. My day can include talking to customers, market analysis, putting together a product requirements document, or preparing marketing materials. My favorite part is getting to make diagrams illustrating how things will work, as it’s pretty fun to transform an idea into a visual.</p>\n<p>\\</p>\n<h3 id=\"whatsthenextbigbreakthroughinaithateveryoneshouldbewatchingfor\">What’s the next big breakthrough in AI that everyone should be watching for?</h3>\n<p>There’s a lot of big breakthroughs coming soon. One that I’m particularly interested in is the hyperpersonalization of content. For the past decade, ads have been fine-tuned to the specific watcher. Some elements of content have been tuned, such as what thumbnail Netflix shows a user, but the actual content (the video itself) has not been. It’ll be interesting to see how directors/producers balance telling the story they want to and the user’s interests.</p>\n<p>\\</p>\n<h3 id=\"whatsbeenthebiggestchallengeyouvefacedinbringingthisaiproducttomarketfromconcepttolaunch\">What’s been the biggest challenge you’ve faced in bringing this AI product to market, from concept to launch?</h3>\n<p>I work on large-scale data storage, which can be very confusing to understand. We have various AI optimizations on data, but there’s often questions about when these optimizations are run, how they work, what they don’t cover, etc. With these kinds of questions, it is important to ensure we have clear, consistent messaging about what we are building and why. I’ve found that explaining the cause of limitations resonates very well with customers.</p>\n<p>\\</p>\n<h3 id=\"howdoyouenvisionaievolvingtobetterunderstandandrespondtohumanemotionsandwhatchallengesoropportunitiesdoyouseeinthatarea\">How do you envision AI evolving to better understand and respond to human emotions, and what challenges or opportunities do you see in that area?</h3>\n<p>Multimodal models are going to get significantly better in the coming years, which will change our primary mode of interaction with AI. Figuring out human emotion is significantly easier from visual or audio information compared to text. I think there's an opportunity to create more natural interactions in a wider array of scenarios.</p>\n<p>\\</p>\n<h3 id=\"whatperformancemetricsorkpisdoyoutracktogaugethesuccessofthisaiproduct\">What performance metrics or KPIs do you track to gauge the success of this AI product?</h3>\n<p>We typically want to see good feedback and usage. I talk to customers pretty often to get a sense of how and why they think about our products, which is key to explain why we see certain trends in metrics.</p>\n<p>\\</p>\n<h3 id=\"howdoyouapproachdesigningaproductexperiencethatsnotonlyfunctionalbutalsoengagingandmemorableforusers\">How do you approach designing a product experience that’s not only functional but also engaging and memorable for users?</h3>\n<p>Large-scale data products are notoriously challenging to use. Simple examples are easy to set up, but production workloads typically involve confusing configuration and code. It’s been a high priority for me to build out functionality that customers need, while making the product very simple to use.</p>\n<p>\\\nThe future is where any business gets insights from their data easily. In the current world, data-driven business insights are typically restricted to the biggest companies - but even they would prefer a simpler experience.</p>\n<p>\\</p>\n<h3 id=\"inthelongtermhowdoyouthinkaiwillhelptheindividualreachonesfullpotential\">In the long-term, how do you think AI will help the individual reach one’s full potential?</h3>\n<p>For the individual, I’m very excited about AI integrations into hardware. Up to now, we’ve largely seen AI in software applications like websites. There’s many larger applications of building devices that utilize AI, and we’re already starting to see some of those implications in cars and phones.</p>\n<p>\\</p>\n<h3 id=\"wheredoyouseetheproductevolvinginthenextfewyearsandwhatfeaturesareyoumostexcitedtoadd\">Where do you see the product evolving in the next few years, and what features are you most excited to add?</h3>\n<p>Databricks is on a path towards becoming increasingly simple and more powerful at the same time. There are a lot of efforts we are working on across the board, from making big-scale data and compute easy to work with to improving performance on queries and workflows. Personally, I think we have some exciting features coming soon throughout the product that make workflows way easier with AI. Examples include AI-generated comments on data, AI code suggestions in the notebook editors, and AI interfaces to chat with data (for example, Databricks AI/BI Genie).</p>\n<p>\\</p>\n<h3 id=\"whatsyourperspectiveonaisimpactonjobsandhowdoyouaddressthoseconcernsinyourproductstrategy\">What’s your perspective on AI’s impact on jobs, and how do you address those concerns in your product strategy?</h3>\n<p>There are concerns over whether AI would reduce the number of jobs. Our products are designed to increase valuable insights, which often come in conjunction with users. For example, with AI/BI Genie, users can create interfaces on their own data. This is a magical experience, where users can ask questions and get answers specific to them. In fact, users can even check the SQL being used to confirm it’s what they’re looking for. This is collaborative with analysts, reducing the time it takes them to go from idea to insight.</p>\n<p>\\</p>\n<h3 id=\"whatuserfeedbacksurprisedyouandledtochangesinyourroadmapstrategyorproductexperience\">What user feedback surprised you and led to changes in your roadmap, strategy or product experience?</h3>\n<p>One major surprise for me was the complexity that some of the larger companies have. This introduces requirements into the product that I wouldn’t have considered on my own. A common example is thinking of migration strategies when introducing a new product. Typically, large companies will have either put together existing technologies (commonly open-source software) or have built custom software to solve the problem that our new product offering tackles. It usually takes a bit of time to understand why and how these are put together to ensure we have a solution that covers all possibilities.</p>\n<hr />\n<p>:::info\nWould you like to take a stab at answering some of these questions?&nbsp;<strong><a href=\"https://hackernoon.com/preview/2sT6QnA98YCmMWQPEN4p?template=ai-product-manager-interview&ref=hackernoon.com\">The link for the template is&nbsp;HERE.</a></strong>&nbsp;Interested in reading the content from all of our writing prompts? Click&nbsp;<strong><a href=\"https://hackernoon.com/preview/2sT6QnA98YCmMWQPEN4p?template=ai-product-manager-interview&ref=hackernoon.com\">HERE.</a></strong></p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Swizzle Ventures raises $5M for inaugural fund addressing women’s health and wealth","url":"https://techcrunch.com/2024/12/20/swizzle-ventures-raises-5m-for-inaugural-fund-addressing-womens-health-and-wealth/","date":1734711759,"author":"Dominic-Madori Davis","unread":true,"desc":"","content":"<p>There is a new venture fund in town. Swizzle Ventures, founded by Jessica Kamada, former COO of the marketing agency Bamboo, has raised just over $5 million for its Fund I, according to an SEC filing. There was no target raise amount.  The firm, which quietly opened in 2023, is an early-stage firm looking to [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Wayland Protocols 1.39 Released With Data Control & Workspace Additions","url":"https://www.phoronix.com/news/Wayland-Protocols-1.39","date":1734710871,"author":"Michael Larabel","unread":true,"desc":"","content":"Jonas Ådahl of Red Hat just released Wayland Protocols 1.39 as the latest set of updates to this de facto repository for Wayland protocols...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"The HackerNoon Newsletter: EIP-1559: Separating Mechanisms From Memes (12/20/2024)","url":"https://hackernoon.com/12-20-2024-newsletter?source=rss","date":1734710666,"author":"Noonification","unread":true,"desc":"","content":"\n              \n        <p><strong>How are you, hacker?</strong></p>\n        <br />\n        <p>🪐 What’s happening in tech today, December 20, 2024?</p>\n        <br />\n        <p>\n          The\n          <a href=\"https://hackernoon.com/noonification\" target=\"_blank\" rel=\"noopener\"> HackerNoon Newsletter</a>\n          brings the HackerNoon \n          <a href=\"https://hackernoon.com\" target=\"_blank\" rel=\"noopener\">homepage</a>\n          straight to your inbox.\n          <a href=\"https://hackernoon.com/on-this-day\" target=\"_blank\" rel=\"noopener\">On this day,</a>\n          \n            <strong>The US Invaded Panama</strong> in 1989,  <strong>East Germany Opened the Berlin Wall For the First Time</strong> in 1963,  <strong>Elvis Presley Was Drafted to the US Army</strong> in 1957, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        <a href=\"https://hackernoon.com/eip-1559-separating-mechanisms-from-memes\" class=\"eventTitle\"><strong>EIP-1559: Separating Mechanisms From Memes</strong></a>\n       to \n        <a href=\"https://hackernoon.com/does-googles-willow-quantum-chip-put-bitcoins-cryptography-at-risk\" class=\"eventTitle\"><strong>Does Google’s Willow Quantum Chip Put Bitcoin’s Cryptography at Risk? </strong></a>,\n       let’s dive right in.\n          \n        </p>\n      \n              \n          <h2><a href=\"https://hackernoon.com/how-to-automatically-publish-your-npm-package-using-github-actions\">How to Automatically Publish Your NPM Package Using GitHub Actions</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/f2OZeUyGKadvdOjeANOTzJzLp2q2-35a3v83.jpeg\" alt /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/kingflamez\">@kingflamez</a> [ 9 Min read ] Learn how to set up a CI/CD pipeline with GitHub Actions to automatically test, version, and publish your npm package. Streamline your workflow, ensure quality, <a href=\"https://hackernoon.com/how-to-automatically-publish-your-npm-package-using-github-actions\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/eip-1559-separating-mechanisms-from-memes\">EIP-1559: Separating Mechanisms From Memes</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-ic034m1.png\" alt /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 25 Min read ] EIP-1559 is an important but misunderstood Ethereum upgrade. Learn the facts about EIP-1559, including its design goals, rationale, features, and benefits.  <a href=\"https://hackernoon.com/eip-1559-separating-mechanisms-from-memes\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/metaverse-growth-brings-new-data-protection-headaches\">Metaverse Growth Brings New Data Protection Headaches</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/YdksaOgUsRdlbtMutjJRekoeG9z2-rg036ke.jpeg\" alt /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/lihisegev\">@lihisegev</a> [ 4 Min read ] A world of possibilities is coming, but it’s coupled with the biggest security risks of our time. How can we protect ourselves in a data-miner’s paradise? <a href=\"https://hackernoon.com/metaverse-growth-brings-new-data-protection-headaches\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/does-googles-willow-quantum-chip-put-bitcoins-cryptography-at-risk\">Does Google’s Willow Quantum Chip Put Bitcoin’s Cryptography at Risk? </a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/T7eOVLz9AZaymTdnRVflwkQCfIk2-b543e4f.webp\" alt /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/niteshpadghan\">@niteshpadghan</a> [ 5 Min read ] Willow by Google is a quantum computing breakthrough, but it;s not powerful enough to disrupt bitcoins cryptographic algorithm.  <a href=\"https://hackernoon.com/does-googles-willow-quantum-chip-put-bitcoins-cryptography-at-risk\">Read More.</a></p>\n        \n              \n        <br />\n        <p>🧑‍💻 What happened in your world this week?</p>\n        <p>\n          It's been said that\n          <a href=\"https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6\">writing can help consolidate technical knowledge</a>,\n          <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\">establish credibility</a>,\n          <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\"> and contribute to emerging community standards</a>.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        </p>\n        <br />\n        <p>\n          <a href=\"https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble\">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>\n        </p>\n        <br />\n        <p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>\n        <br />\n        <p><img src=\"https://cdn.hackernoon.com/images/the-hackernoon-newsletter-footer.png\" alt /></p>\n      \n            ","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Japanese Firm's USB-C Cable Rotates 360 Degrees","url":"https://it.slashdot.org/story/24/12/20/1512221/japanese-firms-usb-c-cable-rotates-360-degrees?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734710520,"author":"msmash","unread":true,"desc":"","content":"Japanese electronics manufacturer Sanwa Supply has launched a rotating USB-C cable capable of 240W power delivery but sadly USB 2.0 transfer speeds, Tom'sHardware reports. The $16 cable features a 360-degree rotating connector and is available in 1-meter and 1.8-meter lengths, with both USB-C to USB-C and USB-A to USB-C options, the report adds.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Japanese+Firm's+USB-C+Cable+Rotates+360+Degrees%3A+https%3A%2F%2Fit.slashdot.org%2Fstory%2F24%2F12%2F20%2F1512221%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fit.slashdot.org%2Fstory%2F24%2F12%2F20%2F1512221%2Fjapanese-firms-usb-c-cable-rotates-360-degrees%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://it.slashdot.org/story/24/12/20/1512221/japanese-firms-usb-c-cable-rotates-360-degrees?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557085&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Lerer Hippeau files to raise Fund IX","url":"https://techcrunch.com/2024/12/20/lerer-hippeau-files-to-a-raise-fund-ix/","date":1734710464,"author":"Dominic-Madori Davis","unread":true,"desc":"","content":"<p>Lerer Hippeau, one of New York's most prolific and A-list VC firms, has filed to raise its ninth fund, according to an SEC filing made Wednesday.</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Ashish Komal: Leveraging Cloud-Based Solutions to Make a Positive Impact","url":"https://hackernoon.com/ashish-komal-leveraging-cloud-based-solutions-to-make-a-positive-impact?source=rss","date":1734710413,"author":"Jon Stojan Media","unread":true,"desc":"","content":"<p>\\\nBusinesses worldwide grapple with ways to become more agile, cost-efficient, and competitive. The rise of cloud migration is a welcome solution for helping companies achieve those ends. However, migrating old systems to new environments raises concerns about infrastructure compatibility, data security, cost management, and skill gaps. Solution Architect <strong><a href=\"https://www.linkedin.com/in/ashishkomal/\">Ashish Komal</a></strong> has dealt with these issues for over 16 years. He’s helped clients transition to more high-performance, cloud-based systems. Along the way, he has gained valuable insights and developed effective strategies that have resolved some of the most difficult cloud migration projects.</p>\n<h2 id=\"thebiggestproblemswithcloudmigration\">The Biggest Problems With Cloud Migration</h2>\n<p>“Always be enthusiastic to learn and explore the new solution,” Ashish says. This upbeat attitude and open-mindedness are two traits he has relied on throughout his career. Those attributes are essential for tackling the monumental hurdles affecting cloud migration.</p>\n<p>\\\nIn the early days of cloud adoption, some within the business community resisted this new technology. Although this advancement inspired hope by introducing a better way to achieve company goals, it also stirred up skepticism. Moving a whole IT infrastructure from an old environment to a new one raised many questions. Is it worth the time, effort, and cost? Will it improve the bottom line? Who can handle this massive overhaul?</p>\n<p>\\\nAshish came face to face with the clients’ skepticism. He realized his most important job, aside from leading a cloud migration, was to build trust. “I overcame these challenges through meticulous planning, transparent communication with stakeholders, and ensuring my team was equipped with the necessary training and resources,” he explains.</p>\n<p>\\\nAnother issue IT professionals like Ashish contend with is how fast technology advances. Although he has accrued much expertise over the past 16 years, he doesn't remain stagnant. “I committed myself to continuous learning and encouraged my team to do the same,” he reveals. He places a high value on staying on top of the latest innovations. As a result, Ashish has created a workplace culture where education and adaptability set the standard for excellence.</p>\n<h2 id=\"therealworldimpactofcloudcomputing\">The Real-World Impact of Cloud Computing</h2>\n<p>Ashish's experience can be boiled down to one belief: The cloud is the future of enterprise IT. His accomplishments with past projects ignited that belief and inspired him to specialize in designing and implementing robust, scalable, and secure cloud solutions.</p>\n<p>\\\n“A pivotal moment in my journey occurred early in my career,” Ashishl reveals. He was part of a team that migrated a legacy system to a modern cloud-based infrastructure for a major healthcare client. The in-house IT team was accustomed to the traditional on-premises setup. Despite the obstacles, Ashishl's team completed the migration. The outcome for the client included significant performance improvements and cost savings.</p>\n<p>\\\nOne of Ashish’s most career-changing events took place during the COVID-19 pandemic. The healthcare industry was under tremendous strain. A change was in order, but a mere technological upgrade was not enough. There was a heightened urgency for a new, secure digital platform.</p>\n<p>\\\nThere was a need to manage the surge in patient data. Additionally, healthcare workers on the front lines required more support. As the Lead Solution Architect, Ashish fast-tracked the implementation of cloud-based infrastructure and AI capabilities without compromising quality or security.</p>\n<p>\\\nThe platform's data analytics tools helped track infection rates, predict hot spots, and manage resources. The AI-driven insights enabled healthcare providers to make quicker, more informed treatment decisions for patients affected by the virus. Moreover, the cloud infrastructure made it easier for remote medical professionals to collaborate at a time when lockdowns were the norm and in-person consultations were limited.</p>\n<p>\\\n“This experience was a profound reminder of the impact that our work in it can have on society, especially in times of need,” Ashish reflects. He described that moment in his career as humbling and empowering. It reinforced his commitment to leveraging technology for the greater good.</p>\n<h2 id=\"whoisashishkomalacareerdriventhepowerofcomputing\">Who is Ashish Komal: A Career Driven the Power of Computing</h2>\n<p><img src=\"https://cdn.hackernoon.com/images/InxBRjRIs6M1kdhuWcyNHiiUrxm1-wo034xf.jpeg\" alt=\"Ashish Komal\" /></p>\n<p>\\\nAshish started his IT career after earning a BTech in computer science. Since then he has collaborated with clients worldwide to modernize their data centers by transitioning to high-performance systems and public cloud infrastructures. His role is to design robust systems that help maintain the flawless operation of business-critical applications. “During my college years, I was deeply intrigued by the transformative power of computing and the emerging field of cloud technology,” he says.</p>\n<p>\\\nCloud computing and architecture are major areas of expertise for Ashish. His extensive experience designing and implementing cloud solutions positions him as an expert in cloud computing. As a result, he’s proficient in creating architectures tailored to the unique needs of organizations. In his current role, he leads a team of consultants who deliver the highest quality solutions to the end users. “My leadership is about ensuring excellence in our deliverables and fostering the professional growth of my team members, \" he explains.</p>\n<h2 id=\"ahighlyawardedcareer\">A Highly-Awarded Career</h2>\n<p>Understanding Ashish’s contributions to the tech industry, it won’t be much of a surprise to know that he’s been recognized globally.</p>\n<p>\\\nAshish garnered the Indian Achiever’s Award for his exceptional contributions to a complex project that resulted in significant client satisfaction. He was honored with the prestigious Titan Award for Business Technology Solutions - Cloud Solutions, recognizing his pioneering efforts in leveraging innovative cloud strategies to drive transformative outcomes for his clients. Additionally, Ashish received the Golden Recognition Award for his quick thinking and effective problem-solving skills during a critical phase of a system integration project, helping to avoid potential delays and cost overruns. These honors reflect his ability to deliver impactful results, drive client satisfaction, and demonstrate outstanding leadership and teamwork.</p>\n<p>\\\nAshish remains humble despite his numerous accomplishments. “These awards are not just personal triumphs but also reflect the collaborative spirit and hard work of the teams I have been a part of,” he says.</p>\n<p>\\\nThe honors also motivate him to continue striving for excellence within the IT field. For example, he has spearheaded the creation of a streamlined cloud migration framework. The tool facilitates the effortless transition of outdated systems to the cloud environment.</p>\n<p>\\\nThe framework minimizes the intricacies and potential risk of migrations. This transparent, modular process allows for customization that meets the unique requirements of diverse organizations. Its implementation has expedited the digital transformation efforts of numerous enterprises.</p>\n<h2 id=\"experttipsonhowtohandlecloudmigration\">Expert Tips on How to Handle Cloud Migration</h2>\n<p>Ashish has valuable insights that can help organizations manage widespread Cloud migrations. The following are three of his best suggestions:</p>\n<p>\\</p>\n<ul>\n<li><strong>Conduct Comprehensive Assessment and Planning</strong>: Perform a detailed assessment of current infrastructure and strategic planning to address potential migration challenges.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><strong>Prioritize Security and Compliance</strong>: Set up robust security measures and compliance checks to safeguard data during migration.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><strong>Maintain Team Readiness</strong>: Train and equip teams with the necessary skills to manage Cloud environments effectively.</li>\n</ul>\n<h2 id=\"aleadershipstylethatinspiresothers\">A Leadership Style That Inspires Others</h2>\n<p>You can argue that the best leaders are those who lead by example. If that’s the case, Ashish's leadership style is noteworthy. It distinguishes him from his fellow IT professionals.</p>\n<p>\\\nHe inspires his peers by leading substantial projects. “By directing large-scale digital transformation initiatives for healthcare and Life Science organizations , I showcase the effectiveness of strategic planning, the importance of teamwork, and the value of resilience,” Ashish explains. The projects he has directed prove what can be achieved through collective effort.</p>\n<p>\\\nAshish’'s expertise offers valuable lessons for organizations seeking to implement a cloud migration solution. He has a strategic approach that sets a benchmark for successful cloud transitions.</p>\n<h2 id=\"innovationandeducationdriveschange\">Innovation and Education Drives Change</h2>\n<p>What's in store for this influential Solution Architect? “My future goals are anchored in the belief that continuous innovation and education are key to driving meaningful change,” he shares. With that in mind, Ashish is making his mark in advancing cloud education.</p>\n<p>\\\nHe's broadening his engagement on educational platforms like Great Learning. The aim is to equip a wider audience with the skills necessary to excel in cloud computing. “By empowering a well-informed workforce, I anticipate accelerating the pace of digital transformation across multiple sectors,” he shares.</p>\n<p>\\\nThe fact that <strong><a href=\"https://ashishkomal.com/\">Ashish Komal</a></strong> has taken on this endeavor is no surprise. He has placed a premium on education, innovation, and teamwork throughout his 16-year career. Has his career choice been peppered with hurdles? Absolutely. However, he has overcome them by having the right mindset. “Persistence pays off, never shy from hard work,” he affirms.</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"The AI war between Google and OpenAI has never been more heated","url":"https://arstechnica.com/information-technology/2024/12/google-and-openai-blitz-december-with-so-many-ai-releases-its-hard-to-keep-up/","date":1734709445,"author":"Benj Edwards","unread":true,"desc":"","content":"\n              <p>Over the past month, we've seen a rapid cadence of notable AI-related announcements and releases from both Google and OpenAI, and it's been making the AI community's head spin. It has also poured fuel on the fire of the OpenAI-Google rivalry, an accelerating game of one-upmanship taking place unusually close to the Christmas holiday.</p>\n<p>\"How are people surviving with the firehose of AI updates that are coming out,\" <a href=\"https://x.com/BowTiedFox/status/1867673263846969607\">wrote</a> one user on X last Friday, which is still a hotbed of AI-related conversation. \"in the last &lt;24 hours we got gemini flash 2.0 and chatGPT with screenshare, deep research, pika 2, sora, chatGPT projects, anthropic clio, wtf it never ends.\"</p>\n<p>Rumors travel quickly in the AI world, and people in the AI industry had been expecting OpenAI to ship some major products in December. Once OpenAI announced \"<a href=\"https://arstechnica.com/ai/2024/12/openai-teases-12-days-of-mystery-product-launches-starting-tomorrow/\">12 days of OpenAI</a>\" earlier this month, Google jumped into gear and seemingly decided to try to one-up its rival on several counts. So far, the strategy appears to be working, but it's coming at the cost of the rest of the world being able to absorb the implications of the new releases.</p><p><a href=\"https://arstechnica.com/information-technology/2024/12/google-and-openai-blitz-december-with-so-many-ai-releases-its-hard-to-keep-up/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/information-technology/2024/12/google-and-openai-blitz-december-with-so-many-ai-releases-its-hard-to-keep-up/#comments\">Comments</a></p>\n\n            ","flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/speedy_wind_dog-1-1152x648.jpg","enclosureMime":""},{"title":"Arizona’s getting an online charter school taught entirely by AI","url":"https://techcrunch.com/2024/12/20/arizonas-getting-an-online-charter-school-taught-entirely-by-ai/","date":1734708964,"author":"Paul Sawers","unread":true,"desc":"","content":"<p>The newest online-only school greenlighted by the Arizona State Board for Charter Schools comes with a twist: The academic curriculum will be taught entirely by AI. Charter schools &#8212; independently operated but publicly funded &#8212; typically get greater autonomy compared to traditional public schools when it comes to how subjects are taught. But Unbound Academy&#8217;s [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Arch Linux Based CachyOS Takes The Lead On Intel Arrow Lake","url":"https://www.phoronix.com/review/intel-arrowlake-cachyos","date":1734708818,"author":"Michael Larabel","unread":true,"desc":"","content":"Following the recent Intel Core Ultra 9 285K Windows 11 vs. Ubuntu Linux benchmarks I wanted to expand the testing to look at how well other Linux distributions as well were performing on this new 24-core Arrow Lake desktop processor. To much surprise Intel's own Clear Linux distribution didn't take the top spot this round but as a surprising upset the Arch Linux based CachyOS distribution outperformed Clear Linux, Ubuntu, Arch Linux, and Fedora Workstation on this flagship Arrow Lake processor.","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Powerloom's Data Network Reaches Milestone as Mainnet Launch Approaches","url":"https://hackernoon.com/powerlooms-data-network-reaches-milestone-as-mainnet-launch-approaches?source=rss","date":1734708292,"author":"Ishan Pandey","unread":true,"desc":"","content":"<p><a href=\"https://powerloom.io/\">Powerloom</a>'s decentralized network has recorded over one billion data points through its network of 5,300 Snapshotter nodes since its testnet launch in February 2024. The nodes capture state changes and event emissions from blockchain activities, converting them into structured datasets.</p>\n<p>\\\nThe platform aims to address data accessibility challenges in blockchain applications. Web3 applications can access these snapshots directly without additional queries or RPC requests, which reduces the computational resources needed for data processing. The system implements a consensus mechanism for data verification, with snapshots stored on IPFS using Content Identifiers (CIDs). The datasets maintain synchronization with blockchain blocks and receive updates to reflect current blockchain states, which helps maintain data accuracy for applications.</p>\n<p>\\\nSwaroop Hegde, Co-Founder of Powerloom, notes that the distributed network of Snapshotter nodes contributes to the infrastructure's resilience and verification capabilities. The platform plans to launch its mainnet in January 2025. The technology focuses on making blockchain data more accessible for projects with limited resources. Traditional methods of processing blockchain data into usable formats require substantial computational power and technical expertise. Powerloom's approach provides pre-processed \"composed Snapshots\" that applications can integrate directly.</p>\n<p>\\\nThe platform's capabilities are demonstrated through <a href=\"https://app.gpm.lol/\">Generative Prediction Markets</a> (GPM), which creates automated prediction markets at five-minute intervals. The system has processed over 500,000 predictions from more than 10,000 wallet addresses across 50,000 markets.</p>\n<p>\\\nPowerloom has initiated a <a href=\"https://app.gpm.lol/\">GPM</a> Tournament running from December 20, 2024, to January 3, 2025, with 500,000 $POWER tokens allocated for rewards based on leaderboard rankings. The $POWER token launch is scheduled for January 2025, incorporating features such as staking and community rewards.</p>\n<p>\\\nThe platform's architecture supports various blockchain-based applications, including DeFi protocols, GameFi applications, and NFT platforms. Each dataset generated through Powerloom undergoes peer validation and consensus verification, with records maintained on IPFS for transparency.</p>\n<p>\\\nThis development occurs as blockchain applications evolve to combine social and financial elements. The technology aims to support real-time data requirements for applications that involve user interactions such as likes, follows, and subscriptions, while maintaining the decentralized benefits of blockchain technology.</p>\n<p>\\\nThe system's approach to data processing and verification suggests potential applications in areas such as blockchain analytics and decentralized social networks. By providing processed datasets, Powerloom enables developers to focus on application development rather than data infrastructure maintenance.</p>\n<p>\\\nDon’t forget to like and share the story!</p>\n<p>:::tip\n<strong>Vested Interest Disclosure:</strong>&nbsp;This author is an independent contributor publishing via our&nbsp;<strong><a href=\"https://business.hackernoon.com/business-blogging/?ref=hackernoon.com#buy\">business blogging program</a></strong>. HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYOR</p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Ransomware attack on health giant Ascension hits 5.6 million patients","url":"https://techcrunch.com/2024/12/20/ransomware-attack-on-health-giant-ascension-hits-5-6-million-patients/","date":1734708225,"author":"Zack Whittaker","unread":true,"desc":"","content":"<p>The cyberattack on Ascension ranks as the third-largest healthcare-related breach of 2024.</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Steam Gamers Spend Just 15% of Time on New Releases","url":"https://games.slashdot.org/story/24/12/20/151224/steam-gamers-spend-just-15-of-time-on-new-releases?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734708120,"author":"msmash","unread":true,"desc":"","content":"Steam users spent only 15% of their total gaming time on new releases in 2024, according to the platform's year-end review, an increase from 9% in 2023 but below 2022's 17%. \n\nLegacy titles dominated playtime, with 47% spent on games released in the past seven years and 37% on titles older than eight years. New online games like Helldivers 2 and Black Myth: Wukong helped drive 2024's modest uptick in new game engagement across Steam's library of over 200,000 titles, while established service games like Counter-Strike and Dota 2 maintained their long-standing popularity.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Steam+Gamers+Spend+Just+15%25+of+Time+on+New+Releases%3A+https%3A%2F%2Fgames.slashdot.org%2Fstory%2F24%2F12%2F20%2F151224%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Fgames.slashdot.org%2Fstory%2F24%2F12%2F20%2F151224%2Fsteam-gamers-spend-just-15-of-time-on-new-releases%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://games.slashdot.org/story/24/12/20/151224/steam-gamers-spend-just-15-of-time-on-new-releases?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557079&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Rivian executives accused of harassment in previously unreported lawsuits","url":"https://techcrunch.com/2024/12/20/rivian-executives-accused-of-harassment-in-previously-unreported-lawsuits/","date":1734706800,"author":"Sean O'Kane","unread":true,"desc":"","content":"<p>Four employees have sued Rivian in separate lawsuits this year over allegations they were harassed, in some cases by top executives, and that the company’s leadership did little to address their concerns, according to a TechCrunch review of court records. Rivian has also reached settlements in three other harassment and discrimination cases, TechCrunch has learned.&#160; [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Google Cuts Managers and VPs in Efficiency Drive","url":"https://tech.slashdot.org/story/24/12/20/1438217/google-cuts-managers-and-vps-in-efficiency-drive?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734705900,"author":"msmash","unread":true,"desc":"","content":"Google has reduced its senior management positions by 10% as part of an ongoing efficiency initiative, CEO Sundar Pichai announced during a company-wide meeting earlier this week. \n\nThe restructuring affected managers, directors, and vice presidents, with some roles eliminated and others converted to non-management positions, a Google spokesperson told BusinessInsider. The move follows Google's January 2023 layoff of 12,000 employees and Pichai's September 2022 goal to improve company efficiency by 20%.<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Google+Cuts+Managers+and+VPs+in+Efficiency+Drive%3A+https%3A%2F%2Ftech.slashdot.org%2Fstory%2F24%2F12%2F20%2F1438217%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Ftech.slashdot.org%2Fstory%2F24%2F12%2F20%2F1438217%2Fgoogle-cuts-managers-and-vps-in-efficiency-drive%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://tech.slashdot.org/story/24/12/20/1438217/google-cuts-managers-and-vps-in-efficiency-drive?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557071&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"The Evolution of Blockchain Layer 2 Networks: Scaling Solutions for a Decentralized Future","url":"https://hackernoon.com/the-evolution-of-blockchain-layer-2-networks-scaling-solutions-for-a-decentralized-future?source=rss","date":1734704541,"author":"Matvii Diadkov","unread":true,"desc":"","content":"<p>The emergence of the smart contract feature in blockchains, popularized by Ethereum, demonstrated the technology’s potential to transform all aspects of the finance industry through tokenization, trustless platforms, and decentralized governance.</p>\n<p>\\\nAlthough this was a major leap from Bitcoin’s rigid network, next-gen blockchains required unprecedented scalability. To compete with traditional finance systems, blockchains need a lot of processing power to handle thousands of transactions per second while keeping costs feasible. Ethereum set the standard but has faced persistent issues like <strong><a href=\"https://cointelegraph.com/news/ethereum-network-congestion-shuts-down-crypto-gaming-casino\">network congestion</a></strong> and high <strong><a href=\"https://bitinfocharts.com/comparison/ethereum-transactionfees.html\">transaction fees</a></strong>.</p>\n<p>\\\nThe growing need for scalability paved the way for the development of layer 2 networks, which are blockchains built atop existing layer 1s to boost scalability.</p>\n<h2 id=\"thegenesisoflayer2networks\"><strong>The Genesis of Layer 2 Networks</strong></h2>\n<p>While layer 2 networks have surged in popularity around Ethereum, the first-ever layer 2 was built for Bitcoin. Launched in 2015, the Lightning Network introduced a payment channel solution capable of handling thousands of transactions per second off-chain. It enables any two parties to create an off-chain channel and exchange high volumes of BTC at a low cost.</p>\n<p>\\\nDuring the initial coin offering (ICO) craze in 2017-2018, Ethereum saw the first wave of layer 2 networks as well, including Raiden Network, Matic (now Polygon), and OmiseGO (now OMG).</p>\n<p>\\\nRaiden, launched in 2017, has operated as a state channel to handle Ethereum transactions off-chain. It shares similarities with the Lightning Network, but it doesn’t support decentralized applications (dApps).</p>\n<p>\\\nTo unlock the full potential of Ethereum dApps, developers introduced more advanced layer 2 technologies, including sidechains and rollups, enabling compatibility with the Ethereum Virtual Machine (EVM), greater scalability, and lower transaction costs.</p>\n<h2 id=\"typesoflayer2solutions\"><strong>Types of Layer 2 Solutions</strong></h2>\n<p>To better understand the evolution of layer 2 networks, let’s discuss the main types in roughly chronological order:</p>\n<p>\\</p>\n<ul>\n<li><p>State channels – this is the most primitive form of layer 2. It enables the development of a peer-to-peer (P2P) channel between two parties to transact unlimited amounts of assets off-chain. A state channel will record only the first and the last transactions on the mainnet. A multi-signature wallet holds the channel’s funds, and participants sign off-chain transactions until they close the channel. \\n While channels like the Lightning Network can greatly increase the speed of transactions between two parties, they are suitable for payment use cases only and cannot be integrated into dApps.</p>\n<p>\\</p></li>\n<li><p>Plasma chains – this methodology uses Merkle trees to build additional chains to the underlying mainnet – they’re usually called child chains. These smaller chains execute transactions off-chain and commit proofs to the mainnet. The chains have a waiting period for users to dispute the validity of transactions by submitting fraud proofs. The child chains are connected to the mainnet via smart contracts stipulating all the rules dictating how they must behave. Plasma technology was<a href=\"https://www.coindesk.com/markets/2017/08/12/ethereum-lightning-buterin-and-poon-unveil-plasma-scaling-plan\"> </a><strong><a href=\"https://www.coindesk.com/markets/2017/08/12/ethereum-lightning-buterin-and-poon-unveil-plasma-scaling-plan\">first introduced </a></strong>by Ethereum’s Vitalik Buterin and eventually integrated by Matic (now Polygon) and OmiseGO. Plasma solutions partially support smart contracts, being capable of operating as bridges. However, they’re not suitable for more complex dapp transactions.</p></li>\n</ul>\n<p>\\</p>\n<ul>\n<li><p>Sidechains – these are independent blockchains that run in parallel to the underlying mainnet, e.g., Ethereum. They operate based on their independent consensus algorithms and are connected to the mainnet via bridges. Polygon started as a plasma chain and eventually turned into a sidechain, offering faster Ethereum transactions at a lower cost. Sidechains are dApp-friendly and have been used in decentralized finance (DeFi), non-fungible tokens (NFT), and Web3 gaming markets.</p>\n<p>\\</p></li>\n<li><p>Rollups – rollups have become the most popular scaling solution. They bundle Ethereum transactions off-chain and submit proofs on the mainnet, sharing its security while reducing transaction load. The great thing about rollups is that they can be fully integrated into dApps as they support complex smart contract operations. There are two types of rollups: optimistic and zero-knowledge (ZK) rollups. The former ones assume that all transactions are valid by default, offering a seven-day window to dispute invalid activity. While this greatly reduces costs, it offers true finality only after one week. Elsewhere, ZK rollups verify all transactions with ZK proofs before submitting them to the mainnet, offering greater privacy and security compared to optimistic rollups. However, due to the complexity of ZK rollups and their initial lower EVM compatibility, optimistic rollups have experienced a much higher adoption rate. Popular optimistic rollups include Arbitrum, OP Mainnet (ex Optimism), and Base.</p></li>\n</ul>\n<h2 id=\"keydevelopmentsinlayer2networks\"><strong>Key Developments in Layer 2 Networks</strong></h2>\n<p>With the emergence of decentralized finance (DeFi) and Web3 trends (including gaming, metaverse, and decentralized gambling), Ethereum has become the main ground for new layer 2 technologies. Due to their limitations, state channels and plasma have lost competition. Since 2021, the main layer 2 battle has been fought between optimistic and ZK rollups. In December 2024, the total value locked (TVL) on Ethereum layer 2s hit a record $60 billion, with Arbitrum, OP, and Base accounting for 75% of it.</p>\n<p>\\n  <img src=\"https://cdn.hackernoon.com/images/dNDmbEwasQUhkkwuUypXDwTWtqI2-2024-12-20T14:22:17.144Z-e2mmp1zgjsr32zzcqj38wig6\" alt=\"https://l2beat.com/scaling/tvl\" /></p>\n<p>Ethereum layer 2s have grown into complex ecosystems offering development and integration tools across all use cases. Some platforms even provide layer 3 networks for enhanced performance and customization. For example, Arbitrum Orbit is a layer 3 on Arbitrum, while zkSync has introduced the concept of hyperchains, a network of customizable and trustless linked layer 3 chains. The success of Ethereum layer 2s has been extended to Bitcoin as well, which saw the rapid development of layer 2s supporting smart contracts and sharing compatibility with Ethereum. Most of these are sidechains. Some examples include Stacks, Rootstock, Merlin, and Core. The TVL of Bitcoin sidechains soared to nearly $3 billion.</p>\n<p>\\n  <img src=\"https://cdn.hackernoon.com/images/dNDmbEwasQUhkkwuUypXDwTWtqI2-2024-12-20T14:22:17.146Z-mdrp7drrr5imwt0kppvsfaye\" alt=\"https://www.bitcoinlayers.org/?status=Metrics&layer-chart=separate&nbsp;\" /></p>\n<p>In addition to Ethereum and Bitcoin, other blockchains have developed their own layer 2 solutions. For example, the BNB Chain introduced opBNB, while Solana is preparing to launch <strong><a href=\"https://soo.network/\">SOON</a></strong>.</p>\n<h2 id=\"challengesandopportunitiesforlayer2networkshowtheyimpactthefutureofblockchain\"><strong>Challenges and Opportunities for Layer 2 Networks: How They Impact the Future of Blockchain</strong></h2>\n<p>While many layer 2s offer impressive scaling, their adoption is hindered by several market-wide challenges, such as complexity, liquidity fragmentation, and security trade-offs. When it comes to Ethereum, interoperability remains a major concern, as assets and data transferred across different layer 2s can become siloed. The network needs cross-chain bridges to improve asset mobility and liquidity, but they can become vulnerable to hacking attacks. Another problem is that some layer 2 solutions rely on centralized validators, posing risks to network security.</p>\n<p>\\\nDespite challenges, layer 2 adoption continues to grow. As DeFi and Web3 apps expand, developers are building more user-friendly dApps using rollups and sidechains.</p>\n<p>\\\nLooking ahead, layer 3 protocols could redefine scalability by offering custom-built sub-networks for specialized apps. Given their ability to cut costs and boost throughput, layer 2s could power the next wave of mainstream blockchain adoption.</p>\n<p>\\n </p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Why Apple sends spyware victims to this nonprofit security lab","url":"https://techcrunch.com/2024/12/20/why-apple-sends-spyware-victims-to-this-nonprofit-security-lab/","date":1734704032,"author":"Lorenzo Franceschi-Bicchierai","unread":true,"desc":"","content":"<p>Cybersecurity experts, who work with human rights defenders and journalists, agree that Apple is doing the right thing by sending notifications to victims of mercenary spyware — and at the same time refusing to forensically analyze the devices. </p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Senators Rip Into Automakers For Selling Customer Data and Blocking Right To Repair","url":"https://tech.slashdot.org/story/24/12/20/147242/senators-rip-into-automakers-for-selling-customer-data-and-blocking-right-to-repair?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1734703620,"author":"msmash","unread":true,"desc":"","content":"A bipartisan group of senators is calling out the auto industry for its \"hypocritical, profit-driven\" opposition to national right-to-repair legislation, while also selling customer data to insurance companies and other third-party interests. From a report: In a letter sent to the CEOs of the top automakers, the trio of legislators -- Sens. Elizabeth Warren (D-MA), Jeff Merkley (D-OR), and Josh Hawley (R-MO) -- urge them to better protect customer privacy, while also dropping their opposition to state and national right-to-repair efforts. \n\n\"Right-to-repair laws support consumer choice and prevent automakers from using restrictive repair laws to their financial advantage,\" the senators write. \"It is clear that the motivation behind automotive companies' avoidance of complying with right-to-repair laws is not due to a concern for consumer security or privacy, but instead a hypocritical, profit-driven reaction.\"<p><div class=\"share_submission\" style=\"position:relative;\">\n<a class=\"slashpop\" href=\"http://twitter.com/home?status=Senators+Rip+Into+Automakers+For+Selling+Customer+Data+and+Blocking+Right+To+Repair%3A+https%3A%2F%2Ftech.slashdot.org%2Fstory%2F24%2F12%2F20%2F147242%2F%3Futm_source%3Dtwitter%26utm_medium%3Dtwitter\"><img src=\"https://a.fsdn.com/sd/twitter_icon_large.png\"></a>\n<a class=\"slashpop\" href=\"http://www.facebook.com/sharer.php?u=https%3A%2F%2Ftech.slashdot.org%2Fstory%2F24%2F12%2F20%2F147242%2Fsenators-rip-into-automakers-for-selling-customer-data-and-blocking-right-to-repair%3Futm_source%3Dslashdot%26utm_medium%3Dfacebook\"><img src=\"https://a.fsdn.com/sd/facebook_icon_large.png\"></a>\n\n\n\n</div></p><p><a href=\"https://tech.slashdot.org/story/24/12/20/147242/senators-rip-into-automakers-for-selling-customer-data-and-blocking-right-to-repair?utm_source=rss1.0moreanon&amp;utm_medium=feed\">Read more of this story</a> at Slashdot.</p><iframe src=\"https://slashdot.org/slashdot-it.pl?op=discuss&amp;id=23557049&amp;smallembed=1\" style=\"height: 300px; width: 100%; border: none;\"></iframe>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Energy Revolution Ventures’ $18M fund lays a bet on ‘new chemistry’ startups in energy and hydrogen","url":"https://techcrunch.com/2024/12/20/energy-revolution-ventures-18m-fund-lays-a-bet-on-new-chemistry-startups-in-energy-and-hydrogen/","date":1734703434,"author":"Mike Butcher","unread":true,"desc":"","content":"<p>What happens when a chemical engineer, who’s previously built a hydrogen-powered drone, becomes a venture capitalist? Energy Revolution Ventures (ERV), that’s what. The VC has now closed an $18 million seed and Series A fund to invest in deep tech, such as energy storage, carbon capture, and, yes, hydrogen technologies.  Marcus Clover, co-founder and partner [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"‘Genius Girl’ goes from inspiring a Korean TV show character to raising a $100 million AI fund","url":"https://techcrunch.com/2024/12/20/genius-girl-goes-from-inspiring-a-korean-tv-show-character-to-raising-a-100-million-ai-fund/","date":1734703200,"author":"Margaux MacColl","unread":true,"desc":"","content":"<p>Principle Venture Partners will write early-stage checks anywhere from $100,000 to “single digit millions.” </p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"DXVK 2.5.2 Brings Fixes & Optimizations For Direct3D 9 / 10 / 11 Atop Vulkan","url":"https://www.phoronix.com/news/DXVK-2.5.2-Released","date":1734702489,"author":"Michael Larabel","unread":true,"desc":"","content":"DXVK 2.5.2 is out today as the newest point release to this open-source software implementing the Direct3D 9 / 10 / 11 APIs atop Vulkan for powering Windows games on Valve's Steam Play (Proton) as well as being used by other software and some games directly...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Liquorix vs. Linux 6.12 Upstream Kernel Performance Across Many Workloads","url":"https://www.phoronix.com/news/Linux-6.12-Liquorix-Performance","date":1734700495,"author":"Michael Larabel","unread":true,"desc":"","content":"A Phoronix Premium subscriber a while back requested some fresh benchmarks of how the Liquorix downstream of the Linux kernel is comparing against the latest upstream kernel... Here are some benchmarks looking at the Liquorix flavor of the Linux kernel compared to upstream Linux 6.12...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Ryzen AI NPU6 Support Added To AMDXDNA Driver For Linux 6.14 Debut","url":"https://www.phoronix.com/news/Ryzen-AI-NPU6-Linux-6.14","date":1734694248,"author":"Michael Larabel","unread":true,"desc":"","content":"The latest round of drm-misc-next material was sent out yesterday to DRM-Next in advance of the upcoming Linux 6.14 merge window...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Weighted Interleave Auto-Tuning Being Worked On For Linux","url":"https://www.phoronix.com/news/Linux-Weight-Interleave-Auto","date":1734692678,"author":"Michael Larabel","unread":true,"desc":"","content":"Joshua Hahn has posted the latest \"request for comments\" draft working on weightedd interleave auto-tuning for the linux kernel in order to better enhance the performance characteristics of primarily Linux servers with multiple memory nodes...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"OpenMoonRay 1.7 Brings More NVIDIA GPU Acceleration, Additional Features","url":"https://www.phoronix.com/news/OpenMoonRay-1.7","date":1734691680,"author":"Michael Larabel","unread":true,"desc":"","content":"In early 2023 DreamWorks open-sourced their MoonRay renderer as OpenMoonRay. Since then they have continued advancing this award-winning production MCRT renderer. Before closing out 2024 they have now released OpenMoonRay 1.7...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Bluesky adds mentions tab in the notifications screen and username squatting protection","url":"https://techcrunch.com/2024/12/20/bluesky-adds-mentions-tab-in-the-notifications-screen-and-username-squatting-protection/","date":1734690898,"author":"Ivan Mehta","unread":true,"desc":"","content":"<p>Social network Bluesky has released a new update to its app that includes a separate mentions tab in notifications, protections against username squatting, and new controls for replies sorting. The company announced that it is adding a new mentions tab with the v1.96 rollout to let you see those posts separately. Until now, all notifications [&#8230;]</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"How to Automatically Publish Your NPM Package Using GitHub Actions","url":"https://hackernoon.com/how-to-automatically-publish-your-npm-package-using-github-actions?source=rss","date":1734688817,"author":"Oluwole Adebiyi","unread":true,"desc":"","content":"<p>\\\nAutomating your npm package publishing process with continuous integration and delivery (CI/CD) ensures that each release passes through a quality gate—your test suite—before publication. At the same time, you can control exactly what ends up in the final published package by excluding test files. In this guide, you’ll learn how to set up CI/CD for a simple npm package—an alphanumeric validator—so that every new GitHub release triggers tests, updates the package version, and automatically publishes a clean package to npm.</p>\n<p>\\</p>\n<h2 id=\"whyautomatenpmpublishing\">Why Automate npm Publishing?</h2>\n<p>Manual npm publishing can be time-consuming and error-prone, particularly as your project grows and gains contributors. By automating the process, you can:</p>\n<ul>\n<li><strong>Ensure Quality:</strong> Automatically run tests before publishing. If tests fail, the new version isn’t released.</li>\n<li><strong>Consistent Versioning:</strong> The published package version always matches the release tag.</li>\n<li><strong>Frictionless Collaboration:</strong> Contributors submit code, you create a release, and the pipeline does the rest—no special npm permissions are required.</li>\n</ul>\n<p>\\</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<ol>\n<li><strong>Node.js & npm:</strong></li>\n</ol>\n<ul>\n<li>Click <a href=\"https://nodejs.org/en/learn/getting-started/how-to-install-nodejs\">here</a> if you do not have NodeJS and NPM installed.</li>\n<li>Confirm installation by running the code below in your terminal.</li>\n</ul>\n<pre><code class=\"bash language-bash\">node -v\nnpm -v\n</code></pre>\n<ol start=\"2\">\n<li><strong>GitHub Account & Repository:</strong></li>\n</ol>\n<ul>\n<li>You need a GitHub repository to store code and run GitHub Actions.</li>\n</ul>\n<ol start=\"2\">\n<li><strong>NPM Account & Access Token:</strong></li>\n</ol>\n<ul>\n<li>Sign up or log in at <a href=\"http://npmjs.com\">npmjs.com</a> and generate an access token.</li>\n<li>Add the access token as a secret in your GitHub repository for automated publishing.</li>\n</ul>\n<p>\\</p>\n<h2 id=\"step1setuptheproject\">Step 1: Set Up the Project</h2>\n<p>We’ll create a simple <code>alphanumeric-validator</code> package that exports a function checking if a string is alphanumeric.</p>\n<ol>\n<li><strong>Initialize the Project</strong></li>\n</ol>\n<pre><code class=\"bash language-bash\">   mkdir alphanumeric-validator cd alphanumeric-validator npm init -y\n</code></pre>\n<ol start=\"2\">\n<li><strong>Update</strong> <code>package.json</code> <strong>as needed.</strong> For the <code>alphanumeric-validator</code>, it will look like this.</li>\n</ol>\n<pre><code class=\"json language-json\">{\n  \"name\": \"alphanumeric-validator\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Validates if a string is alphanumeric\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"jest\"\n  },\n  \"keywords\": [\"alphanumeric\", \"validator\"],\n  \"author\": \"Your Name\",\n  \"license\": \"ISC\"\n}\n</code></pre>\n<ol start=\"3\">\n<li><strong>Implement the Validator</strong></li>\n</ol>\n<pre><code class=\"javascript language-javascript\">// index.js\nfunction isAlphaNumeric(str) {\n  return /^[a-z0-9]+$/i.test(str);\n}\n\nmodule.exports = isAlphaNumeric;\n</code></pre>\n<p>\\</p>\n<h2 id=\"step2addandruntestslocally\">Step 2: Add and Run Tests Locally</h2>\n<p>Testing ensures you don’t publish broken code.</p>\n<ol>\n<li>Install Jest</li>\n</ol>\n<pre><code class=\"bash language-bash\">   npm install --save-dev jest\n</code></pre>\n<ol start=\"2\">\n<li>Create a Test File</li>\n</ol>\n<pre><code class=\"bash language-bash\">   mkdir tests\n</code></pre>\n<ol start=\"3\">\n<li>Paste the code below in the <code>tests/index.text.js</code> file.</li>\n</ol>\n<pre><code class=\"javascript language-javascript\">   // tests/index.test.js\n\n   const isAlphaNumeric = require('../index');\n\n   test('valid alphanumeric strings return true', () =&gt; { expect(isAlphaNumeric('abc123')).toBe(true); });\n\n   test('invalid strings return false', () =&gt; { expect(isAlphaNumeric('abc123!')).toBe(false); });\n</code></pre>\n<ol start=\"4\">\n<li>Run Tests</li>\n</ol>\n<pre><code class=\"bash language-bash\">   npm test\n</code></pre>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/null-bt03vnt.png\" alt=\"Successful test ran\" /></p>\n<p>Tests passing? Great. Now, we’ll ensure these tests run in CI before publishing.</p>\n<p>\\</p>\n<h2 id=\"step3excludenodemodulesfromgit\">Step 3: Exclude Node Modules from Git</h2>\n<p>Before publishing to Github, you want to exclude the <code>node_modules</code>. You don’t want to commit <code>node_modules</code> to version control, as it contains a large number of files that can be regenerated by <code>npm install</code>.</p>\n<p>\\\n<strong>Create a</strong> <code>.gitignore</code> <strong>file</strong> at the root of your project:</p>\n<pre><code class=\"bash language-bash\">echo \"node_modules\" &gt;&gt; .gitignore\n</code></pre>\n<p>This ensures that <code>node_modules</code> is not tracked by git and won’t be pushed to your repository.</p>\n<h2 id=\"step4excludetestsfromthepublishedpackage\">Step 4: Exclude Tests from the Published Package</h2>\n<p>While you will run tests during CI, you don’t want the test files included in your published npm package. This keeps the package clean, has a small bundle size, and ensures only the necessary files are shipped to users. \\n </p>\n<p>Create an <code>.npmignore</code> file in the root folder and add the test file names.</p>\n<pre><code class=\"bash language-bash\">// .npmignore\n__tests__\n*.test.js // captures all files in the directory with a .test.js extension\n</code></pre>\n<p>\\\nThis ensures the test files are not included when you run <code>npm publish</code>.</p>\n<h2 id=\"step5hostyourcodeongithub\">Step 5: Host Your Code on GitHub</h2>\n<ol>\n<li><strong>Create a New GitHub Repository:</strong></li>\n</ol>\n<ul>\n<li><p>Go to <a href=\"https://github.com/new\">https://github.com/new</a> and create a <code>alphanumeric-validator</code> repository.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/f2OZeUyGKadvdOjeANOTzJzLp2q2-2024-12-20T10:00:14.894Z-m7tl2pneyt344gapbh4mrk7n\" alt=\"Creating a new repository\" /></p></li>\n</ul>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/f2OZeUyGKadvdOjeANOTzJzLp2q2-2024-12-20T10:00:14.946Z-dnh4xau6wpfdq8fzeb4pnfb6\" alt=\"Created repository, no code in yet\" /></p>\n<p>\\</p>\n<ol start=\"2\">\n<li><strong>Push Your Code</strong> </li>\n</ol>\n<pre><code class=\"bash language-bash\">   git init\n   git add .\n   git commit -m \"Initial commit\"\n   git remote add origin git@github.com:YOUR_USERNAME/alphanumeric-validator.git\n   git push -u origin main\n</code></pre>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/f2OZeUyGKadvdOjeANOTzJzLp2q2-2024-12-20T10:00:14.948Z-k0sauw007abpupemshedz108\" alt=\"Pushing local code to Github\" /></p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/f2OZeUyGKadvdOjeANOTzJzLp2q2-2024-12-20T10:00:14.962Z-nmpnd9h4zajbxqsa41nudnu5\" alt=\"Created repository, local code now uploaded\" /></p>\n<p>\\</p>\n<h2 id=\"step5initialmanualpublishtonpm\">Step 5: Initial Manual Publish to npm</h2>\n<ul>\n<li>Before initiating the automation, confirm your package can be published—<a href=\"https://docs.npmjs.com/cli/v10/commands/npm-publish\">see here.</a></li>\n<li>Then, add the <code>--access public</code> flag to make your package public and accessible to users.</li>\n</ul>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">npm login\nnpm publish --access public\n</code></pre>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/null-n923v2f.png\" alt=\"Publishing to npm from terminal\" /></p>\n<p>\\</p>\n<ul>\n<li><p>Visit <a href=\"https://www.npmjs.com/package/alphanumeric-validator\">https://www.npmjs.com/package/alphanumeric-validator</a> to verify the initial version is live.</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/null-da33vml.png\" alt=\"Published alphanumeric-validator\" /></p></li>\n</ul>\n<h2 id=\"step6settingupthegithubactionsworkflow\">Step 6: Setting Up the GitHub Actions Workflow</h2>\n<p>You need to configure a workflow that runs on every release event so that when you create a new release (like <code>v1.0.1</code>):</p>\n<ul>\n<li>The workflow checks out your code.</li>\n<li>Installs dependencies.</li>\n<li>Runs tests to ensure quality.</li>\n<li>Updates <code>package.json</code> to the new version from the release tag.</li>\n<li>Publishes the updated package to npm without including test files.</li>\n</ul>\n<p>\\</p>\n<h3 id=\"theworkflowfile\">The Workflow File</h3>\n<p>Create <code>.github/workflows/publish.yml</code>:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">name: Publish Package to npm\n\n# Trigger this workflow whenever a new release is published\non:\n  release:\n    types: [published]\n\n# Grant write permissions to the repository contents so we can push version updates\npermissions:\n  contents: write\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n\n    steps:\n      # Step 1: Check out the repository’s code at the default branch\n      # This makes your code available for subsequent steps like installing dependencies and running tests.\n      - uses: actions/checkout@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          ref: ${{ github.event.repository.default_branch }}\n\n      # Step 2: Set up a Node.js environment (Node 20.x) and configure npm to use the official registry\n      # This ensures we have the right Node.js version and a proper registry URL for installs and publishing.\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20.x'\n          registry-url: 'https://registry.npmjs.org'\n\n      # Step 3: Install dependencies using npm ci\n      # This ensures a clean, reproducible installation based on package-lock.json.\n      - name: Install dependencies\n        run: npm ci\n\n      # Step 4: Run your test suite (using the \"test\" script from package.json)\n      # If tests fail, the workflow will stop here and not publish a broken version.\n      - name: Run tests\n        run: npm test\n\n      # Step 5: Update package.json to match the release tag\n      # The release tag (e.g., v1.0.1) is extracted, and npm version sets package.json version accordingly.\n      # The --no-git-tag-version flag ensures npm doesn't create its own tags.\n      # This step keeps package.json's version aligned with the release tag you just created.\n      - name: Update package.json with release tag\n        run: |\n          TAG=\"${{ github.event.release.tag_name }}\"\n          echo \"Updating package.json version to $TAG\"\n          npm version \"$TAG\" --no-git-tag-version\n\n      # Step 6: Commit and push the updated package.json and package-lock.json back to the repo\n      # This ensures your repository always reflects the exact version published.\n      # We use the GITHUB_TOKEN to authenticate and the granted write permissions to push changes.\n      - name: Commit and push version update\n        run: |\n          TAG=\"${{ github.event.release.tag_name }}\"\n          git config user.name \"github-actions\"\n          git config user.email \"github-actions@github.com\"\n          git add package.json package-lock.json\n          git commit -m \"Update package.json to version $TAG\"\n          git push origin ${{ github.event.repository.default_branch }}\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      # Step 7: Publish the new version to npm\n      # The NODE_AUTH_TOKEN is your npm access token stored as a secret.\n      # npm publish --access public makes the package available to anyone on npm.\n      - name: Publish to npm\n        run: npm publish --access public\n        env:\n          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n</code></pre>\n<p>\\</p>\n<h3 id=\"addingyournpmtokentogithub\">Adding Your NPM Token to GitHub</h3>\n<ul>\n<li>Visit <a href=\"https://www.npmjs.com/settings/:username/tokens/new\">https://www.npmjs.com/settings/:username/tokens/new</a> (Ensure you replace <code>:username</code> with your actual username)</li>\n<li>Enter the name, select automation for the type, and generate</li>\n</ul>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/null-xs43vy3.png\" alt=\"Creating an NPM access token\" /></p>\n<p>\\</p>\n<ul>\n<li><p>You will be redirected to the tokens page, where you can copy the token.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/null-qe53v91.png\" alt=\"\" /></p></li>\n<li><p>Go to <strong>Settings > Secrets and variables > Actions</strong> in your GitHub repository.</p></li>\n<li><p>Click <strong>New Repository Secret</strong> and add <code>NPM_TOKEN</code>.</p>\n<p>\\\n<img src=\"https://cdn.hackernoon.com/images/null-e263voh.png\" alt=\"\" /></p></li>\n</ul>\n<h2 id=\"step7creatinganewrelease\">Step 7: Creating a New Release</h2>\n<p>Let’s say you want to add <code>README.md</code> for &nbsp;<code>v1.0.1</code> release, and you have pushed it:</p>\n<ol>\n<li><strong>Draft a New Release:</strong></li>\n</ol>\n<ul>\n<li>Go to the <strong>Releases</strong> section in your GitHub repo. [<a href=\"https://github.com/username/repo/releases\">https://github.com/username/repo/releases</a>]</li>\n<li>Click <strong>Draft a new release</strong>.</li>\n<li>Set the \"Tag version\" to v1.0.1.</li>\n<li>Click <strong>Publish release</strong>.</li>\n</ul>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/null-hv73vf0.png\" alt=\"\" /></p>\n<ol start=\"2\">\n<li><strong>Workflow Triggered:</strong> The release event fires. The workflow,</li>\n</ol>\n<ul>\n<li>Checks out the code.</li>\n<li>Installs dependencies.</li>\n<li>Runs tests. If tests fail, the job stops and the package won’t be published.</li>\n<li>If tests pass, it updates package.json to <code>1.0.1</code>.</li>\n<li>Publishes the <code>1.0.1</code> version to npm, excluding test files.</li>\n</ul>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/null-l683vth.png\" alt=\"\" /></p>\n<ol start=\"3\">\n<li><strong>Verify on npm:</strong> After a moment, visit your npm package page to see the new version live.</li>\n</ol>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/null-qi93vjx.png\" alt=\"\" /></p>\n<p>\\</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Integrating GitHub Actions into your npm publishing workflow establishes a great CI/CD pipeline. With each new release, a comprehensive series of tests run, package.json is updated with the correct version, and a streamlined package is published to npm—free of unnecessary files like tests.&nbsp;</p>\n<p>This approach saves time, reduces human errors, and enhances the reliability of your releases, making it easier for contributors to see their work go live seamlessly.&nbsp;</p>\n<p><em>A single GitHub release</em> is now all it takes to ship a fully tested, properly versioned package to the npm registry.</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Uzbekistan’s mobile bank TBC bags $37M to expand with new AI and insurance products","url":"https://techcrunch.com/2024/12/20/uzbekistans-mobile-bank-tbc-bags-37m-to-expand-with-new-ai-and-insurance-products/","date":1734688800,"author":"Jagmeet Singh","unread":true,"desc":"","content":"<p>Uzbekistan's mobile-exclusive bank, TBC Bank Uzbekistan, has raised $37 million to bolster its footprint in the Central Asian nation.</p>\n<p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>\n","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"The Under-the-Radar Economy of Social Media Influence","url":"https://hackernoon.com/the-under-the-radar-economy-of-social-media-influence?source=rss","date":1734684613,"author":"Actuls","unread":true,"desc":"","content":"<p>There’s a slice of the internet where the real money isn’t made from crypto volatility but from the steady, lucrative trade of social media influence. Enter&nbsp;<a href=\"http://swapd.co/\">SWAPD.co</a>, a platform that’s quietly built a marketplace where social media accounts and services are the commodities. Over the past few years,&nbsp;<a href=\"https://swapd.co/report\">this site has facilitated over $50,000,000 in transactions</a>, revealing a world where individuals are making five to six figures each month, not from meme coins but from the power of digital engagement.</p>\n<p>\\\nThis isn’t the kind of market that boasts about its successes in broad daylight; it thrives in the shadows, where the art of flipping social media assets is both a science and a guarded secret. Here, an Instagram account with a dedicated following or a Twitter handle with a history of viral tweets can be the equivalent of hitting the jackpot. But it’s not just about buying and selling accounts; services like account growth, content creation, and management are where the real fortunes are being made.</p>\n<p>\\\nFrom an observer’s perspective, what’s fascinating about SWAPD is how it has tapped into a need that’s growing on social media - the desire for instant influence or the expertise to maintain it. You’ll find:</p>\n<ul>\n<li>Growth Specialists who can take a dormant account and turn it into a trending topic overnight.</li>\n<li>Content Creators who understand the zeitgeist, crafting posts that not only engage but also convert followers into customers or fans.</li>\n<li>Management Experts who handle the day-to-day operations of social media empires, allowing the public faces to focus on their brand or image.</li>\n</ul>\n<p>\\\nThis ecosystem functions with a level of discretion that’s almost cloak-and-dagger. While the crypto market might celebrate its gains and losses publicly, transactions on SWAPD are conducted with an eye towards privacy and security. The platform has become a place where one’s digital footprint can be as valuable as any physical asset, yet this world remains largely unknown to the average internet user.</p>\n<p>\\\nSWAPD’s success lies in its ability to provide:</p>\n<ul>\n<li>A secure environment for transactions, ensuring that the high stakes involved in trading digital influence aren’t compromised.</li>\n<li>A community where, despite the secretive nature of the business, there’s a culture of sharing knowledge and celebrating success stories, albeit in hushed tones.</li>\n</ul>\n<p>\\\nThe individuals making it big on SWAPD aren’t just playing the market; they’re shaping it, turning social media from a tool for connection into a sophisticated arena for business. They’ve figured out that in today’s social media world, engagement, loyalty, and influence are currencies that can appreciate far beyond any crypto coin.</p>\n<p>\\\nSo, while the rest of the world might be chasing after the next big blockchain project, there’s a group quietly amassing wealth through the strategic trading of social media influence on platforms like SWAPD.</p>\n<p>\\</p>\n<p>:::tip\n<strong><em>This story was distributed by Actuls under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;<a href=\"https://business.hackernoon.com/business-blogging?ref=hackernoon.com\">here</a>.</em></strong></p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"EIP-1559: Separating Mechanisms From Memes","url":"https://hackernoon.com/eip-1559-separating-mechanisms-from-memes?source=rss","date":1734681621,"author":"2077 Research","unread":true,"desc":"","content":"<p>\\\nEIP-1559 was an upgrade that marked the first ever significant change being made to Ethereum's transaction fee mechanism (TFM) in the history of the network. Essentially, it replaced the prior TFM model with a new one improving economic efficiency and user experience. It also paved the way for Ethereum to begin working on <a href=\"https://vitalik.eth.limo/general/2024/05/09/multidim.html\">multi-dimensional fee markets</a> to improve its efficiency even more, starting with <a href=\"https://www.eip4844.com/\">EIP-4844</a>.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:10.942Z-taawpvkjswcwysehyzhe5fpw\" alt=\"\" /></p>\n<p>In this article we are going to learn about Ethereum's current transaction fee mechanism provided by EIP-1559. We will dive deep into EIP-1559 to explain what its objectives were from the beginning and why it was designed the way it is. Many people have a misunderstanding of what EIP-1559 was created to address and we can attribute much of this confusion to how it was used as the poster child for a popular meme known as <a href=\"https://www.youtube.com/watch?v=2ZuGVLhhxQo\">Ultrasound Money</a>.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:10.988Z-l0xjhbkqea3b8zpo2uvg2z09\" alt=\"\" /></p>\n<p>The motivation to write this article was born out of frustration that many people still don't understand the main benefits of EIP-1559 and the problems it addresses and often come to the wrong conclusions due to its close association with the <a href=\"https://x.com/drakefjustin/status/1304064879662227456\">Ultrasound Money meme</a>. A consequence of this is that much of the foundational work that went towards EIP-1559 is overshadowed and under-appreciated which is quite tragic because much of this broke new ground for the design space of blockchains (especially around <a href=\"https://en.wikipedia.org/wiki/Mechanism_design\">mechanism design</a>).</p>\n<p>\\\nThe objectives of this article are as follows:</p>\n<ol>\n<li>Explain what EIP-1559 is, what benefits it provided, how it improved upon the previous mechanism, and where we potentially go from here.</li>\n<li>Explain what the Ultrasound Money meme is and how EIP-1559 relates to it.</li>\n</ol>\n<p>Before we get started, let's clarify some common misconceptions about EIP-1559:</p>\n<ul>\n<li><strong>EIP-1559 was not designed to lower transaction fees</strong>: The primary goal of EIP-1559 was to create a more efficient and fair fee system, not to reduce fees directly.</li>\n<li><strong>EIP-1559 does not burn ETH to increase its value</strong>: The fee burn was a crucial design choice to prevent manipulation attacks and enhance the fairness and efficiency of Ethereum's transaction fee mechanism.</li>\n</ul>\n<h2 id=\"fundamentalsoftransactionfeemechanisms\">Fundamentals of Transaction Fee Mechanisms</h2>\n<p>In public blockchains the design of the cost/reward structure is important to ensure all actors driving its operation and activity are motivated to participate within the system. A part that plays a big role here is how Ethereum manages the sale and purchase of blockspace to users. In Ethereum, users are required to pay transaction fees to cover costs of inclusion and execution on the blockchain. These fees cover the <a href=\"https://en.wikipedia.org/wiki/Social_cost\">social costs</a> of transactions as well as premiums to block producers who create blocks on behalf of users.</p>\n<p>\\\nThe relationship between users and block producers are characterized by the <a href=\"https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem\">principal-agent problem</a>, which describes where one party (an agent) takes actions on behalf of another party (the principal) but the interests of the agent do not fully align with the principal. In Ethereum, a block producer (agent) includes transactions in blocks on behalf of users (principals), but block producers are motivated to maximize their revenue, therefore when users do not sufficiently incentivize block producers to include their transactions, their requests for inclusion are left unfulfilled.</p>\n<p>\\\nLet's describe below the interests of users and block producers:</p>\n<ul>\n<li><p><strong>Users</strong>: Timely transaction inclusion at the lowest possible cost.</p></li>\n<li><p><strong>Block Producer</strong>: Maximum possible revenue earned from building a block (from transaction fees, consensus rewards, and potentially MEV).</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:10.990Z-kr1b3o4srmgn027xrwo5l4en\" alt=\"\" /></p></li>\n</ul>\n<h3 id=\"whatistherelevanceoftheprincipalagentproblem\">What is the relevance of the principal-agent problem?</h3>\n<p>Block producers serve the network but are under no obligation to include transactions in their blocks (maybe this changes in the future with <a href=\"https://ethereum-magicians.org/t/eip-7547-inclusion-lists/17474\">inclusion lists</a>). While building an empty block incurs opportunity cost for block producers, they still have the freedom to engage in other behaviors (such as only including exorbitantly high transaction bids) that maximize their personal gain, potentially at the expense of network efficiency and fairness. Such misaligned, yet economically-rational, actions by block producers can threaten the efficiency and <a href=\"https://en.wikipedia.org/wiki/Welfare_economics\">welfare</a> of Ethereum. A blockchain's transaction fee mechanism aims to align interests of users and block producers to help achieve the most economically efficient outcome.</p>\n<h2 id=\"thebasicsoftransactionfeemechanismsgoalscoreconcepts\">The Basics of Transaction Fee Mechanisms (Goals &amp; Core Concepts)</h2>\n<p>A&nbsp;<strong>Transaction Fee Mechanism (TFM)</strong>&nbsp;describes a set of rules and processes in a blockchain protocol that determines how transaction fees are calculated, collected, and distributed for processing transactions.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:10.992Z-gwnyllfa1msynclc6438gdq2\" alt=\"\" /></p>\n<p>There are several goals we want to achieve with a TFM:</p>\n<ul>\n<li><p><strong>Good User Experience</strong>: The TFM should provide transparent pricing that minimizes guesswork and uncertainty for users in setting transaction bids. It should therefore improve transaction fee predictability.</p></li>\n<li><p><strong>Incentive Alignment</strong>: The TFM should be designed in such a way that it encourages honest behavior and compliance with protocol rules which seek to provide efficient and fair access to blockchain resources. Honest behavior of users involves them expressing their bids as their true value of their transactions. Honest behavior of block producers is selecting the list of highest value bids (as described by the TFM) and building a block with them.</p></li>\n<li><p><strong>Robustness to Manipulation</strong>: Block producers and users should not be able to benefit from attempting to manipulate the TFM. If the TFM is designed well enough, it will guarantee that attempting manipulation of it is never an optimal strategy for either block producers nor users. In addition to this, the TFM seeks to be robust to coalitional efforts to exploit the mechanism such as one or more users establishing a cartel with a block producer in pursuit of greater benefits. A well-designed TFM ensures that following the mechanism is always more profitable for users and block producers than trying to collude to exploit it.</p></li>\n<li><p><strong>Responsive to Market Conditions</strong>: A TFM should be able to dynamically adjust to current market conditions, facilitating discovery of market-clearing prices that accurately reflect demand for blockspace. In addition to this, it should be robust to market changes reducing fee volatility.</p></li>\n<li><p><strong>Economic Efficiency</strong>: A TFM achieves greater economic efficiency when it allocates blockspace optimally. We aim to ensure that blockspace is allocated to those that value it the most. A TFM should help express the economic value that users ascribe to their transactions to best inform block producers on how to allocate resources when building a block. At a higher level, a TFM should help maximize overall network welfare (everyone being better off).</p>\n<p>\\</p></li>\n</ul>\n<p>Let's introduce one of the main components that make up TFMs - <a href=\"https://en.wikipedia.org/wiki/Market_mechanism\">market mechanisms</a> (e.g. auctions, posted-price markets etc). A <strong>market mechanism</strong> helps coordinate the interactions between users and block producers in the market for blockchain resources to help drive the allocation of blockspace to user transactions.</p>\n<p>\\\nIn every Ethereum block, there is a fixed amount of resources allocated for transaction processing -- we generally refer to this as <strong>blockspace</strong>. Because we limit the amount of blockspace available in each block, we consider it a <a href=\"https://www.investopedia.com/terms/s/scarcity.asp\">scarce resource</a>. We consider blockspace a scarce resource because we limit how much of it is available with each block to satisfy the network's feasibility model for running full nodes (in service of preserving decentralization).</p>\n<p>\\\nLet's explicitly define the nature of supply and demand around blockspace below:</p>\n<ul>\n<li><strong>Supply</strong>: The blockchain resources made available for consumption per block.</li>\n<li><strong>Demand</strong>: The desire of users to have their transactions executed in the next block.</li>\n</ul>\n<p>\\\nUsers express their demand by specifying a bid price they are willing to pay per unit of gas (the resource of blocks) consumed by their transactions. A market mechanism helps provide price discovery to both users and block producers, where market-clearing prices can be established. <a href=\"https://en.wikipedia.org/wiki/Market_clearing\">Market-clearing prices</a> describe the price point where the interests of users (demand) and block producers (sellers) align perfectly. The goal is to have the TFM determine the market-clearing price of blocks, allowing users to trivially set bids and for block producers to easily make decisions about allocation.</p>\n<p>\\\nHaving gone over the basics and core concepts surrounding transaction fee mechanisms, we will now explore how Ethereum's TFM used to work before describing how EIP-1559 changed things for the better.</p>\n<h2 id=\"transactionfeemechanismsinethereumpastpresent\">Transaction Fee Mechanisms in Ethereum (Past &amp; Present)</h2>\n<p>Let's get a better understanding of how we used to manage transaction fees in Ethereum. Gas is the unit of measure used by transactions to meter the amount of blockchain resources they consume when included on Ethereum. Users are required to specify bids in the form of a gas price (denominated in ETH) that they are willing to pay per unit of gas consumed by their transactions. A transaction fee is described by the following formula:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.457Z-qwayiqivrxpqsbe0pz43n71x\" alt=\"\" /></p>\n<p>Example: Consider a transaction that consumes 21000 gas where the user sets a gas price of 20 gwei (2e-8 ETH or 0.00000002 ETH); Their transaction fee would be 0.00042 ETH.</p>\n<h3 id=\"legacytfmpre1559\">Legacy TFM (Pre-1559)</h3>\n<p>Ethereum's legacy TFM (pre-1559) made use of a first-price auction market mechanism.</p>\n<p>A <strong>first-price auction (FPA)</strong> is a type of auction where the highest bidders win and pay the exact amount they bid. Users made bids in the form of gas prices for their transactions and broadcasted these to the network mempool. The block producer would look at the current bids made and select the set of transactions with the highest bids that can fit into their block.</p>\n<p>\\\nThis type of auction was public, meaning that anyone could observe transaction bids at any time and use that information as they wished. Because this TFM doesn't provide any additional measures that communicate information like market-clearing prices, users were left with a lot of uncertainty and guesswork when it came to deciding on what would be a suitable bid. With this lack of information, users (and wallet providers) resorted to relying on bidding information available from the transaction mempool to guide what prices they set for their own bids. Naturally this is incredibly inefficient because other peoples bids do not necessarily reflect the objective demand for transaction inclusion but rather opinions about what it is.</p>\n<p>\\\nLet's walk through the flow of events that unfold involving this TFM:</p>\n<ol>\n<li><p>A user creates a transaction (where the amount of gas that will be consumed by it is calculated).</p></li>\n<li><p>The TFM provides the user with an estimated gas price based on recent transactions.</p></li>\n<li><p>The user sets a gas price based on this provided information and broadcasts their transaction to the mempool.</p></li>\n<li><p>When it is a block producer's time to create a block, they look at the mempool and select the set of revenue-maximizing transactions to include in their block and create it.</p></li>\n<li><p>The block producer broadcasts the new block to the network, and it is included on Ethereum.</p></li>\n<li><p>When the new block is added, the blockchain collects transaction fees from users and transfers them to the block producer.</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.395Z-xom6i3lo9h98h11s1bzy75ml\" alt=\"\" /></p></li>\n</ol>\n<h4 id=\"incentivealignmentlegacytfm\">Incentive Alignment (Legacy TFM)</h4>\n<p>A TFM ideally works well enough that it encourages users and block producers to use it and only it honestly to drive the allocation of blockspace. Let's have a look at how well of a job the legacy FPA mechanism does in this regard:</p>\n<ul>\n<li><strong>Users</strong>: With this TFM, it is not the best strategy for users to express their honest value of their transactions as a bid because their best strategy for inclusion is to set a bid based on the value of other competing bids. For example, a user may have a true higher value they ascribe to their transaction, but if other users have bids that are significantly lower, the user would benefit more by lowering their bid just enough that it's higher than those bids -- we refer to this undesired strategy as <a href=\"https://en.wikipedia.org/wiki/Bid_shading\">bid shading</a>. This therefore demonstrates how the mechanism is <strong>not user incentive-compatible</strong>.</li>\n<li><strong>Block Producers</strong>: The best strategy for a block producer is also its honest one where they simply select the list of highest bids to build their block with. The mechanism is therefore incentive-compatible for block producers.</li>\n</ul>\n<h4 id=\"robustnesstomanipulationlegacytfm\">Robustness to Manipulation (Legacy TFM)</h4>\n<p>The legacy TFM's robustness to manipulation is very limited. The reasons why this is are explained below:</p>\n<ul>\n<li><p><strong>Vulnerability to manipulation by users</strong>: Users stand to benefit from implementing strategies like bid shading.</p></li>\n<li><p><strong>Susceptibility to collusion among block producers and users</strong>: Users and block producers are easily able to make off-chain agreements that improve both their benefits compared to using the TFM. An example of this has been observed numerous times on Ethereum where a user's transaction gets included in a block costing 0 ETH because they entered an agreement with a block producer directly instead of through the TFM. The image below shows a transaction that did just that.</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.391Z-jdz2v1nvyfqvnr220cjc06qy\" alt=\"\" /></p></li>\n</ul>\n<p>The image above demonstrates that collusion was in fact happening during the time when Ethereum leveraged the legacy TFM. Adding to this, the collusion was happening at a large scale. Essentially what was happening was that there were 'dual markets' for blockspace. We had the 'official' market for blockspace managed within Ethereum's protocol and guided by the TFM, and then we had the 'dark market' where users approached block producers directly and struck agreements for inclusion in blocks. Because the TFM had no real measures to prevent this, it became an avenue for sophisticated users to make deals with block producers for valuable blockspace outside of the protocol.</p>\n<p>\\\nHaving explored the legacy TFM's incentive compatibility and resistance to collusion. We formally illustrate the game-theoretical properties of the mechanism below:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.322Z-uft9n84jm9un1716ay88ummb\" alt=\"\" /></p>\n<h4 id=\"economicefficiencylegacytfm\">Economic Efficiency (Legacy TFM)</h4>\n<p>Economic efficiency is maximized when blockspace is allocated efficiently. There are two factors that contribute towards the realization of this goal:</p>\n<ol>\n<li><strong>High value allocation</strong>: Blockspace should be allocated to the highest-value transactions (that truly reflect user values) so that it can be allocated in the most valuable way.</li>\n<li><strong>Price discovery</strong>: Helps users discover market-clearing prices to help them make more informed bids.</li>\n</ol>\n<p>\\\nBecause the mechanism is not incentive compatible for users, they may not always set their bids to reflect the true value they ascribe to their transactions. This can lead to inefficiencies, as the TFM might not allocate blockspace to the highest-value transactions due to imperfect information. Furthermore, strategies like bid shading increase network traffic, which further undermines efficiency. Despite these issues, there is still some level of efficiency in the system. Even if users do not bid perfectly, those with higher valuations are generally more likely to place higher bids, which partially aligns blockspace allocation with transaction value. Therefore, while the legacy TFM allows for some degree of efficiency, it is not optimal.</p>\n<h4 id=\"marketresponsivenesslegacytfm\">Market Responsiveness (Legacy TFM)</h4>\n<p>Ethereum's legacy TFM was reactive to market conditions but not in a controlled or efficient manner. While the TFM did communicate gas prices to users and block producers, these values were often volatile and unpredictable due to the poor and non-dynamic price discovery provided by the mechanism. This made transaction fees quite unpredictable for users.</p>\n<h3 id=\"userexperiencelegacytfm\">User Experience (Legacy TFM)</h3>\n<p>Ethereum's legacy TFM did not provide a good user experience regarding fee predictability. The lack of a stable, predictable fee structure led to much guesswork and uncertainty around setting fees where users faced difficulty estimating the correct bid amount, leading to frustration, frequent bid adjustments, and increased costs due to potential overbidding.</p>\n<h3 id=\"eip1559tfm\">EIP-1559 TFM</h3>\n<p>In August 2021, EIP-1559 introduced a new transaction fee mechanism to Ethereum to address the shortcomings of the prior mechanism. EIP-1559 can be described as a <strong>dynamic posted-price mechanism with elements of a first-price auction</strong>. It was designed with a few objectives in mind:</p>\n<ul>\n<li><p><strong>Improved economic efficiency</strong>: Ensure blockspace is allocated according to true demand to ensure it is used in the most valuable way, therefore enhancing network welfare and optimizing the use of blockchain resources.</p></li>\n<li><p><strong>Improved user experience for transaction senders</strong>: Simplify fee estimation to reduce uncertainty and guesswork, helping users avoid overpaying or facing long waiting times due to underbidding.</p></li>\n<li><p><strong>Stabilizing transaction fees</strong>: Make transaction costs more predictable by reducing sudden changes in fees, ensuring fair pricing for all users.</p></li>\n<li><p><strong>Reducing network congestion</strong>: Minimize the impact of the TFM on network congestion by reducing transaction bid traffic, thereby reducing strain on the network.</p>\n<p>\\</p></li>\n</ul>\n<p>EIP-1559 introduces FOUR key features/changes to Ethereum:</p>\n<ol>\n<li><strong>Base Fees</strong>: A reserve price for transaction gas that is automatically calculated by the protocol based on network demand.</li>\n<li><strong>Variable Block Sizes</strong>: Elastic block sizes that adjust dynamically to measure demand for blockspace, helping to set the appropriate base fees for each block.</li>\n<li><strong>New Payment Rules</strong>: Transaction fees are no longer fully paid to block producers; instead, most of the fees are \"burned\" (permanently removed from circulation), with only a small portion going to block producers.</li>\n<li><strong>Priority Fees</strong>: Optional tips set by users to incentivize block producers to include their transactions more quickly.</li>\n</ol>\n<h4 id=\"basefees\">Base Fees</h4>\n<p>EIP-1559 introduces a new value to blocks called a base fee. This base fee is a protocol-computed reserve price (per unit of gas) and represents the price where blockspace supply and demand are matched. The base fee also represents the minimum bid a user must set for their transaction to be eligible for inclusion in a block.</p>\n<p>\\\nUnlike the previous TFM, the base fee is not set by users but is automatically calculated by Ethereum based on the previous block's usage. It is independent of the current block's contents and is determined by past on-chain activity.</p>\n<p>\\\nThe key benefit of the base fee is <strong>price discovery</strong>. It helps communicate the <a href=\"https://en.wikipedia.org/wiki/Market_clearing\">market-clearing prices</a> to users and adjusts dynamically with each block, utilizing variable block sizes to better reflect current network demands.</p>\n<h4 id=\"variableblocksizes\">Variable Block Sizes</h4>\n<p>Before EIP-1559, Ethereum used fixed-size blocks with a 15M gas limit to ensure that running a full node remained feasible and decentralized. This limit ensured that participants could run nodes on standard hardware, avoiding heavy computational demands.</p>\n<p>\\\nWith EIP-1559, block sizes can now vary between 0 and 30M gas, with a target average of 15M gas per block. This flexibility allows the network to temporarily accommodate higher demand while maintaining long-term feasibility by keeping average block size within acceptable limits. There is still a hard cap on block size, which is double the previous limit.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.257Z-j9qc959uevgqunsj323wrptx\" alt=\"\" /></p>\n<p><strong>Why Variable Block Sizes?</strong></p>\n<ol>\n<li><p><strong>Flexibility during periods of demand fluctuation</strong>: Allowing block sizes to expand up to 30M gas during periods of high demand helps absorb demand spikes, reducing sharp increases in transaction fees and mitigating congestion.</p></li>\n<li><p><strong>Stable base fees</strong>: Variable block sizes enable smoother adjustments to the base fee, leading to more stable and predictable fees for users.</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.178Z-w1ubko8n2784g3z57qsvwplu\" alt=\"\" /></p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.171Z-aulj0qsmbctmduqy0mbtdtc1\" alt=\"\" /></p></li>\n</ol>\n<p>With an understanding of how base fees and variable block sizes interact, let's look at how the protocol manages base fee updates across blocks. This will show how base fees are calculated and how variable block sizes help ensure smoother adjustments.</p>\n<p>\\\nThe base fee for each block is determined using the following formula:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.142Z-ot8t7xpi3yk3xakqnktqm26x\" alt=\"\" /></p>\n<p>To compute a block's base fee, the protocol uses:</p>\n<ol>\n<li>The base fee of the previous block.</li>\n<li>The gas used by the previous block</li>\n</ol>\n<p>\\\nThere are two constants in the formula: <strong>T</strong>, the target block size (15M gas), and <strong>L</strong>, the learning rate (0.125 or 12.5%), which controls how quickly the base fee changes. The learning rate balances:</p>\n<ol>\n<li><strong>Smooth base fee adjustments</strong>: A lower learning rate makes fee changes gradual, reducing volatility.</li>\n<li><strong>Responsive demand adjustments</strong>: A higher learning rate makes the base fee more responsive to changes in network demand.</li>\n</ol>\n<p>\\\nEIP-1559 sets this learning rate to 12.5% to balance smooth adjustments and demand responsiveness. Here is an example of base fee calculation:</p>\n<p>\\\n<strong>Example</strong>: If the previous block's base fee was 20 gwei and it used 29M gas (14M over the target), with a learning rate of 0.125, the next block's base fee would be 22.3 gwei. This demonstrates the protocol's ability to dynamically adjust fees based on demand.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:12.015Z-mp71oc5f4txocy0pxwnhxw6a\" alt=\"\" /></p>\n<h4 id=\"newpaymentrulesandpriorityfees\">New Payment Rules and Priority Fees</h4>\n<p>In Ethereum's legacy TFM, all transaction fees were given entirely to block producers.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.953Z-wxsvujejkn21onni3l78benm\" alt=\"\" /></p>\n<p>With EIP-1559, the fee structure has changed to leverage the blockchain's programmatic capabilities at the protocol level. Under EIP-1559, a transaction fee consists of two parts:</p>\n<ul>\n<li><strong>Base Fee:</strong> A protocol-determined minimum fee (per unit of gas) required for a transaction to be included in a block.</li>\n<li><strong>Priority Fee</strong>: An optional user tip (per unit of gas) paid to block producers to incentivize transaction inclusion.</li>\n</ul>\n<p>\\\nUnlike the legacy TFM, block producers only receive the priority fee. The base fee is burned, meaning it is permanently removed from circulation. The total transaction fee a user pays is calculated as:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.932Z-ytdbjtqkz1oyff5rfmnabma1\" alt=\"\" /></p>\n<p><strong>Example</strong>: For a 21000 gs transaction with a base fee of 20 gwei (2e-8 ETH) and a priority fee of 1 gwei (1e-9 ETH), the total transaction fee would be 0.000441 ETH. Of this, 0.00042 ETH (21000 gas x 20 gwei) is burned, and 0.000021 ETH (21000 x 1 gwei) goes to the block producer.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.910Z-r8v9f16f1jdu82xs1ghrnn78\" alt=\"\" /></p>\n<p><strong>Why is the base fee burned?</strong></p>\n<p>This is the part of EIP-1559 that confuses many people, there are many who believe that EIP-1559 was designed to do this to increase the value of ETH however the base fee revenue burn is a crucial design decision to ensuring the TFM works efficiently and realizes its objectives - whatever monetary effects are experienced because of the burn is simply a side-effect.</p>\n<p>\\\n<strong>The base fee is burned to prevent block producers from colluding with users to bypass the TFM</strong>, which would replicate the issues of the legacy first-price auction system. Burning the base fee ensures it is not given to block producers, maintaining the integrity and fairness of the mechanism. Other methods, like forwarding fees to future block producers or DAOs, were considered but deemed more complex and vulnerable to game-theoretic attacks (gaming the mechanism), making burning the simplest and most secure choice.</p>\n<h3 id=\"walkingthroughhoweip1559works\">Walking through how EIP-1559 Works</h3>\n<p>Before we put everything together, we should cover one more change introduced with EIP-1559: the <strong>fee cap</strong>. This cap sets the maximum fee a user is willing to pay per unit of gas, covering both the base fee and the priority fee. It ensures users have control over the maximum cost of their transaction, even if the base fee rises unexpectedly. The transaction fee per unit of gas is calculated as:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.819Z-ew986m7benqtu8yfxslnbrte\" alt=\"\" /></p>\n<p>This mechanism helps users minimize transaction costs based on their settings:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.699Z-i1knz4fafgfsgrz5qa55xlwc\" alt=\"\" /></p>\n<p>Let's walk through how EIP-1559 functions with all its components:</p>\n<ol>\n<li><p>A user creates a transaction, and the gas required for it is calculated.</p></li>\n<li><p>The TFM provides the current base fee needed for transaction inclusion.</p></li>\n<li><p>The user's wallet sets the fee cap and priority fee (customizable to the user's preference), and broadcasts their transaction to the mempool.</p></li>\n<li><p>When a block producer is ready to create a block, they select the set of transactions from the mempool that maximizes revenue, prioritizing those with the highest priority fees.</p></li>\n<li><p>The block producer creates the block and broadcasts it to the network, where it gets added to Ethereum.</p></li>\n<li><p>When the new block is added, the blockchain collects transaction fees, burns the base fee, and transfers the priority fee to the block producer.</p></li>\n<li><p>The protocol adjusts the base fee based on block usage: if it exceeds 15M gas, the base fee increases, if below, it decreases.</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.679Z-gpftpeuf7929753m7gfadbtz\" alt=\"\" /></p></li>\n</ol>\n<h3 id=\"incentivealignmenteip1559tfm\">Incentive Alignment (EIP-1559 TFM)</h3>\n<p>A well-designed TFM encourages users and block producers to use it and only it honestly to ensure efficient allocation of blockchain resources. Let's assess how EIP-1559 performs in this regard:</p>\n<ul>\n<li><strong>Users</strong>: EIP-1559 is <strong>mostly incentive-compatible for users</strong>. In normal conditions (steady demand and the average block size around the target), truthful bidding is the optimal strategy for users. However, during periods of prolonged excess demand or when the base fee is excessively low, EIP-1559 can resemble a first-price auction, making it less incentive-compatible. Despite these exceptions, EIP-1559 generally improves user incentive-compatibility compared to the legacy TFM, which never guaranteed this property.</li>\n<li><strong>Block Producers</strong>: EIP-1559 remains <strong>incentive-compatible for block producers</strong>. Although block producers only receive the priority fees (with base fees being burned), their best strategy for maximizing revenue is still to include the highest-priority transactions. The burning of base fees reduces the incentive for manipulation, and the potential loss of MEV-related revenue and opportunity costs makes creating empty blocks a non-dominant strategy.</li>\n</ul>\n<h3 id=\"robustnesstomanipulationeip1559tfm\">Robustness to Manipulation (EIP-1559 TFM)</h3>\n<p>EIP-1559 significantly improves robustness to manipulation compared to the legacy TFM. The improvements in this robustness are explained below:</p>\n<ul>\n<li><p><strong>Enhanced resistance to manipulation by users</strong>: Under EIP-1559, the best strategy for users is no longer to game the system, but to honestly bid the true value they ascribe to their transactions, as manipulation provides no financial advantage.</p></li>\n<li><p><strong>Strong defense against block producer and user collusion</strong>: EIP-1559 greatly reduces the incentives for collusion. Since block producers only receive the priority fee and not the base fee (which is burned), there is minimal benefit for them to engage in off-chain agreements with users. Block producers would have to cover the base fee costs themselves, making such strategies unprofitable. EIP-1559's design ensures that following the protocol is the most beneficial approach for both users and block producers.</p>\n<p>\\</p></li>\n</ul>\n<p>Having explored EIP-1559's incentive compatibility and resistance to collusion. We formally illustrate the game-theoretical properties of the mechanism below:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.673Z-me8011m5hm1wn5grz6rk506m\" alt=\"\" /></p>\n<h3 id=\"economicefficiencyeip1559tfm\">Economic Efficiency (EIP-1559 TFM)</h3>\n<p>Economic efficiency is achieved when blockspace is allocated efficiently. EIP-1559 contributes to this through:</p>\n<ol>\n<li><strong>High-value allocation</strong>: EIP-1559 allocates blockspace to transactions that reflect true economic value by providing more accurate fee estimation, which reduces guesswork and ensures that blockspace is used by those who value it most.</li>\n<li><strong>Improved price discovery</strong>: The introduction of base fees and variable block sizes enables better price discovery, allowing users to set more informed bids. This dynamic adjustment to demand reduces fee volatility and enhances the overall efficiency of the network.</li>\n</ol>\n<p>\\\nBy improving incentive alignment and robustness to manipulation, EIP-1559 has led to more efficient allocation of blockspace and enhanced network welfare. However, there is still room for improvement. EIP-1559 does not fully achieve user incentive-compatibility under all conditions, and further mechanism design is needed to minimize MEV and enhance the mechanism's game-theoretical properties for even greater efficiency gains.</p>\n<h3 id=\"marketresponsivenesseip1559tfm\">Market Responsiveness (EIP-1559 TFM)</h3>\n<p>EIP-1559 responds more dynamically to market conditions than the legacy TFM:</p>\n<ul>\n<li><strong>Dynamic base fee adjustments</strong>: By adjusting the base fee based on block utilization, EIP-1559 responds to changes in demand more smoothly, preventing sudden fee spikes and providing a more predictable fee environment.</li>\n</ul>\n<h3 id=\"userexperienceeip1559tfm\">User Experience (EIP-1559 TFM)</h3>\n<p>EIP-1559 has significantly enhanced user experience in 2 main ways:</p>\n<ol>\n<li><strong>Reduced fee volatility</strong>: EIP-1559 succeeded in decreasing fee volatility, making fee estimation easier and more predictable. These improvements are felt by users as they are now able to better anticipate transaction costs.</li>\n<li><strong>Improved transaction waiting times</strong>: With EIP-1559, transaction waiting times have decreased noticeably. Dynamic fee adjustments and variable block sizes handle demand spikes more gracefully, ensuring consistent wait times even during fluctuating market conditions.</li>\n</ol>\n<p>\\\n<a href=\"https://arxiv.org/abs/2201.05574\">Empirical analysis</a> helps support the claims made above, highlighting the enhanced performance metrics of EIP-1559 compared to the legacy TFM. The key findings from this analysis are shared below:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.366Z-i66gegtwmq6en0su1kx2wqu2\" alt=\"\" /></p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.364Z-x7al69a3dfiuuol6n1fx5bss\" alt=\"\" /></p>\n<p>\\\nFrom our thorough exploration of EIP-1559 and the previous mechanism, it is clear that we have made good progress towards achieving the goals of a transaction fee mechanism. EIP-1559 successfully reduced fee volatility, encouraged honest behavior, and shortened transaction waiting times. These improvements not only enhanced the user experience on Ethereum but also increased economic efficiency under the hood. EIP-1559, therefore, represented a successful step forward for Ethereum. <strong>So where do we go from here?</strong></p>\n<h2 id=\"2dfeemarketstheroadtomultidimensionaleip1559\">2D Fee Markets (The Road to Multi-Dimensional EIP-1559)</h2>\n<p>In March 2024, Ethereum introduced <a href=\"https://www.eip4844.com/\">EIP-4844</a>, a major upgrade that added a new resource type called <a href=\"https://research.2077.xyz/eip-7762-eip-7691-making-ethereum-blobs-great-again\">data blobs</a> to the network. Similar to how gas measures EVM execution, data blobs use a separate form of gas called data gas.</p>\n<p>\\\nTo differentiate, we'll refer to the traditional gas used for Ethereum transactions as <strong>execution gas</strong>, while the gas for data blobs is <strong>data gas</strong>. Here's how each type is used:</p>\n<ul>\n<li><strong>Execution Gas</strong>: Used for standard Ethereum transactions, such as ETH transfers, smart contract deployments and calls etc.</li>\n<li><strong>Data Gas</strong>: Used for blob transactions, which attach 128kB data blobs to publish large amounts of data on Ethereum without storing it in state.</li>\n</ul>\n<p>\\\nWhile this article wasn't written to explain what exactly this data blob resource type is and what it is used for, it would be useful to explain a little bit about them. Data blobs were introduced to Ethereum (through EIP-4844) to provide a separate fee market for publishing large amounts of data completely decoupled from the traditional fee markets that drive most transaction activity on the network.</p>\n<p>\\\nThe use case of data blobs is for actors who wish to publish data to Ethereum that will not be stored in state and hence won't require mutation or update. They usually do this to provide proof that the data was once made available on Ethereum, and if the data was stored, it can be presented to Ethereum where the integrity of the payload can be cryptographically verified (i.e., “<a href=\"https://research.2077.xyz/data-availability-or-how-rollups-learned-to-stop-worrying-and-love-ethereum\">data availability</a>”). This directly benefits <a href=\"https://research.2077.xyz/the-practical-guide-to-ethereum-rollups\">L2 solutions like rollups</a> with providing cheaper means to ensure data availability using Ethereum.</p>\n<p>\\\nWhile this is a niche use-case, before EIP-4844 users often used normal transactions (leveraging cheap <a href=\"https://research.2077.xyz/eip-7623-repricing-ethereum-calldata\">calldata</a>) to publish large amounts of data. This naturally impacted the efficiency of execution gas, as less gas became available in blocks to users actually seeking use of the EVM to perform actions like account balance updates and smart contract interactions. To improve efficiency of Ethereum, data blobs were therefore introduced to decouple these trends of usage from traditional transactions leveraging Ethereum's execution.</p>\n<p>\\\nApplying lessons from EIP-1559, EIP-4844 designed a similar fee mechanism for data blobs with some differences:</p>\n<ul>\n<li><p><strong>Target Limits</strong>: Instead of gas, blob fee markets use blob count, targeting 3 blobs per block with a hard cap of 6.</p></li>\n<li><p><strong>Transaction Costs (2D)</strong>: Blob transactions require a small amount of execution gas but primarily use blob gas. The base fee for blob gas adjusts like EIP-1559 based on usage but does not include priority fees because the priority fee of the execution gas portion of the transaction can be set to incentivize inclusion. Each blob consumes 131072 blob gas which the user pays a fee for per unit of blob gas along with the execution gas fee.</p>\n<p>\\</p>\n<p><img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-2024-12-20T08:00:11.352Z-dkuev8me8j3v6y0q9rnpsats\" alt=\"\" /></p></li>\n</ul>\n<h3 id=\"whymultidimensionalfeemarketsmatter\">Why Multi-Dimensional Fee Markets Matter</h3>\n<p><a href=\"https://vitalik.eth.limo/general/2024/05/09/multidim.html\">Multi-dimensional fee markets</a> help us segment the global market for access to Ethereum's computational resources by patterns of usage. In previous times, we used a single fee market geared towards accommodating all sorts of patterns of resource usage. However, we have come to understand that this is not an optimal approach to allocating resources.</p>\n<p>\\\nSome patterns of usage (such as using Ethereum for data availability alone) have different types of underlying demand as well as utilize network resources in different ways. It would therefore be more efficient to global blockchain resource allocation if we made abstractions for different patterns of usage into resource types (like execution, data), to price the utility of their use independently. Our long term vision with Ethereum in terms of economic efficiency is to decide upon the right abstractions and hence better organize access to scarce blockchain resources.</p>\n<h2 id=\"ultrasoundmoney\">Ultrasound Money?</h2>\n<p>At this point, we have quite exhaustively explored transaction fee mechanisms and in particular what EIP-1559 is all about. In this section we will now focus on how exactly it relates to&nbsp;<strong>Ultrasound Money</strong>🦇🔊.</p>\n<p>\\\nUltrasound Money was a term coined by Justin Drake to highlight the evolving monetary policy of the native asset of Ethereum, ETH. The term is often described as a 'meme' to help convey and assert the&nbsp;<strong>monetary premium</strong>&nbsp;of ETH.</p>\n<h2 id=\"monetarypolicyandmonetarypremiumofeth\">Monetary Policy and Monetary Premium of ETH</h2>\n<p>We often use the terms monetary policy and monetary premium when trying to assess how effective an asset can be as a form of money/currency. Lets describe what these two terms mean below:</p>\n<ul>\n<li><p><strong>Monetary Policy</strong>: This refers to how the flow of an asset is managed, including how its supply and demand are regulated within a system.</p></li>\n<li><p><strong>Monetary Premium</strong>: This refers to the additional value an asset holds because it is widely accepted and trusted as medium of exchange or store of value, beyond its intrinsic value.</p>\n<p>\\</p></li>\n</ul>\n<p>Like many forms of money/currency, ETH also has a monetary policy. However, unlike traditional currencies governed by nation-states, ETH's monetary policy is determined by its protocol design, which is algorithmic and transparent. We can better understand ETH's monetary policy by examining the key components that influence its value flow and supply regulation:</p>\n<p>\\</p>\n<ul>\n<li><p><strong>Transaction Fees</strong>: Transaction fees represent the cost to users for utilizing the network. In return, users receive private benefits from having their transactions processed. Block producers receive revenue earned from a portion of the transaction fees.</p></li>\n<li><p><strong>Welfare and Social Costs</strong>: As mentioned above, users pay ETH to receive private benefits. The prices they pay cover social costs imposed on the rest of the network(captured within Ethereum's resource pricing mechanism) as well as a premium to block producers to incentivize inclusion.</p></li>\n<li><p><strong>ETH Issuance</strong>: With the change to PoS the issuance rate of ETH has reduced. New ETH is introduced to the global supply to staked validators who participate in consensus duties such as attestation and block proposing.</p></li>\n<li><p><strong>ETH Burn</strong>: With EIP-1559, base fee burning was introduced where the majority of transaction fee amounts are removed from circulation to maintain strong game-theoretic properties that make the transaction fee mechanism robust to manipulation and hence more economically efficient. By removing ETH from the available supply, the side-effect is that the value of all ETH in circulation increases. The fee burn can therefore be viewed as a lump-sum refund to ETH holders therefore describing a value flow back to all network participants (users, block producers etc).</p>\n<p>\\</p></li>\n</ul>\n<p>While these factors help measure the value flows of ETH and help motivate the sustainability of its economic model,&nbsp;<strong>monetary premium</strong>&nbsp;is decoupled from these fundamentals. As mentioned earlier, monetary premium is a perceived status rooted in belief, which helps shape perceptions, drive adoption, and increase demand for ETH as an asset. This, in turn, enhances the overall utility and function of Ethereum, which relies on the widespread use of ETH.</p>\n<h2 id=\"eip1559shouldnotbethefaceofultrasoundmoney\">EIP-1559 should not be the face of Ultrasound Money</h2>\n<p>While EIP-1559 plays a crucial role in Ethereum's evolving monetary policy, focusing exclusively on it as the cornerstone of the Ultrasound Money narrative potentially overlooks other significant factors that contribute to ETH's value offering. To more effectively advocate for ETH's monetary premium status, it would be more beneficial to highlight a combination of factors that collectively characterize ETH as Ultrasound Money. These factors could potentially include:</p>\n<p>\\</p>\n<ul>\n<li><strong>Leadership in the Wider Crypto Landscape</strong>: Not only has Ethereum pioneered various application trends in the crypto space (e.g. DeFi, NFTs, prediction markets), it also arguably leads the way on many fronts when it comes to protocol research and development.</li>\n<li><strong>Comprehensive Monetary Policy Evolution</strong>: While the fee burning introduced with EIP-1559 is important (first and foremost for being in service of economic efficiency and strengthening game-theoretic properties rather than reducing the supply of ETH), broader monetary policy changes such as Proof of Stake economics and exploration of&nbsp;<a href=\"https://x.com/weboftrees/status/1710704461750944190\">Minimum Viable Issuance (MVI)</a>&nbsp;should be highlighted as equally significant. Highlighting the interplay of these components presents a more compelling and nuanced argument in favor of assigning monetary premium status to ETH.</li>\n<li><strong>Real World Adoption</strong>: Highlighting the adoption of Ethereum outside of the native landscape such as Visa partnerships, RWA projects such as regional banks leveraging DeFi protocols on Ethereum etc may enhance ETH's credibility and reinforces its monetary premium.</li>\n</ul>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>This article was motivated by a desire to correct misunderstandings about EIP-1559 and its role in Ethereum. Misinterpretations, often fueled by memes, can obscure the true reasons behind design choices, and it's important that we realize this and how it potentially hinders progress within this space. Wider circulation of accurate information and critical discussions are essential for driving progress and sowing the seeds for achieving meaningful global impact--we have a long road ahead of us and we need to ensure we remove as much friction we create for ourselves as possible to prepare for what's to come and the problems needing to be solved.</p>\n<p>\\\nIt is my hope that this article helps contribute towards that by reshaping perceptions around EIP-1559 and blockchain mechanism design, highlighting some of the most important work being done within this industry and how we may potentially look back at this point some day and <a href=\"https://www.youtu.be/NaRuoKvANSU?si=vWZacW8tO-FxCHkh&t=2143\">realize how important it was</a>.</p>\n<h2 id=\"additionalreadingreferences\">Additional Reading &amp; References</h2>\n<ul>\n<li>Transaction Fee Mechanism Design for the Ethereum Blockchain: An Economic Analysis of EIP-1559 (<a href=\"https://timroughgarden.org/papers/eip1559.pdf\">link</a>)</li>\n<li>Empirical Analysis of EIP-1559: Transaction Fees, Waiting Time, and Consensus Security (<a href=\"https://arxiv.org/abs/2201.05574\">link</a>)</li>\n<li>EIP 1559: A transaction fee market proposal (RIG) (<a href=\"https://ethereum.github.io/abm1559/notebooks/eip1559.html\">link</a>)</li>\n<li>Foundations of Transaction Fee Mechanism Design (<a href=\"https://arxiv.org/abs/2111.03151\">link</a>)</li>\n<li>Transaction Fees on a Honeymoon: Ethereum's EIP-1559 One Month Later (<a href=\"https://arxiv.org/abs/2110.04753\">link</a>)</li>\n<li>Blockchain Resource Pricing (<a href=\"https://ethresear.ch/t/draft-position-paper-on-resource-pricing/2838\">link</a>)</li>\n<li>Dynamic Posted-Price Mechanisms for the Blockchain Transaction Fee Market (<a href=\"https://arxiv.org/abs/2103.14144\">link</a>)</li>\n<li>Dynamical Analysis of the EIP-1559 Ethereum Fee Market (<a href=\"https://arxiv.org/abs/2102.10567\">link</a>)</li>\n<li>Optimal Dynamic Fees for Blockchain Resources (<a href=\"https://arxiv.org/abs/2309.12735\">link</a>)</li>\n<li>What Can Cryptography Do For Decentralized Mechanism Design? (<a href=\"https://eprint.iacr.org/2022/1294\">link</a>)</li>\n<li>Multidimensional gas pricing (<a href=\"https://vitalik.eth.limo/general/2024/05/09/multidim.html\">link</a>)</li>\n<li>Multidimensional EIP-1559 (<a href=\"https://ethresear.ch/t/multidimensional-eip-1559/11651\">link</a>)</li>\n</ul>\n<p>\\\n<strong><em>Author’s note: A version of this article was previously published <a href=\"https://research.2077.xyz/eip-1559-separating-mechanisms-from-memes\">here</a>.</em></strong></p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"The TechBeat: Future-proof Your Marketing With This Guide on Writing for AI Search Engines (12/20/2024)","url":"https://hackernoon.com/12-20-2024-techbeat?source=rss","date":1734678653,"author":"Techbeat","unread":true,"desc":"","content":"<p>How are you, hacker? \n 🪐<strong>Want to know what's trending right now?:</strong>\n <a href=\"https://hackernoon.com/homepage-has-a-new-baby\">The Techbeat by HackerNoon </a> has got you covered with fresh content from our trending stories of the day! Set email preference <a href=\"https://app.hackernoon.com/profile/email-settings\">here</a>.\n ## <strong><a href=\"https://hackernoon.com/future-proof-your-marketing-with-this-guide-on-writing-for-ai-search-engines\">Future-proof Your Marketing With This Guide on Writing for AI Search Engines</a></strong> <img src=\"https://cdn.hackernoon.com/images/R40xrKHcy9QXU6NDkd58YY2mQOz1-e313j4y.webp\" alt=\"\" />\n By <a href=\"https://hackernoon.com/u/darragh\">@darragh</a> [ 4 Min read ] \n Learn how to write for AI &amp; search engines with actionable tips, examples, &amp; FAQs. Future-proof your content for ChatGPT, Gemini, &amp; Google SEO success! <a href=\"https://hackernoon.com/future-proof-your-marketing-with-this-guide-on-writing-for-ai-search-engines\">Read More.</a></p>\n<h2 id=\"everythingyouneedtoknowaboutthelumoztokengenerationeventhttpshackernooncomeverythingyouneedtoknowaboutthelumoztokengenerationeventhttpscdnhackernooncomimageswls6ttjolgmbl8akwqlibcyfjqf2wm33zx8jpeg\"><strong><a href=\"https://hackernoon.com/everything-you-need-to-know-about-the-lumoz-token-generation-event\">Everything You Need to Know About the Lumoz Token Generation Event</a></strong> <img src=\"https://cdn.hackernoon.com/images/Wls6TtjOLGMbl8aKwQlIbcyfjQF2-wm33zx8.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/lumoz\">@lumoz</a> [ 5 Min read ] \n The modular compute layer &amp; RaaS platform Lumoz will launch its mainnet and conduct the TGE within a week. Find all the details here! <a href=\"https://hackernoon.com/everything-you-need-to-know-about-the-lumoz-token-generation-event\">Read More.</a></p>\n<h2 id=\"blockstmvssealevelacomparisonofparallelexecutionengineshttpshackernooncomblockstmvssealevelacomparisonofparallelexecutionengineshttpscdnhackernooncomimageswsqjfcsxoxwphtnq7snevvhdwgu1j7036ekpng\"><strong><a href=\"https://hackernoon.com/block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines\">Block-STM vs. Sealevel: A Comparison of Parallel Execution Engines</a></strong> <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-j7036ek.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 75 Min read ] \n Block-STM and Sealevel are two approaches to parallelizing blockchain execution. This paper will examine and break down how both TPUs approach parallelization. <a href=\"https://hackernoon.com/block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines\">Read More.</a></p>\n<h2 id=\"dissectingtheresearchbehindbadgpt4oamodelthatremovesguardrailsfromgptmodelshttpshackernooncomdissectingtheresearchbehindbadgpt4oamodelthatremovesguardrailsfromgptmodelshttpscdnhackernooncomimagesn0enud29udnjcfcl7gnmzhdk2fa23i039lewebp\"><strong><a href=\"https://hackernoon.com/dissecting-the-research-behind-badgpt-4o-a-model-that-removes-guardrails-from-gpt-models\">Dissecting the Research Behind BadGPT-4o, a Model That Removes Guardrails from GPT Models</a></strong> <img src=\"https://cdn.hackernoon.com/images/N0ENUd29UdNJCFcl7GnmZHdk2fA2-3i039le.webp\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/applicantsports816\">@applicantsports816</a> [ 10 Min read ] \n Enter BadGPT-4o: a model that has had its safety measures neatly stripped away not through direct weight hacking (as with the open-weight “Badllama” approach). <a href=\"https://hackernoon.com/dissecting-the-research-behind-badgpt-4o-a-model-that-removes-guardrails-from-gpt-models\">Read More.</a></p>\n<h2 id=\"easilywinargumentsbyavoidingthese8logictrapshttpshackernooncomeasilywinargumentsbyavoidingthese8logictrapshttpscdnhackernooncomimagesqkxa8mx2ejscmsrnggr3wbldxfn22w1353jpng\"><strong><a href=\"https://hackernoon.com/easily-win-arguments-by-avoiding-these-8-logic-traps\">Easily Win Arguments By Avoiding These 8 Logic Traps</a></strong> <img src=\"https://cdn.hackernoon.com/images/qkXA8MX2eJScMSRNgGr3WBlDxfN2-2w1353j.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/benoitmalige\">@benoitmalige</a> [ 5 Min read ] \n Learn how to spot and dismantle 8 common logic traps people use in arguments. Stay calm, keep your sanity, and avoid wasting energy in pointless debates. <a href=\"https://hackernoon.com/easily-win-arguments-by-avoiding-these-8-logic-traps\">Read More.</a></p>\n<h2 id=\"shortonbudgetusethesedesignmethodologiestobuildyourfirstmvpwithoutafulltimedesignerhttpshackernooncomshortonbudgetusethesedesignmethodologiestobuildyourfirstmvpwithoutafulltimedesignerhttpscdnhackernooncomimagesq85ywte3qmyufwxzl6mfnyzzwa438u03d0apng\"><strong><a href=\"https://hackernoon.com/short-on-budget-use-these-design-methodologies-to-build-your-first-mvp-without-a-full-time-designer\">Short on Budget? Use These Design Methodologies to Build Your First MVP Without a Full-time Designer</a></strong> <img src=\"https://cdn.hackernoon.com/images/q85yWTe3qMYufWXZl6MfnYzzwa43-8u03d0a.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/marinacher\">@marinacher</a> [ 8 Min read ] \n An early-stage startup doesn’t always need a full-time designer. Product-oriented founders can often build their first prototypes on their own. <a href=\"https://hackernoon.com/short-on-budget-use-these-design-methodologies-to-build-your-first-mvp-without-a-full-time-designer\">Read More.</a></p>\n<h2 id=\"rankingonaiisnotascomplicatedasyouthinkhttpshackernooncomrankingonaiisnotascomplicatedasyouthinkhttpscdnhackernooncomimagesr40xrkhcy9qxu6ndkd58yy2mqoz1ta13j7mwebp\"><strong><a href=\"https://hackernoon.com/ranking-on-ai-is-not-as-complicated-as-you-think\">Ranking on AI Is Not as Complicated As You Think</a></strong> <img src=\"https://cdn.hackernoon.com/images/R40xrKHcy9QXU6NDkd58YY2mQOz1-ta13j7m.webp\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/darragh\">@darragh</a> [ 8 Min read ] \n Explore actionable ways to ensure your content surfaces in AI-driven search results and resonates with human readers. <a href=\"https://hackernoon.com/ranking-on-ai-is-not-as-complicated-as-you-think\">Read More.</a></p>\n<h2 id=\"managingstressmaybealotsimplerthanyouthinkhttpshackernooncommanagingstressmaybealotsimplerthanyouthinkhttpscdnhackernooncomimages6aqve9bubzwe8iooqiq5mujze9p2um034k4png\"><strong><a href=\"https://hackernoon.com/managing-stress-may-be-a-lot-simpler-than-you-think\">Managing Stress May Be A Lot Simpler Than You Think</a></strong> <img src=\"https://cdn.hackernoon.com/images/6aqvE9BUBZWe8iOoQIq5MuJze9P2-um034k4.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/vinitabansal\">@vinitabansal</a> [ 8 Min read ] \n You can't avoid stress, but you can certainly learn to manage it well. To do this, you need to apply the right strategies by taking charge. <a href=\"https://hackernoon.com/managing-stress-may-be-a-lot-simpler-than-you-think\">Read More.</a></p>\n<h2 id=\"dataavailabilityorhowrollupslearnedtostopworryingandloveethereumhttpshackernooncomdataavailabilityorhowrollupslearnedtostopworryingandloveethereumhttpscdnhackernooncomimageswsqjfcsxoxwphtnq7snevvhdwgu1hd036k1png\"><strong><a href=\"https://hackernoon.com/data-availability-or-how-rollups-learned-to-stop-worrying-and-love-ethereum\">Data Availability Or: How Rollups Learned To Stop Worrying And Love Ethereum</a></strong> <img src=\"https://cdn.hackernoon.com/images/WSQJfCSXOxWphTNQ7sneVvhdWGu1-hd036k1.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 27 Min read ] \n Data availability is a critical component of scaling Ethereum. Learn how and why Layer 2 rollups use Ethereum for data availability—and why this matters.  <a href=\"https://hackernoon.com/data-availability-or-how-rollups-learned-to-stop-worrying-and-love-ethereum\">Read More.</a></p>\n<h2 id=\"hereswhyhighachieversfeellikefailureshttpshackernooncomhereswhyhighachieversfeellikefailureshttpscdnhackernooncomimagesstandingontopofamountaind0kxvq2p6k7msfxxmb3n6r8mpng\"><strong><a href=\"https://hackernoon.com/heres-why-high-achievers-feel-like-failures\">Here's Why High Achievers Feel Like Failures</a></strong> <img src=\"https://cdn.hackernoon.com/images/standing-on-top-of-a-mountain-d0kxvq2p6k7msfxxmb3n6r8m.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/scottdclary\">@scottdclary</a> [ 11 Min read ] \n The invisible progress paradox is a trap in personal growth. <a href=\"https://hackernoon.com/heres-why-high-achievers-feel-like-failures\">Read More.</a></p>\n<h2 id=\"howimademoneyinvestingindomainsseostrategyhttpshackernooncomhowimademoneyinvestingindomainsseostrategyhttpscdnhackernooncomimagesz3pyaaww4yzlfgent8cifkrj6bs2pn23bn5jpeg\"><strong><a href=\"https://hackernoon.com/how-i-made-money-investing-in-domains-seo-strategy\">How I Made Money Investing in Domains (SEO Strategy)</a></strong> <img src=\"https://cdn.hackernoon.com/images/z3PYaAWw4yZlfgEnT8CiFKRJ6BS2-pn23bn5.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/amraandelma\">@amraandelma</a> [ 6 Min read ] \n Invest in domains and turn them into financial assets through effective research and effective judgment of market trends. <a href=\"https://hackernoon.com/how-i-made-money-investing-in-domains-seo-strategy\">Read More.</a></p>\n<h2 id=\"thismonetizationapproachisbecomingmoreprominentinsoftwaresaleshttpshackernooncomthismonetizationapproachisbecomingmoreprominentinsoftwaresaleshttpscdnhackernooncomimageslibt2pgxytgfxfchuwb7qqqmcr425h034jtpng\"><strong><a href=\"https://hackernoon.com/this-monetization-approach-is-becoming-more-prominent-in-software-sales\">This Monetization Approach Is Becoming More Prominent in Software Sales</a></strong> <img src=\"https://cdn.hackernoon.com/images/libt2PgxytgFxFcHUwB7QQQmCr42-5h034jt.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/pbland\">@pbland</a> [ 5 Min read ] \n As usage-based pricing options grow in popularity, see how offering flexibility can complement - rather than replace - software subscription models. <a href=\"https://hackernoon.com/this-monetization-approach-is-becoming-more-prominent-in-software-sales\">Read More.</a></p>\n<h2 id=\"letsbuildafreewebscrapingtoolthatcombinesproxiesandaifordataanalysishttpshackernooncomletsbuildafreewebscrapingtoolthatcombinesproxiesandaifordataanalysishttpscdnhackernooncomimagesavhtbhxsgebzi995yukuzgm8buc2axc3dwmpng\"><strong><a href=\"https://hackernoon.com/lets-build-a-free-web-scraping-tool-that-combines-proxies-and-ai-for-data-analysis\">Let's Build a Free Web Scraping Tool That Combines Proxies and AI for Data Analysis</a></strong> <img src=\"https://cdn.hackernoon.com/images/AVhTbHxsGebzI995YUKuzGm8bUC2-axc3dwm.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/aviatorscode2\">@aviatorscode2</a> [ 15 Min read ] \n Learn how to combine web scraping, proxies, and AI-powered language models to automate data extraction and gain actionable insights effortlessly. <a href=\"https://hackernoon.com/lets-build-a-free-web-scraping-tool-that-combines-proxies-and-ai-for-data-analysis\">Read More.</a></p>\n<h2 id=\"ifellinlovewithmycodethenihadtokillithttpshackernooncomifellinlovewithmycodethenihadtokillithttpscdnhackernooncomimagesous9hxhnmoackh1uhedoxjmokwv17z22qhgpng\"><strong><a href=\"https://hackernoon.com/i-fell-in-love-with-my-code-then-i-had-to-kill-it\">I Fell in Love With My Code, Then I Had to Kill It</a></strong> <img src=\"https://cdn.hackernoon.com/images/oUS9HxHnMOackh1UhEDoXjMokWv1-7z22qhg.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/michaelsalim\">@michaelsalim</a> [ 6 Min read ] \n Sometimes the best code is the code you delete. Don't love your code and do what's best for the codebase. <a href=\"https://hackernoon.com/i-fell-in-love-with-my-code-then-i-had-to-kill-it\">Read More.</a></p>\n<h2 id=\"installingopensourcesoftwareonyourmacosmaybecomingtoanendhttpshackernooncominstallingopensourcesoftwareonyourmacosmaybecomingtoanendhttpscdnhackernooncomimageszvmm936jeisn3robjorot0m3wre3ns0341vpng\"><strong><a href=\"https://hackernoon.com/installing-open-source-software-on-your-macos-may-be-coming-to-an-end\">Installing Open-source Software on Your MacOS May Be Coming to an End</a></strong> <img src=\"https://cdn.hackernoon.com/images/ZVMm936JeiSn3robjOroT0m3wrE3-ns0341v.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/saurabh-sugandh\">@saurabh-sugandh</a> [ 3 Min read ] \n Apple has made it clear that applications need to be signed (or say notarized) first before you install them.  <a href=\"https://hackernoon.com/installing-open-source-software-on-your-macos-may-be-coming-to-an-end\">Read More.</a></p>\n<h2 id=\"elsalvadorspresidentteasesrentyourownvolcanobitcoinminingplanhttpshackernooncomelsalvadorspresidentteasesrentyourownvolcanobitcoinminingplanhttpscdnhackernooncomimageszsnnpz3gejgvsxqs3eyp38vlsll2ye0341ujpeg\"><strong><a href=\"https://hackernoon.com/el-salvadors-president-teases-rent-your-own-volcano-bitcoin-mining-plan\">El Salvador's President Teases “Rent Your Own Volcano” Bitcoin Mining Plan</a></strong> <img src=\"https://cdn.hackernoon.com/images/ZSnNpZ3GejgVSxqs3EyP38vlsLL2-ye0341u.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/thesociable\">@thesociable</a> [ 5 Min read ] \n El Salvador’s geothermal Bitcoin mining, including a “rent your own volcano” plan, sparks debate on sustainability, costs, and potential economic growth. <a href=\"https://hackernoon.com/el-salvadors-president-teases-rent-your-own-volcano-bitcoin-mining-plan\">Read More.</a></p>\n<h2 id=\"thesneakywaywebbrowsersareidentifyingyouevenwhenyouturnoffcookieshttpshackernooncomthesneakywaywebbrowsersareidentifyingyouevenwhenyouturnoffcookieshttpscdnhackernooncomimageslvbwxpoo4wxh8mnqfbfkapmqkai21d0370tpng\"><strong><a href=\"https://hackernoon.com/the-sneaky-way-web-browsers-are-identifying-you-even-when-you-turn-off-cookies\">The Sneaky Way Web Browsers Are Identifying You (Even When You Turn Off Cookies)</a></strong> <img src=\"https://cdn.hackernoon.com/images/lvbwxpoO4WXH8MNqfBFKapMQkAi2-1d0370t.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/rampageproxies\">@rampageproxies</a> [ 12 Min read ] \n A guide on browser fingerprinting, how it identifies us, fingerprint testing, and what techniques we can use to ensure our browsing is kept anonymous. <a href=\"https://hackernoon.com/the-sneaky-way-web-browsers-are-identifying-you-even-when-you-turn-off-cookies\">Read More.</a></p>\n<h2 id=\"bitcoingetsdefiupgradestackslaunchesbitcoinbackedsbtcforsmartcontractshttpshackernooncombitcoingetsdefiupgradestackslaunchesbitcoinbackedsbtcforsmartcontractshttpscdnhackernooncomimages7remniehnfobfzztumqeroziggh3zd036p5png\"><strong><a href=\"https://hackernoon.com/bitcoin-gets-defi-upgrade-stacks-launches-bitcoin-backed-sbtc-for-smart-contracts\">Bitcoin Gets DeFi Upgrade: Stacks Launches Bitcoin-Backed sBTC for Smart Contracts</a></strong> <img src=\"https://cdn.hackernoon.com/images/7rEmNIeHNFOBfZZtUMQerOZIGGH3-zd036p5.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/ishanpandey\">@ishanpandey</a> [ 3 Min read ] \n The launch of sBTC indicates growing maturity in Bitcoin's ecosystem, particularly in bridging traditional Bitcoin holdings with DeFi.  <a href=\"https://hackernoon.com/bitcoin-gets-defi-upgrade-stacks-launches-bitcoin-backed-sbtc-for-smart-contracts\">Read More.</a></p>\n<h2 id=\"academicpiracyissometimestheonlywaytosurvivethefinancialexploitationofknowledgehttpshackernooncomacademicpiracyissometimestheonlywaytosurvivethefinancialexploitationofknowledgehttpscdnhackernooncomimages3gwutajrwqvk90fbpczdqx8nvyj1fj03a70png\"><strong><a href=\"https://hackernoon.com/academic-piracy-is-sometimes-the-only-way-to-survive-the-financial-exploitation-of-knowledge\">Academic Piracy Is Sometimes the Only Way to Survive the Financial Exploitation of Knowledge</a></strong> <img src=\"https://cdn.hackernoon.com/images/3GwutAJRWQVk90FbpCzdqx8nvyj1-fj03a70.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/thefrogsociety\">@thefrogsociety</a> [ 19 Min read ] \n Quality learning is increasingly gated by wealth, widening inequalities and limiting access  <a href=\"https://hackernoon.com/academic-piracy-is-sometimes-the-only-way-to-survive-the-financial-exploitation-of-knowledge\">Read More.</a></p>\n<h2 id=\"thedxrpcomebackwasalongtimecominghttpshackernooncomthedxrpcomebackwasalongtimecominghttpscdnhackernooncomimages2jqchkrv03exbugklrdzibfm99q2ac02txjjpeg\"><strong><a href=\"https://hackernoon.com/the-$xrp-comeback-was-a-long-time-coming\">The $XRP Comeback Was a Long Time Coming</a></strong> <img src=\"https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-ac02txj.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/gleams\">@gleams</a> [ 8 Min read ] \n Here are the four things I spotted Ripple doing right, even when every one was sleeping on the cryptocurrency. <a href=\"https://hackernoon.com/the-$xrp-comeback-was-a-long-time-coming\">Read More.</a> \n 🧑‍💻 What happened in your world this week? It's been said that <a href=\"https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6\">writing can help consolidate technical knowledge</a>, <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\">establish credibility</a>,<a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\"> and contribute to emerging community standards</a>. Feeling stuck? We got you covered ⬇️⬇️⬇️\n <a href=\"https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble\">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>\n We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.\n See you on Planet Internet! With love, \n The HackerNoon Team ✌️\n <img src=\"https://cdn.hackernoon.com/images/ezgif.com-gif-maker%20(44).gif\" alt=\"\" /></p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"How Sports Is Taking over New Hollywood on Connected TV","url":"https://hackernoon.com/how-sports-is-taking-over-new-hollywood-on-connected-tv?source=rss","date":1734671197,"author":"David Deal","unread":true,"desc":"","content":"<p>\\\nSports is deeply intertwined with digital culture and consumer behavior, shaping how we search, stream, and spend our time online. The relationship between sports and culture is undeniable, with ripple effects across industries like entertainment, fashion, and technology. And as a result, sports is taking over connected TV.</p>\n<h2 id=\"digitalsearchandsocialnbsptrends\"><strong>Digital Search and Social&nbsp;Trends</strong></h2>\n<p>The dominance of sports in digital search speaks volumes about its cultural impact.&nbsp;<a href=\"https://techcrunch.com/2024/12/10/from-liam-payne-to-coastal-granddaughters-here-are-the-top-trending-searches-for-2024-according-to-google/\">The Top 4 Google searches of 2024</a> — Copa America, UEFA European Championship, ICC Men’s T20 World Cup, and the India vs. England soccer match — show how sports transcends borders and connects global audiences. Even though the NFL reigns supreme in the U.S., soccer and cricket dominated the global stage in terms of digital curiosity and online engagement. Sports figures also made a mark, with Mike Tyson landing among the most searched people after his hyped novelty boxing match against Jake Paul. This event streamed exclusively on Netflix, drawing a massive audience and paving the way for similar sports-driven entertainment hybrids.</p>\n<h2 id=\"culturalcollisionssportsandnbspfashion\"><strong>Cultural Collisions: Sports and&nbsp;Fashion</strong></h2>\n<p>Fashion and sports continue to intersect in new and unexpected ways. In 2024, Tenniscore — a cultural movement blending tennis aesthetics with high fashion — rose to prominence. This was amplified by Zendaya’s role in&nbsp;<em>Challengers,</em>&nbsp;a tennis-centric movie that blurred the line between sports and pop culture. Similarly, NBA players like Shai Gilgeous-Alexander are turning pre-game tunnels into runways, with fans tuning in to see what they’ll wear next as much as for the games themselves.</p>\n<h2 id=\"thetaylorswiftnbspeffect\"><strong>The Taylor Swift&nbsp;Effect</strong></h2>\n<p>Perhaps no moment in 2024 illustrated the cultural power of sports more than the Taylor Swift-NFL crossover. Swift’s relationship with Kansas City Chiefs star Travis Kelce sent NFL ratings soaring and made Swift the unlikely face of the league for a younger, predominantly female demographic. Swift-inspired NFL merchandise flew off the shelves, further proving how sports taps into broader cultural trends to drive engagement and sales.</p>\n<h2 id=\"newhollywoodsnewnbspplaybook\">New Hollywood’s New&nbsp;Playbook</h2>\n<p>All of the above trends are converging on connected TV, where New Hollywood streaming platforms are rewriting the rules for how sports are consumed, shifting away from just airing games to building ecosystems that engage audiences year-round. The NFL’s partnership with Netflix has helped bring sports to a broader, more digitally native audience. The collaboration extends beyond live broadcasts, incorporating exclusive behind-the-scenes content, interactive polls during games, and even halftime concerts like Beyoncé’s highly anticipated Christmas Day performance. This approach reflects how platforms are turning live sports into multifaceted entertainment experiences.</p>\n<p>\\\nAmazon Prime Video has taken its NFL coverage to the next level with features like X-Ray, which overlays live stats, player histories, and game predictions on the screen in real-time. This interactive experience keeps viewers engaged during games and encourages participation through second-screen apps. Similarly, Apple TV+ has integrated its MLS Season Pass with custom playlists on Apple Music and exclusive player interviews, merging sports with music and storytelling to amplify fan engagement.</p>\n<h3 id=\"connectedcontent\">Connected Content</h3>\n<p>New Hollywood streaming services are well-positioned to attract sports fans by tapping into the many ways they can create content related to the actual competition. These platforms are doing more than air live event. They’re crafting narratives that extend the life of a single game, match, or fight. Netflix, for example, didn’t stop at streaming the Jake Paul vs. Mike Tyson fight, one of the most talked-about events of 2024. Netflix capitalized on the event (OK, let’s get real: hyped the event) by producing a mini-documentary chronicling the build-up to the fight, including behind-the-scenes footage, exclusive interviews, and training montages. This approach heightened the drama and drew in viewers who might not have initially cared about the bout, turning it into a cultural phenomenon.</p>\n<p>\\\nSimilarly, the success of Netflix’s&nbsp;<em>Drive to Survive</em>&nbsp;has inspired the platform to replicate the formula for other sports. With&nbsp;*Break Point,*Netflix brought the human side of tennis to life, offering fans an intimate glimpse into the athletes’ mental struggles, rivalries, and personal sacrifices. These shows are not just for avid sports fans; they’re tailored to engage broader audiences, from casual viewers to those entirely new to the sport. This ability to humanize athletes and craft stories has allowed streaming platforms to build connections with viewers who may never have tuned in for live matches alone.</p>\n<p>\\\nWhich, of course, translates to ratings. Which, of course, translates to advertising revenue . . . and bigger market capitalizaitons for New Hollywood streaming companies.</p>\n<p>\\\nOther services are adopting similar strategies, merging sports content with cultural touchpoints. Apple TV+ is integrating its MLS Season Pass with exclusive documentaries on soccer legends and interviews with rising stars, which  keeps fans engaged between matches. Amazon Prime Video has taken a step further with interactive content, such as live Q&amp;A sessions with players and coaches, or alternate broadcasts featuring celebrity commentators who break down the game in a more entertaining, accessible way. These efforts create a more holistic experience, blending live sports with the entertainment value of reality TV and documentaries.</p>\n<p>\\\nStreaming platforms are also embracing cross-genre storytelling to attract younger viewers who might not watch sports traditionally. Hulu’s recent collaboration with ESPN+ produced a limited series blending sports with social commentary, exploring how athletes are shaping culture both on and off the field. This type of content speaks to Gen Z and millennials, who are drawn to stories that combine sports with larger societal themes.</p>\n<p>\\\nStreaming companies are  creators of sports ecosystems that keep fans engaged 24/7. By surrounding the core competitions with complementary content, platforms like Netflix, Amazon, and Apple are redefining how sports and entertainment coexist in the digital age.</p>\n<h3 id=\"communitybuilding\">Community Building</h3>\n<p>New Hollywood services are also experimenting with community-building tools to retain fans long after the final whistle. For example, Amazon’s partnership with Twitch enables live watch parties, where fans can react to games and chat in real time. Hulu has expanded its lineup of sports documentaries, catering to the growing demand for deeper narratives about the athletes and events shaping the sports world. By creating content pipelines that keep sports at the forefront even during the offseason, streaming platforms help ensure fans stay engaged and ready to tune in when the games return.</p>\n<p>\\\nPlatforms are also using AI to personalize the sports experience further. Algorithms now suggest game highlights, fantasy league updates, and related content tailored to viewers’ preferences. For instance, ESPN+ uses AI to recommend clips of key plays that match a subscriber’s favorite teams or players. Peacock integrates user data to highlight upcoming matches of potential interest during live streams. This keeps fans glued to their screens and drives a more personalized and interactive viewing experience.</p>\n<p>\\\nThe shift in sports streaming is about turning every match, season, and moment into a comprehensive digital experience. This strategy is reshaping how audiences connect with sports in the digital age. In 2025, we may find ourselves spending as much time exploring the surrounding content as we do watching the games themselves.</p>\n<h2 id=\"herecometheadvertisers\"><strong>Here Come the Advertisers</strong></h2>\n<p>Where there is culture, there are advertisers striving for cultural relevance.</p>\n<p>\\\nLive sports continue to dominate as the gold standard for real-time, engaged audiences, and advertisers are capitalizing on this dominance by focusing heavily on connected TV (CTV) advertising. Unlike traditional TV, CTV offers precision targeting and interactive opportunities that align perfectly with the sports-viewing experience, making it a battleground for brands.</p>\n<p>\\\nAs more fans turn to streaming platforms for live sports, advertisers are rethinking how to deliver ads that resonate in these environments. Brands are embracing dynamic ad insertion (DAI), which allows ads to be tailored in real-time based on the viewer’s location, demographic, or even their favorite team. For instance, during a live NFL game streamed on Peacock, viewers in different regions might see localized ads for nearby restaurants, while younger viewers might receive targeted promotions for gaming consoles or streaming services.</p>\n<p>\\\nInteractivity is also shaping the future of sports advertising on CTV. Platforms like Amazon Prime Video, which streams exclusive NFL Thursday Night Football and Black Friday games, now include shoppable ads that allow viewers to purchase products directly from their screens without pausing the game. This seamless integration of commerce into the sports experience is not only convenient but also highly effective at capturing impulse purchases.</p>\n<p>\\\nBrands are also leveraging second-screen strategies to complement their CTV campaigns. During live events, viewers are encouraged to engage with ads through companion apps or social media. For example, a soft drink brand might run a campaign during a soccer match on YouTube TV, asking fans to vote on the game’s most exciting play via an app or X. These activations not only increase ad engagement but also amplify the reach of the campaigns across multiple channels.</p>\n<p>\\\nConnected TV also provides  opportunities for measurement and optimization. Advertisers can now track viewership data in near real-time, allowing them to understand ad performance at a granular level. This insight enables brands to adjust their campaigns on the fly, whether by swapping out underperforming ads or doubling down on creative that’s driving engagement. For instance, Disney’s ESPN+ uses predictive analytics to identify when viewers are most likely to be receptive to ads, ensuring that campaigns land at the right moment.</p>\n<p>\\\nSponsorships are evolving as well. Beyond the traditional 30-second ad spots, brands are embedding themselves directly into the sports experience. Streaming services are incorporating branded elements like sponsored game stats, virtual billboards, and halftime shows. For example, during an NBA game streamed on Hulu, a tech company might sponsor the “key performance stats,” displayed on-screen with the company’s logo, creating a subtle yet impactful presence throughout the game.</p>\n<p>\\\nThe flexibility and creativity offered by connected TV advertising are also attracting smaller brands that were previously priced out of live sports advertising on traditional broadcast TV. Streaming platforms like Roku and Pluto TV are creating accessible ad packages tailored to smaller budgets, democratizing access to premium live sports audiences.</p>\n<h2 id=\"whatsnext\"><strong>What’s Next?</strong></h2>\n<p>The convergence of sports, culture, and digital media in 2024 is just the beginning. As New Hollywood platforms continue to refine their sports strategies and experiment with new ways to keep fans engaged year-round, the influence of sports on our digital lives is only set to deepen. 2024 has shown that sports is more than a game. It’s a cultural cornerstone.</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Google’s AI Power Moves with Gemini 2.0 and Project Mariner","url":"https://hackernoon.com/googles-ai-power-moves-with-gemini-20-and-project-mariner?source=rss","date":1734670929,"author":"David Deal","unread":true,"desc":"","content":"<p>\\\nIt’s fashionable to dunk on Google. But the company recently made some announcements that demonstrate how Google is adapting to the AI arms race.&nbsp;The company made two big announcements recently – the launch of&nbsp;<strong><a href=\"https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/\">Gemini 2.0</a></strong>&nbsp;and&nbsp;<strong><a href=\"https://deepmind.google/technologies/project-mariner/\">Project Mariner</a></strong>&nbsp;-- that demonstrate an ability to balance the need for acting quickly yet thoughtfully.</p>\n<p>\\</p>\n<h2 id=\"losingdominanceisgoodforgoogle\">Losing Dominance Is Good for Google</h2>\n<p>Google’s global search market share has seen a&nbsp;<strong><a href=\"https://web.swipeinsight.app/posts/google-s-market-share-drops-to-lowest-point-since-2009?t\">gradual decline</a></strong>. Younger audiences, particularly Gen Z,&nbsp;<strong><a href=\"https://www.wsj.com/tech/googling-is-for-old-people-thats-a-problem-for-google-5188a6ed\">are increasingly using platforms like TikTok and Amazon for searches instead of Google</a></strong>. Meanwhile AI-driven search engines such as Chat GPT Perplexity AI are offering innovative experiences that challenge Google’s traditional model. These tools focus on conversational and generative search capabilities, which appeal to users seeking more interactive or specific results.</p>\n<p>\\\nBut the real problem for Google? Its share of the U.S. search advertising market&nbsp;<strong><a href=\"https://www.entrepreneur.com/business-news/google-losing-search-ad-dominance-to-ai-amazon-tiktok/480906?t\">is projected to fall below 50% for the first time by 2025</a></strong>, down from historical dominance exceeding 70%. Amazon is expected to capture nearly 25% of this market, with TikTok and AI-powered tools also gaining ground. Money talks. Money demands action.</p>\n<p>\\\nLosing dominance is&nbsp;good for Google. Dominance too often breeds complacency. But Google has struggled to find the right balance between responding quickly and thoughtfully. When ChatGPT upended the technology industry in November 2022, Google was characterized as a slow-moving battleship with OpenAI being the fast-moving speed boat. Google responded by going into panic mode. The company rushed to market its answer to ChatGPT, Bard. Unfortunately for Google,&nbsp;<strong><a href=\"https://9to5google.com/2023/02/10/google-employee-sundar-pichai-bard-reveal/?t\">Bard was viewed as a botched roll-out</a></strong>, as the generative Ai chatbot committed numerous mistakes.</p>\n<p>\\\nBut Google licked its wounds and made Bard (rebranded as Gemini) better. Google developed Gemini to the point where it’s now&nbsp;<strong><a href=\"https://explodingtopics.com/blog/most-popular-ai-tools?t\">the second-most popular generative AI model behind ChatGPT</a></strong>. True, ChatGPT has a huge head start and a much larger user base, but Gemini has come a long way in a short amount of time.</p>\n<p>\\\nWhich brings us to two major announcements that Google made recently.</p>\n<h2 id=\"googlesgenerativeaigetssmarter\">Google’s Generative AI Gets Smarter</h2>\n<p>Gemini has advanced significantly with its latest update to Gemini, Gemini 2.0. The roll-out features improved speed, multimodal capabilities, and a deeper contextual understanding of user queries. These advancements aim to position Gemini as a more versatile and powerful tool, particularly for search and content generation.</p>\n<h3 id=\"enhancedmultimodalprocessing\">Enhanced Multimodal Processing</h3>\n<p>One of Gemini 2.0’s notable features is its ability to process and generate content across multiple formats—text, images, and audio—simultaneously. This marks a shift from traditional single-modal interactions, where responses are limited to one format, to dynamic, context-rich responses tailored to the user’s needs.</p>\n<p>\\\nFor example, a user seeking information about a scientific concept might receive a detailed written explanation, a supporting diagram, and an audio summary, all in a single interaction. For recipe searches, users could be presented with step-by-step instructions, a narrated audio guide, and video demonstrations integrated directly into search results.</p>\n<h3 id=\"improvedunderstandingofcontextandintent\">Improved Understanding of Context and Intent</h3>\n<p>Gemini 2.0 demonstrates a more nuanced grasp of user queries, particularly those that are ambiguous or layered. By using advanced natural language understanding (NLU) models, it can disambiguate complex questions and generate responses that synthesize multiple data points. For instance, when a user asks a compound question such as “What are the health benefits of matcha, and how can I incorporate it into my diet?” Gemini can provide a breakdown of matcha’s nutritional benefits, personalized dietary recommendations, and links to recipes or related multimedia content.</p>\n<h3 id=\"dynamicknowledgeintegration\">Dynamic Knowledge Integration</h3>\n<p>Gemini can tap into real-time data and combine it with its static training. This dynamic integration means users can receive up-to-date information on rapidly evolving topics like current events, market trends, or technological developments. For businesses, this raises the stakes to make sure their content is both timely and continuously updated to remain relevant in searches.</p>\n<h3 id=\"scalabilityforlargescalequeries\">Scalability for Large-Scale Queries</h3>\n<p>Gemini 2.0 is designed to handle more complex and data-intensive queries without sacrificing speed. It can synthesize large volumes of structured and unstructured data—such as databases, articles, and multimedia—into concise, actionable answers. This capability may benefit industries like finance, healthcare, and education, where users often seek detailed, high-precision responses.</p>\n<h3 id=\"personalizationcapabilities\">Personalization Capabilities</h3>\n<p>Gemini 2.0 uses contextual signals such as user search history and preferences to deliver highly personalized responses. This personalization allows Gemini to tailor its output based on the user’s unique needs. For example, a frequent traveler researching a destination might receive tailored results, including flight deals, hotel recommendations, and travel guides that align with their budget and previous searches.</p>\n<h2 id=\"gemini20implicationsforbusinesses\">Gemini 2.0: Implications for Businesses</h2>\n<p>These advancements in Gemini mean businesses need to rethink their digital strategies in several ways, such as optimizing content for multimodal outputs. And this is where Google’s distinct advantage comes into play: Google is incorporating Gemini into its vast ecosystem of products, such as Search, Google Workplace, the Android operating system, and Gmail. And even though Google is being challenged, its ecosystem remains powerful. So, businesses need to adapt. Here are near-term implications.</p>\n<h3 id=\"contentstructuring\">Content Structuring</h3>\n<p>To succeed in a Gemini-powered ecosystem, businesses must create content that not only communicates effectively with users but also aligns with the technical requirements of AI-driven platforms. This means breaking down information into modular, layered formats that can be easily parsed and rendered across different media.</p>\n<p>\\\nFor example, text descriptions should be paired with accompanying visuals like diagrams or infographics, each tagged with relevant metadata to ensure machine readability. Audio components, such as narrated guides or summaries, can complement these formats to enhance accessibility and engagement.</p>\n<p>\\\nThis approach caters to Gemini’s ability to provide multimodal responses by optimizing all content elements (whether textual, visual, or auditory) for integration and presentation in search results or AI-assisted applications.</p>\n<h3 id=\"datainteroperability\">Data Interoperability</h3>\n<p>The knowledge integration capabilities of Gemini require businesses to make their digital assets machine-readable and easily interpretable. Structured data plays a key role here, as schema markup, metadata, and semantic tagging enable Gemini to extract and contextualize information efficiently.</p>\n<p>\\\nFor instance, an eCommerce platform could use product schema to highlight details like price, availability, and reviews, thus making sure that Gemini can accurately pull relevant results for queries such as “top-rated laptops under $1,000.”</p>\n<p>\\\nBusinesses might also need to invest in dynamic data systems that allow for real-time updates to make sure that time-sensitive information (e.g., stock levels or promotional pricing) remains accurate when surfaced by AI. This level of interoperability might improve both visibility in AI-driven search and also reduce the risk of outdated or irrelevant results alienating potential customers.</p>\n<h3 id=\"userintentmapping\">User Intent Mapping</h3>\n<p>Gemini’s ability to understand and respond to nuanced queries means businesses must go beyond surface-level content and anticipate the broader context of user searches. This requires mapping out user intent, including potential follow-up questions and related interests, and creating content that addresses these layers of need.</p>\n<p>\\\nFor example, a fitness brand catering to a query like “best home treadmill” could enhance its content strategy by including multimedia elements that answer implicit questions, such as a setup video for the treadmill, a downloadable workout plan, and a maintenance guide. Anticipating these secondary needs would improve the user experience and position the brand as a comprehensive resource.</p>\n<p>\\\nBusinesses can maximize the relevance and impact of their digital assets in AI-powered environments by understanding and addressing both explicit and implicit user intent.</p>\n<h2 id=\"googletacklesaiagentswithprojectmariner\">Google Tackles AI Agents with Project Mariner</h2>\n<p>Google also made inroads with AI agents, which are intelligent systems designed to perform tasks autonomously.</p>\n<p>\\\nThe adoption of AI agents by companies like Salesforce is one of the biggest stories in the business world due to their potential to automate complex tasks, improve operational efficiency, and possibly drive innovation. Google has announced Project Mariner as an experimental AI agent that can autonomously navigate and perform tasks on the web within the Chrome browser.</p>\n<p>\\n Project Mariner, currently in its testing phase, is designed to automate web browsing tasks by moving the cursor, clicking buttons, and filling out forms, essentially mimicking human interaction with websites.&nbsp;Fueled by Gemini 2.0, Mariner uses advanced multimodal capabilities to interpret visual, textual, and contextual cues on websites. This allows the agent to not process information and also engage with interactive elements such as buttons, dropdown menus, and form fields.</p>\n<p>\\\nFor example, in a task like registering for a webinar, Mariner could locate the registration page, fill in user details, select preferences, and submit the form. Unlike static bots that follow rigid scripts, Mariner adapts to variations in website designs. This should help Mariner handle dynamic layouts, pop-ups, or error states. This flexibility is a major advancement, enabling Mariner to complete complex tasks across a wide range of digital environments.</p>\n<h3 id=\"automatingwebbasedtaskswithhumanlikeprecision\">Automating Web-Based Tasks with Human-Like Precision</h3>\n<p>Project Mariner promises to perform multistep tasks that typically require human input. It integrates Gemini 2.0’s contextual understanding to synthesize information from multiple sources and apply it. For instance, if tasked with booking travel, Mariner can browse multiple airline websites, compare prices, and consider user preferences for departure times and layovers before completing the booking process, including payment. This involves not just interaction with individual sites but also decision-making based on the information it retrieves.</p>\n<p>\\\nAdditionally, Mariner can automate repetitive workflows, such as data entry or order processing, by interacting with websites and pulling data into structured formats for internal use. These capabilities highlight Mariner’s potential to change web navigation by turning the browser into a dynamic workspace for automation.</p>\n<h3 id=\"expandingaiagentsintobusinessworkflows\">Expanding AI Agents into Business Workflows</h3>\n<p>Project Mariner’s ability to autonomously interact with web environments has many implications for how businesses approach digital tasks.</p>\n<p>\\\nFor example, in customer service, Mariner could navigate multiple support systems to resolve queries, such as identifying warranty information, filing a claim, or even responding to customer emails.</p>\n<p>\\\nIn market research, it could browse and compile insights from competitor websites, review sites, and online forums, offering businesses comprehensive data without manual effort. Mariner’s (anticipated) adaptability makes it ideal for applications like regulatory compliance, where it could check multiple sources to make sure a company’s practices align with updated legal standards.</p>\n<p>\\\nBy automating these labor-intensive activities, Mariner could reduce operational costs and free up human employees to focus on higher-value tasks. Its development could signal a shift from AI to an active participant in executing complex, goal-oriented workflows. I say “could” because we are in the early days.</p>\n<h2 id=\"howaiassistantscouldchangebusinesses\">How AI Assistants Could Change Businesses</h2>\n<p>AI agents like Project Mariner have the potential to alter how search engines and digital platforms interact with users and businesses. Traditional search relies on user-initiated queries and static content to deliver results, but AI agents introduce a more dynamic approach by autonomously retrieving, analyzing, and synthesizing information across multiple sites. For businesses, this could mean optimizing content for machine-driven searches, where AI agents prioritize structured data, semantic clarity, and real-time updates.</p>\n<p>\\\nFor example, a product page that includes schema markup, detailed metadata, and dynamic pricing information would be better suited to interact with AI agents than one relying solely on text descriptions. This shift necessitates a deeper understanding of how AI agents interpret and prioritize content, which could push businesses to adopt data-driven strategies that align with these evolving search dynamics.</p>\n<h3 id=\"newadvertisingopportunitieswithaidriveninteractions\">New Advertising Opportunities with AI-Driven Interactions</h3>\n<p>The rise of AI agents (beyond what I’m writing about in this article) also presents opportunities for businesses to develop advertising formats tailored to machine-driven engagement. Unlike human users who may respond to visual cues or emotional appeals, AI agents prioritize relevance, efficiency, and data accuracy. This could lead to the emergence of agent-specific advertising strategies, such as paid placements within AI agent workflows.</p>\n<p>\\\nFor instance, in an eCommerce context, businesses might bid for higher visibility in AI-curated product comparisons, similar to how search engine advertising functions today. New ad formats could involve creating promotional data feeds optimized for AI agents. Conceivably a business could integrate special offers or branded messages more effectively into the agent’s interactions with users. Businesses that experiment with these models may gain a competitive edge as AI agents become more prominent in search and commerce.</p>\n<h3 id=\"impactonecommerceandpersonalization\">Impact on eCommerce and Personalization</h3>\n<p>For eCommerce platforms, AI agents like Project Mariner could change how products are searched, recommended, and purchased. By navigating multiple platforms, comparing prices, and assessing user preferences autonomously, AI agents can streamline the decision-making process for consumers. This could enable businesses to focus on creating personalized experiences by feeding the agents detailed product data, rich descriptions, and real-time inventory updates.</p>\n<p>\\\nFor example, an AI agent assisting a customer looking for running shoes could analyze options across various sites, compare technical specifications, and even recommend complementary products like performance socks or hydration packs. The integration of personalized recommendations into the AI workflow has the potential to boost conversion rates, as customers are presented with tailored options that meet their specific needs with minimal effort.</p>\n<h2 id=\"googlesadvantages\">Google’s Advantages</h2>\n<p>Where does Google go from here? Well, we know in 2025, the company will be embroiled in a dogfight with those pesky upstarts (that don’t seem so much like upstarts anymore) such as OpenAI and Perplexity. Google’s strengths in the generative AI arms race stem from its integration of AI across a vast ecosystem, access to extensive user data, and the resources to innovate at scale. These advantages allow Google to enhance tools like Gemini 2.0 and Project Mariner in ways that competitors cannot easily replicate.</p>\n<h3 id=\"ecosystemintegration\">Ecosystem Integration</h3>\n<p>As noted earlier, Google’s vast ecosystem (including Search, Gmail, Google Workspace, Android, and YouTube) enables interoperability between services, allowing Google to implement new AI capabilities at scale. For example, Gemini 2.0’s multimodal features can enrich Google Search with text, image, and audio responses while also enhancing personalized recommendations on YouTube or workflow automation in Workspace. Competing startups like OpenAI Perplexity lack this sprawling infrastructure, which limits their ability to offer end-to-end solutions across diverse user needs.</p>\n<h3 id=\"marketleadershipanddataaccess\">Market Leadership and Data Access</h3>\n<p>Despite its declining search market share, Google retains the largest repository of user data, giving it an edge in training generative AI models. Gemini 2.0, for instance, benefits from billions of daily user interactions that help refine its contextual understanding, personalization, and real-time knowledge integration. Startups don’t match the scale and diversity of Google’s data, which remains essential for optimizing AI performance across a wide range of scenarios.</p>\n<h3 id=\"brandtrustandfamiliarity\">Brand Trust and Familiarity</h3>\n<p>Google’s longevity in the tech industry builds a level of trust and familiarity among users and businesses. While OpenAI and others are viewed as innovators, Google’s reputation as a reliable provider of search and productivity tools likely helps its AI offerings gain quicker adoption in enterprise and consumer markets. Ongoing improvements, such as Project Mariner’s ability to automate workflows, capitalize on Google’s brand credibility to introduce advanced capabilities with potentially less resistance than newer entrants might face.</p>\n<h3 id=\"resourcesforrapiditeration\">Resources for Rapid Iteration</h3>\n<p>Google’s financial resources and expertise allow it to iterate quickly on AI projects and recover from missteps. The botched rollout of Bard, for instance, has been largely mitigated by Gemini’s subsequent advancements. Google’s ability to deploy massive teams of engineers and researchers gives it an edge in improving AI tools faster than leaner startups can.</p>\n<h2 id=\"googlesdisadvantages\">Google’s Disadvantages</h2>\n<p>Google’s strengths in scale and infrastructure can also hinder its ability to innovate as quickly as leaner rivals. And it business model, heavily reliant on search advertising, faces challenges as user behavior shifts toward platforms like TikTok, Amazon, and AI-driven alternatives. Google must also contend with increased regulatory scrutiny and high expectations from users accustomed to its dominance.</p>\n<h3 id=\"slowerinnovationpace\">Slower Innovation Pace</h3>\n<p>While Google is no longer the slow-moving battleship it was accused of being after ChatGPT’s launch, its size and bureaucracy still hinder rapid innovation compared to more agile competitors. OpenAI and Perplexity can bring features to market faster and iterate based on user feedback without navigating the complex organizational challenges Google faces.</p>\n<h3 id=\"dependenceontraditionalrevenuestreams\">Dependence on Traditional Revenue Streams</h3>\n<p>Google’s business model is deeply tied to search advertising, which faces growing competition from platforms like Amazon and TikTok, as well as conversational AI. The rise of AI agents that are discussed here could complicate Google’s ad-driven revenue model. Adapting to this shift while maintaining profitability could be a challenge.</p>\n<h3 id=\"publicperceptionofmonopoly\">Public Perception of Monopoly</h3>\n<p>Google’s dominance in tech has often attracted regulatory scrutiny, and its moves in AI could exacerbate this issue. Competitors and regulators may argue that Google’s access to data resources and its integration of AI into widely used platforms give it an unfair advantage, potentially leading to antitrust investigations. This is less of a risk for smaller companies like OpenAI and Perplexity, which are perceived as disruptors rather than monopolists.</p>\n<h3 id=\"vulnerabilitiesinuserretention\">Vulnerabilities in User Retention</h3>\n<p>Younger audiences, particularly Gen Z, increasingly favor platforms like TikTok and Amazon for search-related activities. This demographic shift threatens Google’s long-term user retention and its ability to shape AI adoption patterns. If these users grow accustomed to alternative platforms, they may be less inclined to embrace Google’s AI offerings, even as tools like Gemini 2.0 and Mariner gain traction.</p>\n<h3 id=\"highstakesinexecution\">High Stakes in Execution</h3>\n<p>Unlike startups that can afford niche successes, Google faces immense pressure to deliver AI solutions that work flawlessly across its entire ecosystem. Missteps like the initial Bard rollout or underwhelming adoption of new features can damage its reputation more significantly than failures from smaller competitors, as Google’s products are held to a higher standard by users and the industry alike.</p>\n<h2 id=\"dontdismissbattleships\">Don’t Dismiss Battleships</h2>\n<p>Accurate or not, the perception of Google is that the company is responding to change, not driving it. But the company seems to be figuring out how to manage the cadence of change by balancing speed with rigor. To be sure,&nbsp;Google is being challenged on all fronts, ranging from fast-growing search alternatives to ongoing antitrust legislation. But remember when Meta was supposedly on the ropes in 2021-22 only to roar back with AI-driven capabilities? Don’t count out the battleships.</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Transform Your Development Process with Smarter Software Reviews","url":"https://hackernoon.com/transform-your-development-process-with-smarter-software-reviews?source=rss","date":1734665033,"author":"Just Another Tech Lead","unread":true,"desc":"","content":"<p>\\</p>\n<h2 id=\"whatissoftwarereview\">What is Software Review?</h2>\n<p>What is a review in software testing?</p>\n<p>\\\nThere are different types of reviews that happen at different points in the software development lifecycle (<a href=\"https://aws.amazon.com/what-is/sdlc/\">SDLC</a>), and we’ll dive into them all in this article.</p>\n<p>\\\nReviewing throughout the entire software development process is key. You shouldn’t just test the final product at the end of development.</p>\n<p>\\\nThat’s far too late.</p>\n<p>\\\nReviewing in software ensures that you maintain quality, produce the right thing, and do so in a timely manner.</p>\n<p>\\\nI’ve been in all stages of the software review process many many times over the years. It’s one of the key skills that a software engineer has to be comfortable with outside of writing code.</p>\n<h2 id=\"objectivesandbenefitsofsoftwarereview\">Objectives and Benefits of Software Review</h2>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:51.447Z-bmlit1w0vvs5i65hj6u9o19v\" alt=\"An image showing a bulleyes dartboard that represents hitting the targets in a software review\" /></p>\n<p>\\\nWhenever I’m thinking of reviews, I have a few key things I’m trying to achieve.</p>\n<p>\\\nThe first purpose I think of for the review process, is to make sure you identify and issues as early as possible in the software development life cycle and fix them. In almost all cases, the earlier you find and fix a problem, the cheaper and easier it is.</p>\n<p>\\\nAnother main purpose I’m striving for in the software review is the make sure that you’re actually creating the software that your users are expecting.</p>\n<p>\\\nIn my experience, It’s pretty common for engineers to veer off from course a little and before too long you are creating quality software, but not the quality software that your user wanted.</p>\n<p>\\\nA successful review at any point in the review process aims to ensure both the quality and direction of the product.</p>\n<h2 id=\"typesofsoftwarereview\">Types of Software Review</h2>\n<p>There are many types of <a href=\"https://justanothertechlead.com/software/the-importance-of-review-in-software-testing-best-practices-explained/\">software reviews</a>, including, but not limited to:</p>\n<p>\\</p>\n<ul>\n<li>Code Review</li>\n<li>Peer Review</li>\n<li>Technical Review</li>\n<li>Pair Programming</li>\n<li>Management review</li>\n</ul>\n<h3 id=\"peerreviewcodereview\">Peer Review / Code Review</h3>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:51.450Z-w7sayb9l6tok6nit2old56lz\" alt=\"An example of a code reiew as part of a review in software testing\" /></p>\n<p>\\\nThe peer review is one of the earliest forms of formal review for the actual code to be checked for <a href=\"https://www.sonarsource.com/learn/code-quality/\">quality</a> and direction.</p>\n<p>\\\nPeer software developers (the reviewer, usually from the same development team) will look at the associated work item (Test Case, User Story, Documentation) and make sure that the code you’ve written matches the intent of that work item.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:51.451Z-hdmr65amcas575foyy16mmui\" alt=\"An informal review or pair programming during the revirew in software testing process\" /></p>\n<p>\\\nOnce they are happy that the written code matches the intent of the work item, they will do code inspections to look for any bugs or code that could be written in a more efficient or easier to understand manner.</p>\n<p>\\\nThe peer review is usually a collaborative effort and can be picked up by one or more software engineers familiar with the software product and code base.</p>\n<p>\\\nWhen I review code, I make sure that I am not just looking for basic technical faults (divide by zero bugs, etc), but that I am also looking for code structure, well named variables, well architeted solutions.</p>\n<p>\\\nI am very picky with my code reviews as you I am a firm believer that code is written once and read a thousand times. Get it right before it gets merged to main.</p>\n<h3 id=\"technicalreview\">Technical Review</h3>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:51.452Z-xzh7d409qk3c3ehoqxx1vn3n\" alt=\"A group of stakeholders in a technical review meeting for the review in software testing process\" /></p>\n<p>\\\nA Technical Review is where a group of people from different roles get together to assess the overall state of may parts of the software project.</p>\n<p>\\\nParticipants include:</p>\n<ul>\n<li>Software Architects</li>\n<li>Senior Developers</li>\n<li>Business Analysts</li>\n<li>QA</li>\n</ul>\n<p>\\\nThis is a fairly formal review meeting where the group will cover topics such as:</p>\n<ul>\n<li>Project Scope</li>\n<li>Requirements documents and specifications</li>\n<li>Test Plans</li>\n<li>Prototypes or MVCs</li>\n</ul>\n<p>\\\nThe idea behind the technical review process is to verify the correctness of the requirements, the direction of the project and the technical roadmap. All of this is to look forwards to try and ensure a smooth project process.</p>\n<h3 id=\"managementreview\">Management Review</h3>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:52.035Z-y87hll1frxttnyn61d4uss84\" alt=\"A picture of a management review meeting. Showing charting and project status.\" /></p>\n<p>\\\nThis part of the review process is to give high-level stakeholders high-level details about the status of the project.</p>\n<p>\\\nManagers tend to want to know about whether deadlines are being met (if not, why not) and if the cost of the project is on target.</p>\n<p>\\\nThere’s no software inspections, no looking at source code and no worrying about testing in this review. The key phrase here is “status report”.</p>\n<h3 id=\"softwareauditreview\">Software Audit Review</h3>\n<p>Software audit review is an exterior review where a single or multiple reviewers outside the development team inspect the software development processes to check compliance with standards, requirements, and specifications.</p>\n<p>\\\nThese tend to be infrequent and only really done at a high level.</p>\n<h2 id=\"theroleofreviewinthesoftwaredevelopmentprocess\">The Role of Review in the Software Development Process</h2>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:52.017Z-cdnbyf82vdra24ninwcth50y\" alt=\"An image of the Software Development Lifecycle.\" /></p>\n<p>\\\nEach of the above review types is crucial in its own way to the success of a project.</p>\n<p>\\\nReviews highlight issues and miscommunications early on. They keep the project on track and in the right direction.</p>\n<p>\\\nWhether formal or informal reviews, reviews get people talking. They gather stakeholders and knowledgeable people in the same place and get multiple minds solving and validating all of the work.</p>\n<p>\\\nReviews help companies ensure that their software complies with regulatory and industry standards.</p>\n<h2 id=\"challengesandsolutionsinsoftwarereview\">Challenges and Solutions in Software Review</h2>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/QRqitUIXi9Z5pvAY0aAnCzCu0002-2024-12-20T03:23:51.897Z-xotlwi5yow169hg23rf5ji2q\" alt=\"What are the challenges and solutions in the software review?\" /></p>\n<p>\\\nAdmin and beurocreacy.</p>\n<p>\\\nIn my experience, these are the two most common complaints from engineers about the software review process.</p>\n<p>I’ve worked in many companies with many smart people.</p>\n<p>\\\nUnfortunately, smart engineers don’t often like many meetings. They don’t like doing Jira admin. They don’t like people scrutinizing their code.</p>\n<p>\\\nAdding time and effort between a coder and writing code is rarely something you want to do.</p>\n<p>\\\nHowever, going slower to get to the end goal faster is always a smart move.</p>\n<p>\\\nShowing engineers that putting the effort in upfront on generating the correct specifications, and test cases and how reviews play a critical role in delivering what the client actually wants will make your life a lot easier.</p>\n<p>\\\nAnother issue is showing the people involved that the effort they are putting in to code reviews, technical reviews etc has a real world benefit is hard to do.</p>\n<p>\\\nYou can’t run A-B tests on this type of thing. All you can do is highlight the successes that this process has had in the past and how running projects without these processes have failed in the past.</p>\n<p>\\\nSoftware development and the development process is about metrics. Prove how this type of project management has worked with stats from the past.</p>\n<h2 id=\"bestpracticesforeffectivesoftwarereview\">Best Practices for Effective Software Review</h2>\n<p>Let’s summarise some of the best practices I’ve mentioned throughout this post:</p>\n<p>\\</p>\n<ul>\n<li>Establish clear objectives and scope for the review.</li>\n<li>Assign roles and responsibilities to team members.</li>\n<li>Use a structured review process, such as entry evaluation, review process management, planning, preparation, and analysis and exit evaluation.</li>\n<li>Use tool-assisted reviews for efficient and asynchronous reviews.</li>\n<li>Track metrics to justify the time and brainpower required for code review.</li>\n</ul>\n<h2 id=\"softwaretestingandreviewacollaborativeapproach\">Software Testing and Review: A Collaborative Approach</h2>\n<p>You should always have automated tests for your code. However, manual testing with QA is a vital step in creating a polished software product.</p>\n<p>\\\nQA think differently to Engineers. QA look to break things, engineers tend to think about the “happy path”.</p>\n<p>\\\nOnce you as an engineering team have delivered and tested a vertical flow, hand it over to QA to do their thing.</p>\n<p>\\\nThey will bend and twist your software in ways you can’t imagine.</p>\n<p>\\\nThis is a vital step in the software review process.</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Zero-shot Voice Conversion: Comparing HierSpeech++ to Other Basemodels","url":"https://hackernoon.com/zero-shot-voice-conversion-comparing-hierspeech-to-other-basemodels?source=rss","date":1734645611,"author":"The FewShot Prompting Publication","unread":true,"desc":"","content":"<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/zYC7U8hxuymTblz2tvYE\">Abstract and 1 Introduction</a></p>\n<p>2 Related Work</p>\n<p><a href=\"http://hackernoon.com/preview/bUHHU5ui0Jvfx3NLgXn7\">2.1 Neural Codec Language Models and 2.2 Non-autoregressive Models</a></p>\n<p><a href=\"https://hackernoon.com/preview/lS4EQj0KRDhn2JWgnfXm\">2.3 Diffusion Models and 2.4 Zero-shot Voice Cloning</a></p>\n<p><a href=\"http://hackernoon.com/preview/0tdbCniFMdYJpqFBCq1m\">3 Hierspeech++ and 3.1 Speech Representations</a></p>\n<p><a href=\"http://hackernoon.com/preview/LfAveoCj2GBPe2t8ENsl\">3.2 Hierarchical Speech Synthesizer</a></p>\n<p><a href=\"http://hackernoon.com/preview/gnJLUxC1N3hjl8z8Ycyb\">3.3 Text-to-Vec</a></p>\n<p><a href=\"http://hackernoon.com/preview/uaiYjb5hLYsRXymXWlJv\">3.4 Speech Super-resolution</a></p>\n<p><a href=\"http://hackernoon.com/preview/SeWuSTT0PJg90QdoNgeg\">3.5 Model Architecture</a></p>\n<p>4 Speech Synthesis Tasks</p>\n<p><a href=\"http://hackernoon.com/preview/mya5VKgy7cMfFIbGo6hC\">4.1 Voice Conversion and 4.2 Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/Be55iPleupZFqDxK016G\">4.3 Style Prompt Replication</a></p>\n<p><a href=\"http://hackernoon.com/preview/6EpMrittOGKdxcNiewLu\">5 Experiment and Result, and Dataset</a></p>\n<p><a href=\"http://hackernoon.com/preview/UQ35wTFA4My9dTvIDKal\">5.2 Preprocessing and 5.3 Training</a></p>\n<p><a href=\"http://hackernoon.com/preview/rxy4GP4BLWswikJeUazr\">5.4 Evaluation Metrics</a></p>\n<p><a href=\"http://hackernoon.com/preview/7N8HfSBM8a6QMtZDWpiB\">5.5 Ablation Study</a></p>\n<p><a href=\"https://hackernoon.com/preview/dR9mbhgRFvheDMvNmdgj\">5.6 Zero-shot Voice Conversion</a></p>\n<p><a href=\"http://hackernoon.com/preview/GEZi85nULQUQ7lZHWvuv\">5.7 High-diversity but High-fidelity Speech Synthesis</a></p>\n<p><a href=\"https://hackernoon.com/preview/HAmXU0iL45pVwpajWp00\">5.8 Zero-shot Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/nug8VdvUj3SspNsA610I\">5.9 Zero-shot Text-to-Speech with 1s Prompt</a></p>\n<p><a href=\"https://hackernoon.com/preview/lRMdEqFa0jX4IYP4zAoq\">5.10 Speech Super-resolution</a></p>\n<p><a href=\"https://hackernoon.com/preview/6uCIPfcNQJsmMHh13eGW\">5.11 Additional Experiments with Other Baselines</a></p>\n<p><a href=\"http://hackernoon.com/preview/NeatQ4ggLL4BJnS7NeYg\">6 Limitation and Quick Fix</a></p>\n<p><a href=\"http://hackernoon.com/preview/YXoT6IIglVoPPjR3FISF\">7 Conclusion, Acknowledgement and References</a></p>\n<h2 id=\"56zeroshotvoiceconversion\">5.6 Zero-shot Voice Conversion</h2>\n<p>We compared the voice style transfer performance of HierSpeech++ with other basemodels: 1) AutoVC [66], which is an autoencoder-based non-autoregressive VC model using an information bottleneck to disentangle the content and style, 2) VoiceMixer [46], which is a GAN-based parallel VC model using similarity-based information bottleneck, 3- 5) Diffusion-based models (DiffVC [64], Diff-HierVC [11], and DDDM-VC [10]), 6) YourTTS [7], VITS-based end-to-end VC models utilizing phoneme sequences to extract content information, 7) HierVST [45], hierspeech-based end-to-end VC model using hierarchical style adaptation. For a fair comparison, we trained all model with the same dataset (LT460, train-clean-460 subsets of LibriTTS) without YourTTS. We utilized the official implementation of YourTTS which was trained with an additional dataset. We also trained the model with a large-scale dataset such as LT-960, all training subsets of LibriTTS) and additional datasets to verify the effectiveness of scaling-up the dataset.</p>\n<p>\\\nFor the subjective objective, TABLE 5 demonstrates that our model significantly improves the naturalness and similarity of the converted speech in terms of nMOS and sMOS. We found that our model with a large-scale dataset showed a better naturalness than ground-truth speech.</p>\n<p>\\\nHowever, the results also showed that increasing the dataset without filtering noisy data slightly decreased an audio quality in terms of nMOS and UTMOS but the similarity increased consistently according to the data scale. In addition, WER also showed better performance than the other models. Furthermore, the results of the similarity measurement show that our models perform better in terms of the EER and SECS. Moreover, the results verified that HierSpeech++ which was trained with a large-scale dataset is a much stronger zero-shot speech synthesizer.</p>\n<p>\\\nWe will include zero-shot cross-lingual voice style transfer results and additional zero-shot voice conversion results with noisy speech prompts on our demo page. We highly recommend listening to the demo samples and will release the source code of the hierarchical speech synthesizer for a strong zero-shot speech synthesizer. Furthermore, we can also upsample the audio using SpeechSR from 16 kHz to 48 kHz, which can simply improve the perceptual audio quality as described in Section 5.10.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-4x83xo5.png\" alt=\"TABLE 6: Temperature parameter search. For TTS, we have two controllable temperature, Tttv of TTV and Th of hierarchical speech synthesizer. We utilize a HierSpeech++ trained with LT-960 for this experiment and fix the random seed. We found that low temperatures improve the robustness of synthetic speech in terms of CER and WER. However, if you hope to generate diverse and expressive speech, you could choose high temperatures. The CER and WER of groundtruth is 2.31 and 4.13, respectively. UTMOS is presented with standard deviation.\" /></p>\n<p>\\</p>\n<p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2311.12454\">available on arxiv</a> under CC BY-NC-SA 4.0 DEED license.</p>\n<p>:::</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Sang-Hoon Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(2) Ha-Yeong Choi, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(3) Seung-Bin Kim, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(4) Seong-Whan Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea and a Corresponding author.</p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Not to be outdone by OpenAI, Google releases its own “reasoning” AI model","url":"https://arstechnica.com/information-technology/2024/12/not-to-be-outdone-by-openai-google-releases-its-own-reasoning-ai-model/","date":1734644993,"author":"Benj Edwards","unread":true,"desc":"","content":"\n              <p>It's been a really busy month for Google as it apparently endeavors to outshine OpenAI with a blitz of AI releases. On Thursday, Google dropped its latest party trick: <a href=\"https://ai.google.dev/gemini-api/docs/thinking-mode\">Gemini 2.0 Flash Thinking Experimental</a>, which is a new AI model that uses runtime \"reasoning\" techniques similar to <a href=\"https://arstechnica.com/ai/2024/12/openais-new-200-mo-chatgpt-subscription-will-buy-you-more-compute-time/\">OpenAI's o1</a> to achieve \"deeper thinking\" on problems fed into it.</p>\n<p>The experimental model builds on Google's newly released <a href=\"https://arstechnica.com/information-technology/2024/12/google-goes-agentic-with-gemini-2-0s-ambitious-ai-agent-features/\">Gemini 2.0 Flash</a> and runs on its AI Studio platform, but early tests <a href=\"https://techcrunch.com/2024/12/19/google-releases-its-own-reasoning-ai-model/\">conducted</a> by TechCrunch reporter Kyle Wiggers reveal accuracy issues with some basic tasks, such as incorrectly counting that the word \"strawberry\" contains two R's.</p>\n<p>These so-called reasoning models differ from standard AI models by incorporating feedback loops of self-checking mechanisms, similar to techniques we <a href=\"https://arstechnica.com/information-technology/2023/04/hype-grows-over-autonomous-ai-agents-that-loop-gpt-4-outputs/\">first saw in early 2023</a> with hobbyist projects like \"Baby AGI.\" The process requires more computing time, often adding extra seconds or minutes to response times. Companies have turned to reasoning models as traditional scaling methods at training time have been showing diminishing returns.</p><p><a href=\"https://arstechnica.com/information-technology/2024/12/not-to-be-outdone-by-openai-google-releases-its-own-reasoning-ai-model/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/information-technology/2024/12/not-to-be-outdone-by-openai-google-releases-its-own-reasoning-ai-model/#comments\">Comments</a></p>\n\n            ","flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-1152x648.jpg","enclosureMime":""},{"title":"Conducting Ablation Studies to Verify the Effectiveness of Each Component in HierSpeech++","url":"https://hackernoon.com/conducting-ablation-studies-to-verify-the-effectiveness-of-each-component-in-hierspeech?source=rss","date":1734644711,"author":"The FewShot Prompting Publication","unread":true,"desc":"","content":"<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/zYC7U8hxuymTblz2tvYE\">Abstract and 1 Introduction</a></p>\n<p>2 Related Work</p>\n<p><a href=\"http://hackernoon.com/preview/bUHHU5ui0Jvfx3NLgXn7\">2.1 Neural Codec Language Models and 2.2 Non-autoregressive Models</a></p>\n<p><a href=\"https://hackernoon.com/preview/lS4EQj0KRDhn2JWgnfXm\">2.3 Diffusion Models and 2.4 Zero-shot Voice Cloning</a></p>\n<p><a href=\"http://hackernoon.com/preview/0tdbCniFMdYJpqFBCq1m\">3 Hierspeech++ and 3.1 Speech Representations</a></p>\n<p><a href=\"http://hackernoon.com/preview/LfAveoCj2GBPe2t8ENsl\">3.2 Hierarchical Speech Synthesizer</a></p>\n<p><a href=\"http://hackernoon.com/preview/gnJLUxC1N3hjl8z8Ycyb\">3.3 Text-to-Vec</a></p>\n<p><a href=\"http://hackernoon.com/preview/uaiYjb5hLYsRXymXWlJv\">3.4 Speech Super-resolution</a></p>\n<p><a href=\"http://hackernoon.com/preview/SeWuSTT0PJg90QdoNgeg\">3.5 Model Architecture</a></p>\n<p>4 Speech Synthesis Tasks</p>\n<p><a href=\"http://hackernoon.com/preview/mya5VKgy7cMfFIbGo6hC\">4.1 Voice Conversion and 4.2 Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/Be55iPleupZFqDxK016G\">4.3 Style Prompt Replication</a></p>\n<p><a href=\"http://hackernoon.com/preview/6EpMrittOGKdxcNiewLu\">5 Experiment and Result, and Dataset</a></p>\n<p><a href=\"http://hackernoon.com/preview/UQ35wTFA4My9dTvIDKal\">5.2 Preprocessing and 5.3 Training</a></p>\n<p><a href=\"http://hackernoon.com/preview/rxy4GP4BLWswikJeUazr\">5.4 Evaluation Metrics</a></p>\n<p><a href=\"http://hackernoon.com/preview/7N8HfSBM8a6QMtZDWpiB\">5.5 Ablation Study</a></p>\n<p><a href=\"https://hackernoon.com/preview/dR9mbhgRFvheDMvNmdgj\">5.6 Zero-shot Voice Conversion</a></p>\n<p><a href=\"http://hackernoon.com/preview/GEZi85nULQUQ7lZHWvuv\">5.7 High-diversity but High-fidelity Speech Synthesis</a></p>\n<p><a href=\"https://hackernoon.com/preview/HAmXU0iL45pVwpajWp00\">5.8 Zero-shot Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/nug8VdvUj3SspNsA610I\">5.9 Zero-shot Text-to-Speech with 1s Prompt</a></p>\n<p><a href=\"https://hackernoon.com/preview/lRMdEqFa0jX4IYP4zAoq\">5.10 Speech Super-resolution</a></p>\n<p><a href=\"https://hackernoon.com/preview/6uCIPfcNQJsmMHh13eGW\">5.11 Additional Experiments with Other Baselines</a></p>\n<p><a href=\"http://hackernoon.com/preview/NeatQ4ggLL4BJnS7NeYg\">6 Limitation and Quick Fix</a></p>\n<p><a href=\"http://hackernoon.com/preview/YXoT6IIglVoPPjR3FISF\">7 Conclusion, Acknowledgement and References</a></p>\n<h2 id=\"55ablationstudy\">5.5 Ablation Study</h2>\n<p>Before we compare the model with other baselines in the TTS and VC tasks, we conducted ablation studies by comparing Reconstruction[10], Resynthesis [11], and VC performance to verify the effectiveness of each component in HierSpeech++. First, although previous E2E models have shown highquality waveform audio generation, the zero-shot speech synthesis performance was considerably low, and some studies must fine-tune or use speaker id for speaker adaptation. Recently, HierVST has significantly improved a voice style transfer performance of the E2E model; therefore so we conduct ablation studies by building up on HierVST</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-ky83xjg.png\" alt=\"TABLE 2: Reconstruction results for ablation studies. LT-460 denotes LibriTTS train-clean-100 and 360 subsets, and LT-960additionally utilize a train-other-500 subset with LT-460. ALL denotes that the model is trained with all dataset in Section 5.1.\" /></p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-wt93xkh.png\" alt=\"TABLE 3: Resynthesis results for ablation studies\" /></p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-tab3x60.png\" alt=\"TABLE 4: Voice Conversion results for ablation studies. Params. denotes the number of model parameters.\" /></p>\n<p>\\\n<strong>AMP Block</strong> We first replaced the MRF block of HiFi-GAN with the AMP of BigVGAN for OOD generation. The AMP improved the performance of all tasks in terms of all metrics without F0 consistency. The results show that the BigVGANbased HAG performs better but the loss balance may lean toward optimizing the waveform reconstruction rather than F0 prediction; however, the naturalness and similarity of the converted speech improved in terms of all metrics. Specifically, objective naturalness exhibited better UTMOS.</p>\n<p>\\\n<strong>SF Encoder</strong> To address F0 consistency, we utilize an SF encoder (SFE) for a dual-path semantic encoder, which enhances the semantic prior in terms of all metrics. This significantly improved the F0 consistency of inference scenario. It is worth noting that F0 can be manually controlled.</p>\n<p>\\\n<strong>Dual-audio Encoder</strong> We also utilized a dual-audio posterior encoder (DAE) to increase the acoustic capacity of the acoustic representation, which significantly increases the reconstruction performance. Although the linear spectrogram contains useful information for reconstructing a waveform audio, this representation still lacks the ability to reproduce all information; therefore, additional information from waveform audio could complement a wave-level acoustic representation. It is worth noting that the DAE was only utilized during training but significantly improved reconstruction and pronunciation. However, we found that the enhanced acoustic posterior contains a large information resulting in reducing a VC performance.</p>\n<p>\\\n<strong>T-Flow</strong> To bridge the gap between each representation, we replace a wavenet-based normalizing flow with Transformerbased normalizing flow (T-Flow) using AdaLN-Zero for style adaptation. This also improved the entire performance of all metrics. Moreover, speaker similarity significantly improved.</p>\n<p>\\\n<strong>Bi-Flow</strong> Moreover, we adopt a bidirectional normalizing flow (Bi-Flow) to reduce the train-inference mismatch problem. The results show that Bi-Flow slightly decreases the reconstruction quality. However, this could regularize a posterior by conditioning the information used in the inference scenario, thereby improving the VC performance. We also found that high weight of Bi-Flow significantly decreased a reconstruction performance, and thus, we use λ of 0.5 for weak regularization.</p>\n<p>\\\n<strong>Large-scale Data</strong> In addition, we demonstrated that our model is robust to data scale-up. We did not use any labels to train the model, and only used a low-resolution speech dataset of 16 kHz, which we could obtain simply due to SpeechSR. For scaling-up, we did not conduct any preprocessing to train the model without down-sampling (any to 16 kHz), so there are noisy samples in our dataset however we did not experience any problems.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-m7c3x22.png\" alt=\"TABLE 5: Zero-shot VC results on unseen speakers from VCTK dataset. DiffVC♠ denotes pre-trained model from the officialimplementation trained with LibriTTS. YourTTS♣ denotes a pre-trained model from the official implementation trained with\" /></p>\n<p>\\</p>\n<p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2311.12454\">available on arxiv</a> under CC BY-NC-SA 4.0 DEED license.</p>\n<p>:::</p>\n<hr />\n<p>[10] Reconstruction: Posterior Encoder → Generator → Audio</p>\n<p>\\\n[11] Resynthesis: Prior Encoder → Generator → Audio</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Sang-Hoon Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(2) Ha-Yeong Choi, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(3) Seung-Bin Kim, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(4) Seong-Whan Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea and a Corresponding author.</p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"The 7 Objective Metrics We Conducted for the Reconstruction and Resynthesis Tasks","url":"https://hackernoon.com/the-7-objective-metrics-we-conducted-for-the-reconstruction-and-resynthesis-tasks?source=rss","date":1734643811,"author":"The FewShot Prompting Publication","unread":true,"desc":"","content":"<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/zYC7U8hxuymTblz2tvYE\">Abstract and 1 Introduction</a></p>\n<p>2 Related Work</p>\n<p><a href=\"http://hackernoon.com/preview/bUHHU5ui0Jvfx3NLgXn7\">2.1 Neural Codec Language Models and 2.2 Non-autoregressive Models</a></p>\n<p><a href=\"https://hackernoon.com/preview/lS4EQj0KRDhn2JWgnfXm\">2.3 Diffusion Models and 2.4 Zero-shot Voice Cloning</a></p>\n<p><a href=\"http://hackernoon.com/preview/0tdbCniFMdYJpqFBCq1m\">3 Hierspeech++ and 3.1 Speech Representations</a></p>\n<p><a href=\"http://hackernoon.com/preview/LfAveoCj2GBPe2t8ENsl\">3.2 Hierarchical Speech Synthesizer</a></p>\n<p><a href=\"http://hackernoon.com/preview/gnJLUxC1N3hjl8z8Ycyb\">3.3 Text-to-Vec</a></p>\n<p><a href=\"http://hackernoon.com/preview/uaiYjb5hLYsRXymXWlJv\">3.4 Speech Super-resolution</a></p>\n<p><a href=\"http://hackernoon.com/preview/SeWuSTT0PJg90QdoNgeg\">3.5 Model Architecture</a></p>\n<p>4 Speech Synthesis Tasks</p>\n<p><a href=\"http://hackernoon.com/preview/mya5VKgy7cMfFIbGo6hC\">4.1 Voice Conversion and 4.2 Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/Be55iPleupZFqDxK016G\">4.3 Style Prompt Replication</a></p>\n<p><a href=\"http://hackernoon.com/preview/6EpMrittOGKdxcNiewLu\">5 Experiment and Result, and Dataset</a></p>\n<p><a href=\"http://hackernoon.com/preview/UQ35wTFA4My9dTvIDKal\">5.2 Preprocessing and 5.3 Training</a></p>\n<p><a href=\"http://hackernoon.com/preview/rxy4GP4BLWswikJeUazr\">5.4 Evaluation Metrics</a></p>\n<p><a href=\"http://hackernoon.com/preview/7N8HfSBM8a6QMtZDWpiB\">5.5 Ablation Study</a></p>\n<p><a href=\"https://hackernoon.com/preview/dR9mbhgRFvheDMvNmdgj\">5.6 Zero-shot Voice Conversion</a></p>\n<p><a href=\"http://hackernoon.com/preview/GEZi85nULQUQ7lZHWvuv\">5.7 High-diversity but High-fidelity Speech Synthesis</a></p>\n<p><a href=\"https://hackernoon.com/preview/HAmXU0iL45pVwpajWp00\">5.8 Zero-shot Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/nug8VdvUj3SspNsA610I\">5.9 Zero-shot Text-to-Speech with 1s Prompt</a></p>\n<p><a href=\"https://hackernoon.com/preview/lRMdEqFa0jX4IYP4zAoq\">5.10 Speech Super-resolution</a></p>\n<p><a href=\"https://hackernoon.com/preview/6uCIPfcNQJsmMHh13eGW\">5.11 Additional Experiments with Other Baselines</a></p>\n<p><a href=\"http://hackernoon.com/preview/NeatQ4ggLL4BJnS7NeYg\">6 Limitation and Quick Fix</a></p>\n<p><a href=\"http://hackernoon.com/preview/YXoT6IIglVoPPjR3FISF\">7 Conclusion, Acknowledgement and References</a></p>\n<h2 id=\"54evaluationmetrics\">5.4 Evaluation Metrics</h2>\n<p>For the reconstruction and resynthesis tasks, we conducted seven objective metrics: a log-scale Mel error distance (Mel), perceptual evaluation of speech quality (PESQ)[5] , Pitch, periodicity (Period.), voice/unvoice (V/UV) F1 score, and logscale F0 consistency F0c. We used the official implementation of CARGAN [60] for pitch, periodicity, and U/UV F1[6] . For F0c, we calculated the L1 distance between the log-scale ground-truth and the predicted F0 in the HAG.</p>\n<p>\\\nFor VC, we used two subjective metrics: naturalness mean opinion score (nMOS) and voice similarity MOS (sMOS) with a CI of 95%; and three objective metrics for naturalness: UTMOS [69], character error rate (CER) and word error rate (WER); two objective metrics for similarity: automatic speaker verification equal error rate (EER), and speaker encoder cosine similarity (SECS). We utilized the open-source UTMOS[7] which is an MOS prediction model for a naturalness metric. Although this can not be considered an absolute evaluation metric, we believe that it is a simple way to estimate the audio quality of synthetic speech. Additionally, this method does not require ground-truth audio or labels to estimate the score. Therefore, we highly recommend using this simple metric during validation by adding a single line. For CER and WER, we utilized the Whisper’s official implementation. We used a large model with 1,550 M parameters and calculated the CER and WER after text normalization, as presented in the official implementation. We utilized a pre-trained automatic speaker verification models [42][8] which was trained with a large-scale speech dataset, VoxCeleb2 [14]. In [13], the effectiveness of metric learning in automatic speaker verification was demonstrated. Furthermore, [42] introduced online data augmentation, which decreased the EER from 2.17% to 1.17%. In addition, we utilized the pre-trained speaker encoder, Resemblyzer [9] to extract a speaker representation, and we calculated the cosine similarity between the speaker representation of the target speech and synthetic speech.</p>\n<p>\\\nFor TTS, we additionally utilize a prosody MOS (pMOS). Sixty samples were randomly selected for each model. The nMOS was rated by 10 listeners on a scale of 1-5, and the sMOS and pMOS were rated by 10 listeners on a scale of 1-4. A confidence interval of 95% was reported for MOS.</p>\n<p>\\</p>\n<p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2311.12454\">available on arxiv</a> under CC BY-NC-SA 4.0 DEED license.</p>\n<p>:::</p>\n<hr />\n<p>[5] <a href=\"https://github.com/ludlows/PESQ\">https://github.com/ludlows/PESQ</a></p>\n<p>\\\n[6] <a href=\"https://github.com/descriptinc/cargan\">https://github.com/descriptinc/cargan</a></p>\n<p>\\\n[7] <a href=\"https://github.com/tarepan/SpeechMOS\">https://github.com/tarepan/SpeechMOS</a></p>\n<p>\\\n[8] <a href=\"https://github.com/clovaai/voxceleb_trainer\">https://github.com/clovaai/voxceleb_trainer</a></p>\n<p>\\\n[9] <a href=\"https://github.com/resemble-ai/Resemblyzer\">https://github.com/resemble-ai/Resemblyzer</a></p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Sang-Hoon Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(2) Ha-Yeong Choi, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(3) Seung-Bin Kim, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(4) Seong-Whan Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea and a Corresponding author.</p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"How We Used the LibriTTS Dataset to Train the Hierarchical Speech Synthesizer","url":"https://hackernoon.com/how-we-used-the-libritts-dataset-to-train-the-hierarchical-speech-synthesizer?source=rss","date":1734642912,"author":"The FewShot Prompting Publication","unread":true,"desc":"","content":"<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/zYC7U8hxuymTblz2tvYE\">Abstract and 1 Introduction</a></p>\n<p>2 Related Work</p>\n<p><a href=\"http://hackernoon.com/preview/bUHHU5ui0Jvfx3NLgXn7\">2.1 Neural Codec Language Models and 2.2 Non-autoregressive Models</a></p>\n<p><a href=\"https://hackernoon.com/preview/lS4EQj0KRDhn2JWgnfXm\">2.3 Diffusion Models and 2.4 Zero-shot Voice Cloning</a></p>\n<p><a href=\"http://hackernoon.com/preview/0tdbCniFMdYJpqFBCq1m\">3 Hierspeech++ and 3.1 Speech Representations</a></p>\n<p><a href=\"http://hackernoon.com/preview/LfAveoCj2GBPe2t8ENsl\">3.2 Hierarchical Speech Synthesizer</a></p>\n<p><a href=\"http://hackernoon.com/preview/gnJLUxC1N3hjl8z8Ycyb\">3.3 Text-to-Vec</a></p>\n<p><a href=\"http://hackernoon.com/preview/uaiYjb5hLYsRXymXWlJv\">3.4 Speech Super-resolution</a></p>\n<p><a href=\"http://hackernoon.com/preview/SeWuSTT0PJg90QdoNgeg\">3.5 Model Architecture</a></p>\n<p>4 Speech Synthesis Tasks</p>\n<p><a href=\"http://hackernoon.com/preview/mya5VKgy7cMfFIbGo6hC\">4.1 Voice Conversion and 4.2 Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/Be55iPleupZFqDxK016G\">4.3 Style Prompt Replication</a></p>\n<p><a href=\"http://hackernoon.com/preview/6EpMrittOGKdxcNiewLu\">5 Experiment and Result, and Dataset</a></p>\n<p><a href=\"http://hackernoon.com/preview/UQ35wTFA4My9dTvIDKal\">5.2 Preprocessing and 5.3 Training</a></p>\n<p><a href=\"http://hackernoon.com/preview/rxy4GP4BLWswikJeUazr\">5.4 Evaluation Metrics</a></p>\n<p><a href=\"http://hackernoon.com/preview/7N8HfSBM8a6QMtZDWpiB\">5.5 Ablation Study</a></p>\n<p><a href=\"https://hackernoon.com/preview/dR9mbhgRFvheDMvNmdgj\">5.6 Zero-shot Voice Conversion</a></p>\n<p><a href=\"http://hackernoon.com/preview/GEZi85nULQUQ7lZHWvuv\">5.7 High-diversity but High-fidelity Speech Synthesis</a></p>\n<p><a href=\"https://hackernoon.com/preview/HAmXU0iL45pVwpajWp00\">5.8 Zero-shot Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/nug8VdvUj3SspNsA610I\">5.9 Zero-shot Text-to-Speech with 1s Prompt</a></p>\n<p><a href=\"https://hackernoon.com/preview/lRMdEqFa0jX4IYP4zAoq\">5.10 Speech Super-resolution</a></p>\n<p><a href=\"https://hackernoon.com/preview/6uCIPfcNQJsmMHh13eGW\">5.11 Additional Experiments with Other Baselines</a></p>\n<p><a href=\"http://hackernoon.com/preview/NeatQ4ggLL4BJnS7NeYg\">6 Limitation and Quick Fix</a></p>\n<p><a href=\"http://hackernoon.com/preview/YXoT6IIglVoPPjR3FISF\">7 Conclusion, Acknowledgement and References</a></p>\n<h2 id=\"5experimentandresult\">5 EXPERIMENT AND RESULT</h2>\n<p><img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-fd83xa9.png\" alt=\"TABLE 1: Training Dataset. We utilize public-available speech dataset to train the model. For TTV, we utilize only LibriTTS dataset.\" /></p>\n<h3 id=\"51dataset\">5.1 Dataset</h3>\n<p>We utilized LibriTTS dataset [90] to train the hierarchical speech synthesizer. First, we trained the model with trainclean subsets of LibriTTS (train-clean-100 and train-clean-360) for a fair comparison. Additionally, we utilized the trainother-500 subsets of LibriTTS for better voice style transfer. Furthermore, we scaled-up the dataset to 1 kh to improve the robustness and diversity, as indicated in TABLE 1[2] . For the Libri-light [27] and Multi-Speaker Speech Synthesis (MSSS) dataset of AIHub [3] , we sampled a small portion of speech from each speaker. We used a EXPRESSO [61] and NIKL[4]. We downsampled the audio at 16 kHz, and normalized it using a scale of [-0.95, 0.95]. For text-to-vec, we utilized all the train subsets of LibriTTS. For speechSR, we used a VCTK dataset [76] which has a sampling rate of 48 kHz to compare the models. However, we also trained the model with a largescale dataset for better speech super-resolution performance by including MSSS dataset, VCTK, and EXPRESSO.</p>\n<p>\\</p>\n<p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2311.12454\">available on arxiv</a> under CC BY-NC-SA 4.0 DEED license.</p>\n<p>:::</p>\n<hr />\n<p>[2] Although we hope to increase the data scale to over 10k Hours, this is the maximum limit in our academic resources.</p>\n<p>\\\n[3] <a href=\"https://aihub.or.kr\">https://aihub.or.kr</a></p>\n<p>\\\n[4] <a href=\"https://www.nia.or.kr/\">https://www.nia.or.kr/</a></p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Sang-Hoon Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(2) Ha-Yeong Choi, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(3) Seung-Bin Kim, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(4) Seong-Whan Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea and a Corresponding author.</p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Style Prompt Replication: A Simple Trick That Helped Us In Our Journey","url":"https://hackernoon.com/style-prompt-replication-a-simple-trick-that-helped-us-in-our-journey?source=rss","date":1734642011,"author":"The FewShot Prompting Publication","unread":true,"desc":"","content":"<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/zYC7U8hxuymTblz2tvYE\">Abstract and 1 Introduction</a></p>\n<p>2 Related Work</p>\n<p><a href=\"http://hackernoon.com/preview/bUHHU5ui0Jvfx3NLgXn7\">2.1 Neural Codec Language Models and 2.2 Non-autoregressive Models</a></p>\n<p><a href=\"https://hackernoon.com/preview/lS4EQj0KRDhn2JWgnfXm\">2.3 Diffusion Models and 2.4 Zero-shot Voice Cloning</a></p>\n<p><a href=\"http://hackernoon.com/preview/0tdbCniFMdYJpqFBCq1m\">3 Hierspeech++ and 3.1 Speech Representations</a></p>\n<p><a href=\"http://hackernoon.com/preview/LfAveoCj2GBPe2t8ENsl\">3.2 Hierarchical Speech Synthesizer</a></p>\n<p><a href=\"http://hackernoon.com/preview/gnJLUxC1N3hjl8z8Ycyb\">3.3 Text-to-Vec</a></p>\n<p><a href=\"http://hackernoon.com/preview/uaiYjb5hLYsRXymXWlJv\">3.4 Speech Super-resolution</a></p>\n<p><a href=\"http://hackernoon.com/preview/SeWuSTT0PJg90QdoNgeg\">3.5 Model Architecture</a></p>\n<p>4 Speech Synthesis Tasks</p>\n<p><a href=\"http://hackernoon.com/preview/mya5VKgy7cMfFIbGo6hC\">4.1 Voice Conversion and 4.2 Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/Be55iPleupZFqDxK016G\">4.3 Style Prompt Replication</a></p>\n<p><a href=\"http://hackernoon.com/preview/6EpMrittOGKdxcNiewLu\">5 Experiment and Result, and Dataset</a></p>\n<p><a href=\"http://hackernoon.com/preview/UQ35wTFA4My9dTvIDKal\">5.2 Preprocessing and 5.3 Training</a></p>\n<p><a href=\"http://hackernoon.com/preview/rxy4GP4BLWswikJeUazr\">5.4 Evaluation Metrics</a></p>\n<p><a href=\"http://hackernoon.com/preview/7N8HfSBM8a6QMtZDWpiB\">5.5 Ablation Study</a></p>\n<p><a href=\"https://hackernoon.com/preview/dR9mbhgRFvheDMvNmdgj\">5.6 Zero-shot Voice Conversion</a></p>\n<p><a href=\"http://hackernoon.com/preview/GEZi85nULQUQ7lZHWvuv\">5.7 High-diversity but High-fidelity Speech Synthesis</a></p>\n<p><a href=\"https://hackernoon.com/preview/HAmXU0iL45pVwpajWp00\">5.8 Zero-shot Text-to-Speech</a></p>\n<p><a href=\"http://hackernoon.com/preview/nug8VdvUj3SspNsA610I\">5.9 Zero-shot Text-to-Speech with 1s Prompt</a></p>\n<p><a href=\"https://hackernoon.com/preview/lRMdEqFa0jX4IYP4zAoq\">5.10 Speech Super-resolution</a></p>\n<p><a href=\"https://hackernoon.com/preview/6uCIPfcNQJsmMHh13eGW\">5.11 Additional Experiments with Other Baselines</a></p>\n<p><a href=\"http://hackernoon.com/preview/NeatQ4ggLL4BJnS7NeYg\">6 Limitation and Quick Fix</a></p>\n<p><a href=\"http://hackernoon.com/preview/YXoT6IIglVoPPjR3FISF\">7 Conclusion, Acknowledgement and References</a></p>\n<h2 id=\"43stylepromptreplication\">4.3 Style Prompt Replication</h2>\n<p>We found a simple trick to transfer the style even with a one second speech prompt by introducing style prompt replication (SPR). Similar to the DNA replication, we copy the same sequence of prompt as shown in Fig 7. The replicated prompt by n times is fed to the style encoder to extract the style representation. Specifically, because the prompt style encoder usually encounters a long sequence of prompts over 3s, synthetic speech from short prompts may be generated incorrectly. However, SPR can deceive the style encoder as it seems like long prompts, thus we can synthesize the speech even with 1s speech prompt.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-3g83x08.png\" alt=\"Fig. 7: Style Prompt Replication\" /></p>\n<p>\\</p>\n<p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2311.12454\">available on arxiv</a> under CC BY-NC-SA 4.0 DEED license.</p>\n<p>:::</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Sang-Hoon Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(2) Ha-Yeong Choi, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(3) Seung-Bin Kim, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea;</p>\n<p>(4) Seong-Whan Lee, Fellow, IEEE with the Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea and a Corresponding author.</p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"As firms abandon VMware, Broadcom is laughing all the way to the bank","url":"https://arstechnica.com/information-technology/2024/12/as-firms-abandon-vmware-broadcom-is-laughing-all-the-way-to-the-bank/","date":1734640862,"author":"Scharon Harding","unread":true,"desc":"","content":"\n              <p>Another company has publicly <a href=\"https://arstechnica.com/information-technology/2024/10/a-year-after-broadcoms-vmware-buy-customers-eye-exit-strategies/\">cut ties with Broadcom's VMware</a>. This time, it's Ingram Micro, one of the world's biggest IT distributors. The announcement comes as Broadcom eyes services as a key part of maintaining VMware business in 2025. But even as some customers are reducing reliance on VMware, its <a href=\"https://www.reuters.com/technology/broadcom-rallies-forecast-booming-ai-chip-demand-2024-12-13/\">trillion-dollar</a> owner is laughing all the way to the bank.</p>\n<h2>IT distributor severs VMware ties</h2>\n<p>Ingram is reducing its Broadcom-related business to \"limited engagement with VMware in select regions,\" a spokesperson told <a href=\"https://www.theregister.com/2024/12/16/ingram_micro_vmware_broadcom_deal_ends/\">The Register</a> this week.</p>\n<p>\"We were unable to reach an agreement with Broadcom that would help our customers deliver the best technology outcomes now and in the future while providing an appropriate shareholder return,” the spokesperson said.</p><p><a href=\"https://arstechnica.com/information-technology/2024/12/as-firms-abandon-vmware-broadcom-is-laughing-all-the-way-to-the-bank/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/information-technology/2024/12/as-firms-abandon-vmware-broadcom-is-laughing-all-the-way-to-the-bank/#comments\">Comments</a></p>\n\n            ","flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1503144949-1152x648.jpg","enclosureMime":""},{"title":"New physics sim trains robots 430,000 times faster than reality","url":"https://arstechnica.com/information-technology/2024/12/new-physics-sim-trains-robots-430000-times-faster-than-reality/","date":1734639029,"author":"Benj Edwards","unread":true,"desc":"","content":"\n              <p>On Thursday, a large group of university and private industry researchers unveiled <a href=\"https://genesis-embodied-ai.github.io/\">Genesis</a>, a new open source computer simulation system that lets robots practice tasks in simulated reality 430,000 times faster than in the real world. Researchers can also use an AI agent to generate 3D physics simulations from text prompts.</p>\n<p>The accelerated simulation means a neural network for piloting robots can spend the virtual equivalent of decades learning to pick up objects, walk, or manipulate tools during just hours of real computer time.</p>\n<p>\"One hour of compute time gives a robot 10 years of training experience. That's how Neo was able to learn martial arts in a blink of an eye in the Matrix Dojo,\" <a href=\"https://x.com/DrJimFan/status/1869795912597549137\">wrote</a> Genesis paper co-author Jim Fan on X, who says he played a \"minor part\" in the research. Fan has previously worked on <a href=\"https://arstechnica.com/information-technology/2024/03/nvidia-announces-moonshot-to-create-embodied-human-level-ai-in-robot-form/\">several</a> <a href=\"https://arstechnica.com/information-technology/2023/10/eureka-uses-gpt-4-and-massively-parallel-simulations-to-accelerate-robot-training/\">robotics simulation</a> projects for Nvidia.</p><p><a href=\"https://arstechnica.com/information-technology/2024/12/new-physics-sim-trains-robots-430000-times-faster-than-reality/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/information-technology/2024/12/new-physics-sim-trains-robots-430000-times-faster-than-reality/#comments\">Comments</a></p>\n\n            ","flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/genesis_teapot-1152x648.jpg","enclosureMime":""},{"title":"Worldshards Launches Complete In-Game Economy With Pre-tge Airdrops For All The Active Players","url":"https://hackernoon.com/worldshards-launches-complete-in-game-economy-with-pre-tge-airdrops-for-all-the-active-players?source=rss","date":1734637874,"author":"Gaming Wire","unread":true,"desc":"","content":"<p>ABU DHABI, United Arab Emirates, December 19th, 2024/GamingWire/--WorldShards, the Sandbox MMORPG released on the Open Loot platform alongside other successful web3 titles, has announced the launch of its complete in-game economy, set to roll out in December 2024.</p>\n<p>\\\nThis milestone marks a pivotal step toward the game's Token Generation Event (TGE) in early 2025, building on the significant momentum achieved since the Early Access release in February 2024.</p>\n<p>\\\nSince its launch, WorldShards has attracted tens of thousands of players and over 300,000 active community members, achieving more than $4 million in sales in 2024 across various offerings, including Artifact Boxes, Mystery Island Boxes, and Founder’s Lootboxes — many of which sold out quickly, demonstrating strong community interest.</p>\n<p>\\\nHere is a complete list of what is coming with the economy launch update:</p>\n<h3 id=\"proxytokeningamerewards\">Proxy Token In-game Rewards</h3>\n<p>The upcoming launch of the in-game economy will include the introduction of Proxy Tokens, which will be introduced in mid-December. These tokens will be obtainable while actively engaging various gameplay mechanics and will play a key role in the player's journey, serving as the primary currency for NFT crafting and upgrades, and will be fully convertible to game tokens at a 1:1 ratio when the TGE takes place in early 2025.</p>\n<h3 id=\"free30daystrialaccess\">Free 30 Days Trial Access</h3>\n<p>To make the game even more accessible, WorldShards is lifting access code requirements in December, allowing everyone to try out the game with 30-day trial access for all users, with the option to convert the trial to permanent access if in-game activity criteria are met.</p>\n<h3 id=\"airdropforallactiveplayers\">Airdrop For All Active Players</h3>\n<p>Aside from all the events planned during Phase 2, every active player, including those who have only trial access, will participate in the airdrop campaign. Player activity serves as the main metric of the campaign, so even those who don’t own or use collectible NFTs will be eligible for the airdrop.</p>\n<p>\\\nAll users who already had full access to the game are granted welcome bundles they can gift to their friends, granting them full game access and 30$ in premium currency called gems.</p>\n<p>\\\nAlso, all users who purchase Welcome Bundles in the future will get a +1 bonus Welcome Bundle for their friends.</p>\n<p>WorldShards plans to continue its growth in the competitive web3 market by adding even more innovative features to both gameplay and economy further down the line.</p>\n<h3 id=\"aboutworldshards\">About WorldShards</h3>\n<p><strong><a href=\"https://www.worldshards.online/\">WorldShards</a></strong> is a cross-platform MMORPG, developed by Lowkick Studio in partnership with Abu Dhabi Gaming. LowKick is a studio founded by experienced veterans behind World of Tanks, Allods Online, Lineage 2, and other successful video games.</p>\n<p>\\\nThe project was launched in partnership with the Open Loot platform, the creators of Big Time and $OL token.</p>\n<p>For more information, users can visit <strong><a href=\"http://www.worldshards.online\">www.worldshards.online</a></strong> or follow WorldShards on <strong><a href=\"https://discord.com/invite/3gjguaACfC\">Discord</a></strong> and <strong><a href=\"https://x.com/worldshardsgame\">X</a></strong>.</p>\n<h3 id=\"contact\">Contact</h3>\n<p>Nikita Vladimirov</p>\n<p>hello@lowkick.games</p>\n<p>:::tip\nThis story was distributed as a release by Gamingwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;<strong><a href=\"https://business.hackernoon.com/business-blogging?ref=hackernoon.com\">here</a></strong></p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Phemex Announces Holiday Trading Campaign: Win a Luxury Bali Holiday!","url":"https://hackernoon.com/phemex-announces-holiday-trading-campaign-win-a-luxury-bali-holiday?source=rss","date":1734637599,"author":"BTCWire","unread":true,"desc":"","content":"<p>APIA, Samoa, DEC. 19 – As Christmas and the New Year approach, there's no better way to end the year than celebrating with your loved ones in a tropical paradise.</p>\n<p>\\\nLeading cryptocurrency exchange <strong><a href=\"https://phemex.com/\">Phemex</a></strong> is excited to announce an exclusive opportunity to enjoy the holidays on the beautiful island of Bali, along with a chance to win 4 ETH! Join the festive Phemex Cryptomas Event and make your holiday season unforgettable.</p>\n<h3 id=\"eventrewards\">Event Rewards</h3>\n<p>Cryptomas Award: Users who trade consecutively for 20 or more days will be eligible for a chance to win the top prize—a Bali Island tour! One lucky winner will be selected from all eligible participants.</p>\n<p>\\\nGingerbread Man Award: Five additional eligible users will receive Christmas gift boxes, including a luggage case, socks, ornaments, and more.</p>\n<p>\\\nReindeer Award: Users who register and complete 15 days of trading will share a 2 ETH prize pool. Those who register and complete 2 days of trading will share another 2 ETH prize pool.</p>\n<p>\\\nSnowman Award: Users who register and achieve a trading volume of $2,000 will be eligible to share in a 20,0000 USDT trading bonus pool based on their trading volume.</p>\n<p>\\\n<strong><a href=\"https://phemex.com/en/promo/activity/129\">Celebrate the Season! Join the Phemex Cryptomas Celebration from December 18, 2024, to January 6, 2025!</a></strong></p>\n<p>\\\nNow is the perfect time to join Phemex, the leading exchange that offers new spot pairs daily for a competitive trading edge while prioritizing security with an innovative cold wallet system and a Proof of Reserves tool to ensure asset safety.</p>\n<p>\\\nAs the first exchange to publish both proof-of-reserves and proof-of-solvency, Phemex stands out as a trustworthy platform with customizable features tailored to users' needs.</p>\n<h3 id=\"aboutphemex\">About Phemex</h3>\n<p>Phemex is a leading cryptocurrency exchange that specializes in spot and derivatives trading. It features 140+ USDT-margined contract trading pairs with up to 100x leverage that all support Hedge Mode, alongside 300+ popular spot trading pairs.</p>\n<p>\\\nIndividuals from all over the world can instantly buy, sell, and trade blockchain cryptocurrency through a user-friendly and secure platform. Phemex has released transparent Merkle-Tree Proof-of-Reserves so all users can verify on the blockchain that all funds are 100% backed on the platform. As the first exchange to publish both proof-of-reserves and proof-of-solvency through a unique, self-proving approach, Phemex stands out as one of the best and most trustworthy crypto exchanges.</p>\n<h3 id=\"contact\">Contact</h3>\n<p>Oyku Yavuz; PR &amp; Content Lead</p>\n<p><strong><a href=\"mailto:oyku.yavuz@phemex.com\">oyku.yavuz@phemex.com</a></strong></p>\n<p>:::tip\nThis story was distributed as a release by Btcwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;<strong><a href=\"https://business.hackernoon.com/business-blogging?ref=hackernoon.com\">here</a></strong></p>\n<p>:::</p>\n<p>\\\n \\n </p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Boost VC Invests In PoSciDonDAO, Welcoming It To Their Go-To-Market Program","url":"https://hackernoon.com/boost-vc-invests-in-poscidondao-welcoming-it-to-their-go-to-market-program?source=rss","date":1734637274,"author":"Chainwire","unread":true,"desc":"","content":"<p>Panama City, Panama, December 19th, 2024/Chainwire/--PoSciDonDAO has announced that Boost VC has invested in the project, representing a significant step forward in its mission to decentralize scientific research and innovation.</p>\n<p>\\\nThe investment includes PoSciDonDAO’s acceptance into Boost VC’s Go-To-Market Program, which will provide valuable resources to support the project’s development and adoption.</p>\n<h3 id=\"boostvcexpandscommitmenttodecentralizedsciencewithposcidondao\">Boost VC Expands Commitment to Decentralized Science With PoSciDonDAO</h3>\n<p>Boost VC, co-founded by Adam Draper and Brayton Williams, is known for supporting emerging technologies that introduce alternative approaches to traditional systems.</p>\n<p>\\\nOver the years, Boost VC has demonstrated a strong commitment to the decentralized science (DeSci) space by investing in projects such as Molecule, ResearchHub, HairDAO, and Data Lake.</p>\n<p>\\\nThese initiatives have advanced democratized science, open innovation, and accessibility for researchers and innovators. By including PoSciDonDAO in its program, Boost VC reinforces its dedication to decentralized approaches in scientific research and development.</p>\n<h3 id=\"opportunitiesthroughboostvcspartnership\">Opportunities Through Boost VC’s Partnership</h3>\n<p>\\\nBoost VC’s investment and PoSciDonDAO’s participation in its Go-To-Market Program present new opportunities for growth. Key benefits include:</p>\n<p>\\</p>\n<ol>\n<li>Access to Expert Mentorship: Boost VC’s team and network of industry experts will provide guidance to help PoSciDonDAO refine its strategy and scale.</li>\n<li>Market Positioning: Insights into navigating competitive landscapes, with tailored go-to-market strategies for adoption and growth.</li>\n<li>Network Expansion: Integration into a collaborative community of innovators, fostering partnerships with research institutions and advocates in decentralized science and blockchain.</li>\n</ol>\n<h3 id=\"asharedvisionfordecentralizedscience\">A Shared Vision for Decentralized Science</h3>\n<p>This partnership reflects a shared vision of decentralization as a tool to promote equity, inclusivity, and progress in science. PoSciDonDAO and Boost VC aim to collaborate in fostering a movement that emphasizes transparency in research funding and equitable access to scientific resources.</p>\n<h3 id=\"thefutureofdesciacollectiveeffort\">The Future of DeSci: A Collective Effort</h3>\n<p>Boost VC’s partnership with PoSciDonDAO underscores growing momentum for DeSci. Through this collaboration, both entities aim to demonstrate that decentralization can enhance inclusivity and equity in scientific innovation.</p>\n<p>\\\nBy joining forces, PoSciDonDAO and Boost VC will work toward advancing a model of knowledge creation and resource allocation that benefits the global scientific community.</p>\n<h3 id=\"aboutposcidondao\">About PoSciDonDAO</h3>\n<p>PoSciDonDAO leverages blockchain technology to democratize personalized medicine research by bridging the gap between researchers, funders, and the broader scientific community.</p>\n<p>\\\nThrough decentralized governance and funding, the platform ensures transparent and equitable resource allocation, fostering trust and inclusivity in advancing personalized medicine innovation.</p>\n<p>For more information about PoSciDonDAO, users can visit the official PoSciDonDAO <strong><a href=\"https://www.poscidondao.com/\">website</a></strong>.</p>\n<p>\\\nUsers are invited to stay informed about PoSciDonDAO’s initiatives by following the project on social platforms:</p>\n<p><strong><a href=\"https://x.com/PoSciDonDAO\">Twitter/X</a></strong> | <strong><a href=\"https://t.me/OfficialPoSciDonDAO\">Telegram</a></strong> | <strong><a href=\"https://discord.com/invite/75SrHpcNSZ\">Discord</a></strong></p>\n<h3 id=\"contact\">Contact</h3>\n<p>Marketing Representative</p>\n<p>Ayat Abourashed</p>\n<p>ayat@poscidon.com</p>\n<p>:::tip\nThis story was distributed as a release by Chainwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;<strong><a href=\"https://business.hackernoon.com/business-blogging?ref=hackernoon.com\">here</a></strong></p>\n<p>:::</p>\n<p>\\</p>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Intel & Canonical Collaborate On Graphics Preview Stack For Ubuntu 24.10","url":"https://www.phoronix.com/news/Intel-Gfx-Preview-Ubuntu-24.10","date":1734636792,"author":"Michael Larabel","unread":true,"desc":"","content":"Intel and Canonical have been collaborating to provide an early \"Graphics Preview\" stack for Ubuntu 24.10 to provide better support for the new Intel Core Ultra Series 2 \"Lunar Lake\" and Intel Arc B-Series \"Battlemage\" graphics...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"IEEE MOVE: To the Rescue After Hurricanes Helene and Milton","url":"https://spectrum.ieee.org/ieee-move-hurricane-helene-milton","date":1734634804,"author":"Willie D. Jones","unread":true,"desc":"","content":"<p>Mobile response fleet delivers power, connectivity, and hope</p>","flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NTM2NjEzNC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTczODcyMDM1MH0.ZgSw1DYcQ1Sj4MQuQX--Xu_NKLhiE-1HarqBZz2OVIc/image.jpg?width=600","enclosureMime":""},{"title":"This Backpack Lightens Its Own Load","url":"https://spectrum.ieee.org/suspension-backpack","date":1734633381,"author":"Michelle Hampson","unread":true,"desc":"","content":"<p>The prototype dampens the jostling of items inside it</p>","flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NTM1MjA3Ni9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc4MTY4MDgxNn0.v2TW3ZvX5QlCfZHKl1NJaKqEa18jlhyB6i5ND95xYLk/image.jpg?width=600","enclosureMime":""},{"title":"Latest Qualcomm RB3 Gen 2 Developer Kit Unlocks AI Computing for IoT Edge Innovation","url":"https://spectrum.ieee.org/qualcomm-developer-kit","date":1734632615,"author":"Dexter Johnson","unread":true,"desc":"","content":"<p>New kits put advanced AI edge computing power into the hands of developers everywhere</p>","flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NTM2NjAyNC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc2NTExNzkwOH0.2157cZZPkFHcYjjVurFFQbDGRdAi9iQmouxVf5knmcE/image.png?width=600","enclosureMime":""},{"title":"Linux 6.13 Is A Great Holiday Gift For AMD Systems With Many New Features","url":"https://www.phoronix.com/news/Linux-6.13-AMD-Features","date":1734628725,"author":"Michael Larabel","unread":true,"desc":"","content":"Of the many new features in Linux 6.13 for that kernel debuting by late January, AMD customers once again have a lot to look forward to from new Zen 5 features being enabled to additional performance optimizations. Here is a look at some of the most exciting new AMD features and improvements with this first major Linux kernel release coming for 2025...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"A new, uncensored AI video model may spark a new AI hobbyist movement","url":"https://arstechnica.com/ai/2024/12/a-new-uncensored-ai-video-model-may-spark-a-new-ai-hobbyist-movement/","date":1734623410,"author":"Benj Edwards","unread":true,"desc":"","content":"\n              <p>The AI-generated video scene has been hopping this year (or <a href=\"https://arstechnica.com/information-technology/2024/12/twirling-body-horror-in-gymnastics-video-exposes-ais-flaws/\">twirling wildly</a>, as the case may be). This past week alone we've seen releases or announcements of OpenAI's <a href=\"https://arstechnica.com/ai/2024/12/ten-months-after-first-tease-openai-launches-sora-video-generation-publicly/\">Sora</a>, Pika AI's <a href=\"https://pikartai.com/pika-2-0/\">Pika 2</a>, Google's <a href=\"https://deepmind.google/technologies/veo/veo-2/\">Veo 2</a>, and Minimax's <a href=\"https://x.com/fofrAI/status/1868763436974588222\">video-01-live</a>. It's frankly hard to keep up, and even tougher to test them all. But recently, we put a new open-weights AI video synthesis model, Tencent's <a href=\"https://aivideo.hunyuan.tencent.com/\">HunyuanVideo</a>, to the test—and it's surprisingly capable for being a \"free\" model.</p>\n<p>Unlike the aforementioned models, HunyuanVideo's neural network weights are openly distributed, which means they can be run locally under the right circumstances (people have already <a href=\"https://www.reddit.com/r/StableDiffusion/comments/1h7hunp/how_to_run_hunyuanvideo_on_a_single_24gb_vram_card/\">demonstrated it</a> on a consumer 24 GB VRAM GPU) and it can be fine-tuned or used with <a href=\"https://research.ibm.com/blog/LoRAs-explained\">LoRAs</a> to teach it new concepts.</p>\n<p>Notably, a few Chinese companies have been at the forefront of AI video for most of this year, and some experts speculate that the reason is less reticence to train on copyrighted materials, use images and names of famous celebrities, and incorporate some uncensored video sources. As we saw with <a href=\"https://arstechnica.com/information-technology/2024/06/ridiculed-stable-diffusion-3-release-excels-at-ai-generated-body-horror/\">Stable Diffusion 3</a>'s mangled release, including nudity or pornography in training data may allow these models achieve better results by providing more information about human bodies. HunyuanVideo notably allows uncensored outputs, so unlike the commercial video models out there, it can generate videos of anatomically realistic, nude humans.</p><p><a href=\"https://arstechnica.com/ai/2024/12/a-new-uncensored-ai-video-model-may-spark-a-new-ai-hobbyist-movement/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2024/12/a-new-uncensored-ai-video-model-may-spark-a-new-ai-hobbyist-movement/#comments\">Comments</a></p>\n\n            ","flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/hunyuan_video_header_1-1152x648.jpg","enclosureMime":""},{"title":"Intel Core Ultra 9 285K \"Arrow Lake\" Windows 11 vs. Ubuntu Linux Performance","url":"https://www.phoronix.com/review/intel-arrowlake-windows-linux","date":1734622200,"author":"Michael Larabel","unread":true,"desc":"","content":"One of the areas for benchmarking exploration that I had been meaning to dive into since the launch of the Intel Arrow Lake processors back in October was checking out the Microsoft Windows 11 vs. Linux performance for the new Core Ultra 9 285K flagship processor. Particularly with the mix of P and E cores I was curious for a fresh look at the Windows vs. Linux performance capabilities. With recently carrying out a Windows 11 install on Arrow Lake for running the Intel Arc B580 Battlemage Windows vs. Linux benchmarks, following that I carried out some fresh CPU benchmarks for seeing how Arrow Lake processor performance is looking on these competing operating systems.","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Fish Shell 4.0 Beta Released With C++ Code Ported To Rust","url":"https://www.phoronix.com/news/Fish-Shell-4.0-Beta","date":1734616904,"author":"Michael Larabel","unread":true,"desc":"","content":"The Fish Shell as the interactive, user-friendly command line shell debuted its 4.0 beta release ahead of the holidays. Notably in this release is porting the C++ code over to the Rust programming language...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"OpenVINO 2024.6 Released With Intel Arc B-Series Support, NPU Optimizations","url":"https://www.phoronix.com/news/OpenVINO-2024.6-Released","date":1734616506,"author":"Michael Larabel","unread":true,"desc":"","content":"Intel's OpenVINO open-source AI toolkit is out with a new feature release today for closing out the year. The OpenVINO 2024.6 release brings initial support for the Arc B-Series \"Battlemage\" graphics cards as well as further optimizing the Intel NPU support...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"It's AI Versus the World's Largest Tuberculosis Epidemic","url":"https://spectrum.ieee.org/tuberculosis","date":1734609603,"author":"Edd Gent","unread":true,"desc":"","content":"<p> An Indian group has built tools to help with diagnosis and treatment</p>","flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NTMxMjA1NC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc3NjkxNTE3MX0.1vA1ZEceKKLPnznv62hcRZv9KfaPJ8mfYQ2MuPhMpFY/image.jpg?width=600","enclosureMime":""},{"title":"AlmaLinux 10 Beta Running Great With Nice Performance As Free/Community Alternative To RHEL 10","url":"https://www.phoronix.com/review/almalinux-10-beta","date":1734609600,"author":"Michael Larabel","unread":true,"desc":"","content":"Along with the recent release of the Red Hat Enterprise Linux 10 beta, the AlmaLinux crew released their AlmaLinux 10 beta as the latest wares for this popular community/free alternative to upstream RHEL. I've been running some early benchmarks and testing on this AlmaLinux 10.0 Beta \"Purple Lion\" release and it's running well with performance right inline with upstream RHEL 10 Beta.","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"AMD Updates Linux Patches For L3 Smart Data Cache Injection SDCIAE Handling","url":"https://www.phoronix.com/news/AMD-L3-SDCIAE-Linux-v2","date":1734607752,"author":"Michael Larabel","unread":true,"desc":"","content":"Back in August AMD posted Linux patches for L3 Smart Data Cache Injection Allocation Enforcement (SDCIAE). That L3 Smart Data Cache Injection (SDCI) work was since announced as part of the AMD EPYC 9005 \"Turin\" processors. A second iteration of those SDCIAE were posted this week in working to get this functionality enabled for the mainline Linux kernel...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Linux 6.14 To Support Realtek RTL8125D Rev B 2.5G Ethernet ASIC","url":"https://www.phoronix.com/news/Realtek-RTL8125D-Rev-B-Linux","date":1734607107,"author":"Michael Larabel","unread":true,"desc":"","content":"The Linux kernel already supports the Realtek RTL8125D 2.5G Ethernet controller but additional handling is required to enable the revision B variant of this chipset, which will be coming in the next kernel cycle...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Cloud Hypervisor 43 Brings Live Migration Over TCP, Performance Improvements","url":"https://www.phoronix.com/news/Cloud-Hypervisor-43","date":1734606193,"author":"Michael Larabel","unread":true,"desc":"","content":"Cloud Hypervisor 43 is out as the newest version of this Intel-backed, Rust-based open-source VMM project that now routinely sees contributions from Microsoft, Arm, Rivos, Tencent, and other organizations...","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"NetBSD 10.1 Released With Support For More Network Hardware, Better Ampere Altra Support","url":"https://www.phoronix.com/news/NetBSD-10.1-Released","date":1734567105,"author":"Michael Larabel","unread":true,"desc":"","content":"Building off the release of NetBSD 10.0 that arrived for Easter this year and incorporated a half-decade of work, NetBSD 10.1 is out right before Christmas as the first update to this BSD operating system series...","flags":null,"enclosureUrl":"","enclosureMime":""}]}